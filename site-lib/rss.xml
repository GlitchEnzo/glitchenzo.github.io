<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Trick McCarthy's Blog]]></title><description><![CDATA[Obsidian digital garden]]></description><link>https://glitchenzo.github.io/</link><image><url>https://glitchenzo.github.io/site-lib/media/favicon.png</url><title>Trick McCarthy's Blog</title><link>https://glitchenzo.github.io/</link></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Mon, 29 Dec 2025 14:59:17 GMT</lastBuildDate><atom:link href="https://glitchenzo.github.io/site-lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Mon, 29 Dec 2025 14:58:54 GMT</pubDate><copyright><![CDATA[Patrick McCarthy]]></copyright><ttl>60</ttl><dc:creator>Patrick McCarthy</dc:creator><item><title><![CDATA[2021-12-31 - A Look Back Over 2021]]></title><description><![CDATA[2021-12-31It's hard to believe that 2021 is already over and done with. Little did I know that when the global pandemic rolled-in in March 2020, it'd still be lingering about in December 2021.A lot has changed for me over this past year.Back in January, Vicarious Visions was moved under/merged with/taken over by Blizzard. Previously, they were under Activision, which itself was under the larger entity known as Activision Blizzard King. It all gets confusing. Not only did this transition mean that VV would no longer be able to work on Activision games (Tony Hawk, Crash Bandicoot, Call of Duty, etc), but it also meant that the entire studio (outside of a small handful of folks) would be entirely devoted to supporting Diablo.From January to July, I was specifically working on the Tools team on Diablo IV. I won't get into the details here, but I'll just say that that position was less than ideal for me and the direction I wanted my career to take.In July, I got married! The ceremony was on a beautiful day on top of a mountain in Vermont.In July, I also left VV/Blizzard. I had been at VV for longer than any other place in my career, and it was hard to make the decision to leave. They allowed me to branch out, try new things, take risks, and grow my skills way more than anywhere else I ever worked. I will forever be thankful to them for that.On my second-to-last day at VV, the news broke about the widespread gender discrimination at Blizzard, which I was saddened, but unfortunately not surprised, to hear about.In August, I began working at Tripwire Interactive as their Lead Engine Programmer. My team helped finish up the raytracing update for <a data-tooltip-position="top" aria-label="https://www.tripwireinteractive.com/#/maneater" rel="noopener nofollow" class="external-link is-unresolved" href="https://www.tripwireinteractive.com/#/maneater" target="_self">Maneater</a> that was released on the Xbox Series X and PlayStation 5 in November. We are now hard at work on an unannounced title.Meanwhile, I've also been working on something big&nbsp;in my free-time. I'm not quite ready to fully unveil it to the world, but know that it combines my love of graphics and my background in tools. I've given myself a deadline of GDC to have something shareable, so look for more information in March 2022.Hang in there everyone! Everything can, and will, get better.]]></description><link>https://glitchenzo.github.io/2021-12-31-a-look-back-over-2021.html</link><guid isPermaLink="false">2021-12-31 - A Look Back Over 2021.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:37:19 GMT</pubDate></item><item><title><![CDATA[2018-02-15 - NuGet For Unity Released]]></title><description><![CDATA[2018-02-15In my free-time for the past several years, I've been working on building a NuGet client from scratch that runs entirely within the Unity Editor. I have finally launched NuGet For Unity onto the Unity Asset Store.&nbsp; It is completely free and open-source, so have at it! Asset Store:&nbsp;<a rel="noopener nofollow" class="external-link is-unresolved" href="https://assetstore.unity.com/packages/tools/utilities/nuget-for-unity-104640" target="_self">https://assetstore.unity.com/packages/tools/utilities/nuget-for-unity-104640</a><br>
Source Code:&nbsp;<a rel="noopener nofollow" class="external-link is-unresolved" href="https://github.com/GlitchEnzo/NuGetForUnity" target="_self">https://github.com/GlitchEnzo/NuGetForUnity</a>]]></description><link>https://glitchenzo.github.io/2018-02-15-nuget-for-unity-released.html</link><guid isPermaLink="false">2018-02-15 - NuGet For Unity Released.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:37:18 GMT</pubDate></item><item><title><![CDATA[2015-08-07 - Isometric Platformer]]></title><description><![CDATA[2015-08-07Now that video games have been around for several decades, we've seen many different genres as well as countless hybrids between multiple genres. Normally, I would say that a good game could be made regardless of the genre, but I am now of the opinion that there is no such thing as a good isometric platformer, nor will there ever be I suppose. Let me recount a tale for you. &nbsp;I was searching the Interwebs for a top-down Metroid type game. &nbsp;I saw some folks mention a game called <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Scurge:_Hive" rel="noopener nofollow" class="external-link is-unresolved" href="https://en.wikipedia.org/wiki/Scurge:_Hive" target="_self">Scurve: Hive</a>. &nbsp;It was a game that strangely launched on both the GBA and Nintendo DS. &nbsp;The game sounded oddly familiar to me, so I opened my box of NDS games and found that I already had a copy that I had apparently found in a bargain bin for $10. I popped it into my Majora's Mask New 3DS (gotta flash my nerd-cred!) and gave it a go. &nbsp;While I generally like the coloring, enemy design, weapons, and environment, there was one thing that really bothered me that made the game near-unplayable for me. Platforming. &nbsp;In an isometric game. What does a platforming game consist of? &nbsp;Jumping from platform to platform using precise timing and coordination. Using precise timing and coordination! What does the isometric view entail? &nbsp;A camera projection that makes everything the same size regardless of distance or height.
Regardless of distance or height!
What happens when you mix precision jumping with a camera projection that prevents you from judging platform position? &nbsp;You get a terrible game, that's what! <br> Flash forward a couple months to the current day and I recently got <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Rare_Replay" rel="noopener nofollow" class="external-link is-unresolved" href="https://en.wikipedia.org/wiki/Rare_Replay" target="_self">Rare Replay</a> on my Xbox One. Included in the collection are several old isometric platformers from Rare. &nbsp;While I will admit that the use of lighting and shadows in <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Snake_Rattle_%27n%27_Roll" rel="noopener nofollow" class="external-link is-unresolved" href="https://en.wikipedia.org/wiki/Snake_Rattle_%27n%27_Roll" target="_self">Snake Rattle 'n Roll</a>&nbsp;made it not as frustratingly difficult, others, such as <a data-tooltip-position="top" aria-label="https://en.wikipedia.org/wiki/Knight_Lore" rel="noopener nofollow" class="external-link is-unresolved" href="https://en.wikipedia.org/wiki/Knight_Lore" target="_self">Knight Lore</a> are abysmal. Knight Lore used a monochromatic artstyle that made the isometric plaforming incredibly difficult. &nbsp;It took great effort for me to be able to figure out which platforms were where. While I can't seem to find any screenshots from Scurge: Hive of the specific spot that was annoying enough to make me want to throw my 3DS on the floor, here are a couple that kinda&nbsp;give you an idea: <br><a data-tooltip-position="top" aria-label="http://3.bp.blogspot.com/-RLiBWtHu6dc/VcTRrWaPlSI/AAAAAAAAUxk/RjqyaZZGBbc/s1600/images.jpg" rel="noopener nofollow" class="external-link is-unresolved" href="http://3.bp.blogspot.com/-RLiBWtHu6dc/VcTRrWaPlSI/AAAAAAAAUxk/RjqyaZZGBbc/s1600/images.jpg" target="_self"></a><img src="http://3.bp.blogspot.com/-RLiBWtHu6dc/VcTRrWaPlSI/AAAAAAAAUxk/RjqyaZZGBbc/s1600/images.jpg" referrerpolicy="no-referrer" target="_self" class="is-unresolved"><br><a data-tooltip-position="top" aria-label="http://3.bp.blogspot.com/-A-YYg_NnHbw/VcTSAwV6NTI/AAAAAAAAUxs/ofqMVxB-BQM/s1600/download.jpg" rel="noopener nofollow" class="external-link is-unresolved" href="http://3.bp.blogspot.com/-A-YYg_NnHbw/VcTSAwV6NTI/AAAAAAAAUxs/ofqMVxB-BQM/s1600/download.jpg" target="_self"></a><img src="http://3.bp.blogspot.com/-A-YYg_NnHbw/VcTSAwV6NTI/AAAAAAAAUxs/ofqMVxB-BQM/s1600/download.jpg" referrerpolicy="no-referrer" target="_self" class="is-unresolved">In summary: Never make an isometric platformer!]]></description><link>https://glitchenzo.github.io/2015-08-07-isometric-platformer.html</link><guid isPermaLink="false">2015-08-07 - Isometric Platformer.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:37:17 GMT</pubDate><enclosure url="http://4.bp.blogspot.com/-PCYBzHSPFBs/VcP5eYGLbUI/AAAAAAAAUws/WH7eY8Hnq98/s320/Scurge_hive_gameplay.PNG" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://4.bp.blogspot.com/-PCYBzHSPFBs/VcP5eYGLbUI/AAAAAAAAUws/WH7eY8Hnq98/s320/Scurge_hive_gameplay.PNG"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2014-05-16 - Dart vs TypeScript]]></title><description><![CDATA[2014-05-16Coming&nbsp;primarily&nbsp;from a C# background (as well as C, C++, &amp; Java), working with JavaScript was quite a paradigm shift. &nbsp;As a result, I was very slow developing in JavaScript because I had to learn all of the ins and outs of the language while I was trying to implement functionality. As you may know from <a data-tooltip-position="top" aria-label="http://recreationstudios.blogspot.com/2014/02/dart-on-cloud-9-ide.html" rel="noopener nofollow" class="external-link is-unresolved" href="http://recreationstudios.blogspot.com/2014/02/dart-on-cloud-9-ide.html" target="_self">reading previous posts</a>, this led me to switch to Dart. &nbsp;Having a syntax very similar to C#/Java, I was more than happy to dive in. &nbsp;I quickly developed a simplistic game engine/framework and even developed four games in one month (one game a week). Having changed jobs (again!), I took time off of my hobby development to focus on getting up to speed at my new job. &nbsp;I'm now at the point of where I'm investigating the feasibility of a new idea. &nbsp;I want to turn my framework into a library that can be used by anyweb developer to make games. &nbsp;I was envisioning compiling the Dart code into JavaScript, allowing other developers to interface with it and even create new scripts on the fly. <br> My entire Dart world shattered apart when I discovered that this would be incredibly difficult, if not impossible to do. &nbsp;You see, even though Dart compiles to JavaScript, it was not meant to be consumed by any one else in that form. &nbsp;The focus is squarely on the Dart VM which isn't even implemented in any real browser. &nbsp;In order to interface with JavaScript, you have to use the <a data-tooltip-position="top" aria-label="https://www.dartlang.org/articles/js-dart-interop/" rel="noopener nofollow" class="external-link is-unresolved" href="https://www.dartlang.org/articles/js-dart-interop/" target="_self">interop layer</a>. &nbsp;Yikes! I sat for several days trying to plan out the best way of exposing practically everything from my Dart code to JavaScript as well as allow random JavaScript code to be serialized along with Dart so that everything was saved together as one game. &nbsp;I eventually decided to look elsewhere for other options. The major alternatives to Dart are:<br>
JavaScript - I've obviously already tried that and need to get away from it until <a data-tooltip-position="top" aria-label="http://en.wikipedia.org/wiki/ECMAScript#ECMAScript_Harmony_.286th_Edition.29" rel="noopener nofollow" class="external-link is-unresolved" href="http://en.wikipedia.org/wiki/ECMAScript#ECMAScript_Harmony_.286th_Edition.29" target="_self">JavaScript 2.0</a>.<br>
<a data-tooltip-position="top" aria-label="http://coffeescript.org/" rel="noopener nofollow" class="external-link is-unresolved" href="http://coffeescript.org/" target="_self">CoffeeScript</a>- This has one of the worst syntaxes I've ever seen. &nbsp;In my opinion, it makes JavaScript worse.<br>
<a data-tooltip-position="top" aria-label="http://www.typescriptlang.org/" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.typescriptlang.org/" target="_self">TypeScript</a>- Everything I've seen thus far for this is amazing, but I'm hesitant after Dart. Dart and TypeScript both have: Types
Generics
Classes
Properties (getters and setters)
Static Fields &amp; Methods
Aliasing
Optional &amp; Default Parameters
Lambda Expressions (Anonymous Methods) What TypeScript has that Dart doesn't: Enumerations
Interfaces (explicit) Dart only has implicit interfaces via classes Modules Dart uses libraries instead public/private keywords Dart uses underscores to mark fields/methods as private. &nbsp;BLEH!!! Rest Parameters
Overloaded Methods I can't believe Dart doesn't support this. &nbsp;This is huge to me. Generic Constraints
Superset of JavaScript All existing JavaScript is valid TypeScript
This allows direct interfacing with JavaScript code
This also means that its implementations of classes, modules, etc are JavaScript 2.0 compatible! What Dart has that TypeScript doesn't: Pub A great way to get other people's packages automatically Basic Framework Classes Lists, WebAudio, WebGL, TypedData, etc
TypeScript has lib.d.ts, but it doesn't provide as much Abstract Classes
Operator Overloading Very handy feature that I hope TypeScript gets at some point Indexers (overloading []) Very useful for creating custom collections or math types (Vector, Matrix, etc) One of the biggest advantages of TypeScript over Dart is this: <br><a data-tooltip-position="top" aria-label="https://c9.io/site/blog/2012/10/typescript-support-in-cloud9/" rel="noopener nofollow" class="external-link is-unresolved" href="https://c9.io/site/blog/2012/10/typescript-support-in-cloud9/" target="_self">Cloud 9 supports TypeScript</a>
I haven't written a single line of TypeScript (yet!), so I can't truly comment how if it is better than Dart, but on paper it looks fantastic. &nbsp;I'll try it out soon!]]></description><link>https://glitchenzo.github.io/2014-05-16-dart-vs-typescript.html</link><guid isPermaLink="false">2014-05-16 - Dart vs TypeScript.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:37:16 GMT</pubDate></item><item><title><![CDATA[2014-03-30 - Game A Week - 4 - Long Jump]]></title><description><![CDATA[2014-03-30<a data-tooltip-position="top" aria-label="http://re-creationstudios.com/gaw/4/" rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/gaw/4/" target="_self">Play the game here!</a>
** Monday
I wanted to have an even more physics heavy game, one that used joints and compound shapes, so I decided to make a vehicle building long jump game. &nbsp;I created the base project along with a very long ground object and a wall to prevent travel to the left. &nbsp;I added in a simple box that would move based upon forces given to it via keypresses. &nbsp;I created a *FollowObject***component that lets the Camera follow the box around. &nbsp;I built a simple ramp, added in distance indicators (current and max) and had the input disable after the box went off the ramp. &nbsp;I was surprised by how fun it already was to play; just flinging a box off of a ramp. Tuesday
I started working on adding joints, but it immediately became clear that I needed to separate out my RigidBodycomponents&nbsp;from their Collidercomponents, which I did. &nbsp;I then realized that I needed to implement some sort of parent/child hierarchy in order to get compound shapes working correctly. &nbsp;This was quite a bit of refactoring work. I added in a quick and simple set of marker bars that indicate every 10 meters in order to help give a sense of motion and distance. Wednesday
I got really sick and didn't work on anything. Thursday
I was still recovering from my sickness. Friday
I did no work on the game. Saturday
I did no work on the game. Sunday
I added in a RevoluteJointcomponent and hooked up two CircleColliders as simple wheels. &nbsp;I pushed the left wall out more to give the player more room to gain speed before hitting the ramp. <br> <a data-tooltip-position="top" aria-label="http://re-creationstudios.com/gaw/4/" rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/gaw/4/" target="_self">Play the game here!</a> Final Thoughts
Due to my sickness and other things in life, I lost several days to be able to work on the game. &nbsp;I had planned for a lot more features since I had the entire week off of work, but alas it was not to be. My major planned feature was to allow the player to construct their own vehicle with various parts available such as wheels, rockets, etc. I was impressed by how fun the game was even in the early stages. &nbsp;I believe this is a really fun concept that needs to be expanded upon in the future. Considering I'm starting a new job this next week, I may skip on doing a Game A Week challenge.]]></description><link>https://glitchenzo.github.io/2014-03-30-game-a-week-4-long-jump.html</link><guid isPermaLink="false">2014-03-30 - Game A Week - 4 - Long Jump.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:37:16 GMT</pubDate></item><item><title><![CDATA[2014-03-23 - Game A Week - 3 - Orbital Golf]]></title><description><![CDATA[2014-03-23Here is how the past week went: (<a data-tooltip-position="top" aria-label="http://re-creationstudios.com/gaw/3/" rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/gaw/3/" target="_self">Play the game here!</a>) Monday<br>
I really wanted to integrate a physics engine in order to get all of the benefits one provides. &nbsp;So, I decided to implement Orbital Golf, a physics heavy golfing game that I had developed a rough prototype of several years ago in Unity. &nbsp;<a data-tooltip-position="top" aria-label="http://re-creationstudios.com/unity/orbitalgolf/" rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/unity/orbitalgolf/" target="_self">You can play the old Unity prototype here</a>. I pulled the <a data-tooltip-position="top" aria-label="https://github.com/dart-lang/dart-box2d" rel="noopener nofollow" class="external-link is-unresolved" href="https://github.com/dart-lang/dart-box2d" target="_self">dart-box2d</a> package into my Dart project, which is a Dart port of <a data-tooltip-position="top" aria-label="http://box2d.org/" rel="noopener nofollow" class="external-link is-unresolved" href="http://box2d.org/" target="_self">Box2D</a>. I then implemented a basic Collidercomponent as well as a rough BoxCollidercomponent. &nbsp;I managed to get a small box to fall and land on a large static box acting as the ground. Tuesday
I fixed a major scaling issue with rendering. &nbsp;I added in a second moving box that bounces off the first box. &nbsp;I implemented a CircleCollidercomponent and the ability to programmatically create a circle mesh. &nbsp;I created a simple wrapper around mouse input to allow that as an input option. I then spent hours trying unsuccessfully to detect then the mouse clicks an object. Wednesday
After continuing to struggle with detecting clicked objects by trying to "unproject" the mouse position as a raycast into the scene, I decided to try going the other direction. &nbsp;(I was able to successfully unproject the mouse position and create a ray vector pointing into the scene, but detecting the ray hitting objects posed the problem.) &nbsp;I implemented a temporary&nbsp;Clickercomponent that projects its own world position into screen space whenever the mouse button is pressed and then sees if it matches (within a range) &nbsp;the mouse position. &nbsp;It worked great, and since I only needed to be able to detect clicks on the ball, this works fine for the game. Thursday
I implemented a Planetcomponent that calculates gravity based upon distance to the planet. &nbsp;I also implemented a Ballcomponent that uses gravity of surrounding planets to apply forces and move the ball around. Friday
I made it so that if ball is clicked on, dragged, and then released, it applies a force relative to how much the mouse was dragged in order to fling the ball around. &nbsp;I added in a simple counter to count how many hits were made. I ran into odd issues with trying to make a "factory" method to generate planets. &nbsp;It seems like a bug in Dart, but I need to investigate it further before I report it. I set up a goal circle that is a static Box2D sensor. &nbsp;I implemented a callback system for when two Box2D objects collider and made it so when the ball and goal touch, it displays a winning message. I also implemented a line renderer to show the force vector to be applied to the ball. &nbsp;It's very crude, but does the job. Saturday
I set up a simple level system that can switch between various levels. I also tried working on displaying a trajectory prediction line, but it turns out to be fairly complicated. &nbsp;I had tried doing a similar thing back with the old Unity version. &nbsp;You can see there is a prediction line in the Unity version, but it doesn't take into account any collisions or friction with surfaces. &nbsp;I was hoping to have a superior prediction line with this prototype, but that doesn't appear to be possible for a one week challenge. Sunday
I decided to change things up a bit and instead of working on gameplay I would try and make it look a little better. &nbsp;I implemented a Texture2Dobject and the ability to set textures on a Material. &nbsp;I wrote a simple new shader that took a single texture. &nbsp;I found a checkerboard pattern image online and I now have a goal with a checkerboard texture applied to it in order to help it stand out more. <br> I changed focus once more and I added the ability to make the game go fullscreen using the <a data-tooltip-position="top" aria-label="http://docs.webplatform.org/wiki/tutorials/using_the_full-screen_api" rel="noopener nofollow" class="external-link is-unresolved" href="http://docs.webplatform.org/wiki/tutorials/using_the_full-screen_api" target="_self">Fullscreen API</a>. I also added in a wrapper around touch events to be able to get touches on a touchscreen. &nbsp;These two features together make it work much better on a mobile device, and I tested the game on my Android phone (Galaxy Note 3). I also made a quick update so that the force line moves along with the ball instead of sitting out in space where you first clicked the ball. <br> <a data-tooltip-position="top" aria-label="http://re-creationstudios.com/gaw/3/" rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/gaw/3/" target="_self">Play the game here!</a> Final Thoughts
I was quite happy with what I accomplished this week. &nbsp;I actually had almost the entire week off of work which helped me be more productive. As usual, there were several features I wish I could have added: Better scoring - scoring based upon the flight time of the ball divided by the number of hits
Better camera - a camera that uses mouse wheel and pinching to zoom
Prediction line - as you probably read above, I really wanted a line to predict ball trajectory
Non-spherical planets - ovals, simple terrain
Orbiting planets - planets orbiting around other planets as moons
More debris and obstacles - things cluttering the way To be honest, I'm glad the week is over. &nbsp;It's good to be able to switch over to a different game every week. &nbsp;I really like the concept of Orbital Golf &nbsp;and I believe it has great potential, but there are other ideas I'd love to try out. &nbsp;I have this next week off of work as well, so hopefully I can whip up something awesome.]]></description><link>https://glitchenzo.github.io/2014-03-23-game-a-week-3-orbital-golf.html</link><guid isPermaLink="false">2014-03-23 - Game A Week - 3 - Orbital Golf.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:37:15 GMT</pubDate></item><item><title><![CDATA[2014-03-16 - Game A Week - 2 - Asteroid Spacewar]]></title><description><![CDATA[2014-03-16Here is how the past week went: (<a data-tooltip-position="top" aria-label="http://re-creationstudios.com/gaw/2/" rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/gaw/2/" target="_self">Play the game here!</a>) Monday<br>
I decided that since the first Game A Week (GAW) game (Pong) only had 2D shapes with translation, then the next game should have 2D shapes with translation&nbsp;and&nbsp;rotation. &nbsp;In keeping with the theme of remaking old games, I chose to create a clone of&nbsp;<a data-tooltip-position="top" aria-label="http://en.wikipedia.org/wiki/Spacewar_%28video_game%29" rel="noopener nofollow" class="external-link is-unresolved" href="http://en.wikipedia.org/wiki/Spacewar_%28video_game%29" target="_self">Spacewar</a>&nbsp;next. &nbsp;I was only able to set up the initial project in Dart, nothing else. Tuesday
I created a triangle shaped&nbsp;GameObject&nbsp;and wrote up a simple&nbsp;Ship&nbsp;component that I assigned it. &nbsp;This component uses keyboard input to rotate the triangle left and right and move the triangle forward and backward. &nbsp;I also changed the background color to black (whoa!). Wednesday
I changed the ship to move via forces applied to it instead of just changing its position. Thursday
No progress. &nbsp;I went to&nbsp;a&nbsp;concert&nbsp;dinner and drinks. (We discovered the concert was cancelled after arriving at the venue.) Friday
No progress. I went to a birthday party. Saturday
I set it up so that the ship warps to the opposite screen edge when it reaches one screen edge. &nbsp;I added in the ability to fire bullets that also warp around. I made a tough decision that since I had not worked on the game very much during the week, that I had to trim down features. &nbsp;I knew I wouldn't have time to put in multiplayer, random ship warping, etc. I decided to make it a more simplistic game similar to Asteroids. I implemented an&nbsp;AsteroidManagercomponent that randomly spawns asteroids that fly around the screen. Sunday
I added in collision detection between the ship, bullets, and asteroids. &nbsp;I set up scoring as well as game over conditions. &nbsp;I added in the ability to render the ship with color (everything previously could only render in white). &nbsp;I tweaked the random creation of asteroids and limited the maximum number of both bullets and asteroids in order to avoid the game being a big mess of objects. <br> <a data-tooltip-position="top" aria-label="http://re-creationstudios.com/gaw/2/" rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/gaw/2/" target="_self">Play the game here!</a> Final Thoughts
I had even less time this week to work on the game than last week. &nbsp;I believe I spent about a total of 12 hours on it this week. Here were the features I had hoped to get in that I had to scrap:
Sounds- Again, sounds for everything didn't make it in.
Planets&nbsp;- Planets with gravity that affected the acceleration/velocity of all objects
Multiplayer- Two ships battling against one another. I'm really hoping that I'll have more time in the next two weeks for future GAWs due to certain circumstances in my life that I'll explain later. NOTE: I realized after publishing the game to my server that my changes to some shared shaders broke last week's Pong game. &nbsp;Nothing is rendering anymore. &nbsp;I'll need to figure out what's going on with that and fix it (no other game code will be changed except that). NOW&nbsp;FIXED!]]></description><link>https://glitchenzo.github.io/2014-03-16-game-a-week-2-asteroid-spacewar.html</link><guid isPermaLink="false">2014-03-16 - Game A Week - 2 - Asteroid Spacewar.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:37:15 GMT</pubDate></item><item><title><![CDATA[2014-03-09 - Game A Week - 1 - Pong]]></title><description><![CDATA[2014-03-09I've read about many different indie developers making a game a week, but it was <a data-tooltip-position="top" aria-label="http://www.gamasutra.com/blogs/RamiIsmail/20140226/211807/Game_A_Week_Getting_Experienced_At_Failure.php" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.gamasutra.com/blogs/RamiIsmail/20140226/211807/Game_A_Week_Getting_Experienced_At_Failure.php" target="_self">this recent article</a> on Gamasutra that really sold me on the idea. &nbsp;I decided that I would try to do it myself, using it to strengthen my game design skills as well beefing up my Dart knowledge. I was tempted to tackle this challenge using Unity, as I have vast knowledge of the ins and outs of that engine, but in the end I decided it would be more educational for me to use something I was not very familiar with. &nbsp;I figured it would force me to think outside the box to come up with solutions. <br> Here is how the past week went: (<a data-tooltip-position="top" aria-label="http://re-creationstudios.com/gaw/1/" rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/gaw/1/" target="_self">Play the game here!</a>) Monday
The first issue was figuring out what game to make. &nbsp;I assumed that making a clone would be best to start off with, and a very simple one at that. &nbsp;Pong seemed appropriate for many different reasons. Once I had chosen the game, &nbsp;I had to set up the basic Dart project structure. &nbsp;This was rather difficult just because of the Dart Editor. &nbsp;(I had decided to use the Dart Editor instead of Cloud 9 while I learn the ins and outs of Dart.) &nbsp;Dart would constantly take up massive amounts of RAM (2.3&nbsp;GB) and CPU (87%), which would cause it to come to a crawl and even crash repeatedly on my PC. <br> I also had quite a bit of difficulty trying to load assets in Dart. &nbsp;I'm developing the base engine as a Dart lib, so I first tried putting the shader files directly in the lib folder. &nbsp;I couldn't figure out any way to actually access them at run-time, so I tried putting them in the asset folder, since that is what is described <a data-tooltip-position="top" aria-label="https://www.dartlang.org/tools/pub/package-layout.html" rel="noopener nofollow" class="external-link is-unresolved" href="https://www.dartlang.org/tools/pub/package-layout.html" target="_self">here</a>. &nbsp;That also didn't work since it requires pub build which apparently doesn't work on Dart libs. &nbsp;So, I ended up simply putting them in the example folder. &nbsp;It's not ideal, but it works for the present. I eventually figured out how to make the Dart Editor stable. &nbsp;I deleted all of the metadata under C:/Users/[user]/DartEditor and then deleted all of the packages folders in my project, since they are generated by Dart anyway. &nbsp;I rebooted the Dart Editor and pulled in my project. &nbsp;It ran smoothly after that. I didn't get as far as I had planned since I was battling against the Dart Editor most of &nbsp;the time. &nbsp;I did end up with a square and triangle rendering via WebGL in Dart using my own custom shader loading. Tuesday
The next major part to implement was an actual game loop instead of having one single Render call. &nbsp;I set up requestAnimationFrameto achieve this, which was relatively straight-forward. &nbsp;It currently calls both Update and Render at the same framerate. &nbsp;I may change this in the future, since most engines/APIs have Update called much more often than Render, but it works fine for me now. I then created a GameObjectbase class as well as Rendererand Transformcomponents that can be attached to GameObjects. &nbsp;I updated the square and triangle test from Monday to use these new structures which greatly simplified the set up code. A small tweak was made so that the WebGL rendering context (Canvas) will be automatically resized along with the browser window. It doesn't really look like a productive day, but I actually accomplished a lot by putting in those base components. &nbsp;It should make all future work much easier. Wednesday
I didn't get much time to work on the game due to other things in life, but I did get some important pieces in. I created a Cameracomponent to help alleviate the hassle of dealing with projection and view matrices all the time. &nbsp;I created a Scenemanager to manage GameObjectsand to automatically call their Update and Render methods. &nbsp;I also created a very simple Colorclass that acts as a simple wrapper around Vector4to provide static properties to commonly used colors. &nbsp;The square and triangle test is now only a few lines of code to set up. Thursday
It was another short day for me, yet very productive. &nbsp;I implemented Keyboardclass to handle all keyboard input. &nbsp;I created a Paddlecomponent that uses the keyboard to move up and down. I created a Ballcomponent that moves across the screen and detects collision with the screen edges and the paddles. Friday
I didn't even touch Pong on Friday because I went out for pizza and beer with my girlfriend. I don't want to sacrifice my social life for the sake of a game a week. Saturday
I spent most of the day going for a long bike-ride. &nbsp;I tried fixing some issues, which was mainly fruitless. &nbsp;I tried forcing the canvas to have focus as soon as the webpage loads so that it immediately can accept keyboard input. &nbsp;It works most of the time, however it doesn't work when the browser is first loaded, which is quite common when debugging using the Dart Editor. &nbsp;I tried fixing some wonky collision behavior between the ball and paddle. &nbsp;I made it a little better, but it's still nowhere near perfect. &nbsp;I also added in simple scaling to the Transformcomponent to allow easily re-scaling the paddles. &nbsp;It works well right now for axis-aligned 2D shapes, but it may have to be re-visited in the future to be more robust. &nbsp;Also, scaling currently only scales the rendering mesh, not the collider mesh. Sunday
I spent the afternoon at a friend's house playing various board games. &nbsp;I set up a scoring system with normal HTML used for displaying the score. &nbsp;I implemented a crude AI system so that you are playing against the computer. &nbsp;This brought to light a big bug with the collision system. &nbsp;I had to put in a hack to alleviate that. &nbsp;I also added in a random element to the ball velocity after a player scores. &nbsp;I then adjusted collision between the ball &amp; paddles with the screen edges. &nbsp;Finally, I deployed the game to my server. <br> <a data-tooltip-position="top" aria-label="http://re-creationstudios.com/gaw/1/" rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/gaw/1/" target="_self">Play the game here!</a> Final Thoughts
I was surprised by how little time I actually had put into the game over the past week. &nbsp;It is an incredibly difficult task balancing my time between my full time job, my bike-riding, my girlfriend, my friends, etc. &nbsp;I had hoped to accomplish much, much more. I have an entire list of features I had hoped to put in, including:
Networking- Allow multiple players across various web browsers
Different Paddle Shapes - Not just | shapes, but &lt; and &gt; and curved surfaces
Increasing Speeds - Make the ball go faster as the score increased
Varying Angles - Make the angles of the ball not always 90 degree bounces
Sound - Simplistic sounds to indicate when the ball hits a paddle
Circle Ball- Use an actual circle mesh for the ball instead of a square
Scale Properly - Currently the game doesn't scale the collision zones with the visible window In the end, I did get a working (albeit simplistic) version of Pong up and running via Dart and WebGL. &nbsp;I suppose that's as good of a first Game A Week as I can get. &nbsp;I'm already looking forward to the next game! (Whatever it may be.)]]></description><link>https://glitchenzo.github.io/2014-03-09-game-a-week-1-pong.html</link><guid isPermaLink="false">2014-03-09 - Game A Week - 1 - Pong.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:37:08 GMT</pubDate></item><item><title><![CDATA[2012-07-23 - Unity GPU Noise 1.3 Released]]></title><description><![CDATA[2012-07-23As you can tell from the title, I've been able to release several updates for GPU Noise since my last post. I borrowed a MacBook from one of my friends and installed Unity on it. &nbsp;That allowed me to quickly port all of the noise functions to GLSL and ensure they all worked on Mac. &nbsp;However, I was still having issues with the noise functions on my Android devices. &nbsp;Unity on Android is actually incredibly unhelpful in this regard. &nbsp;It doesn't report any errors or anything. The shader simply fails and runs a fallback shader. I decided to create a WebGL test page using the same GLSL code since WebGL uses OpenGL ES 2.0 (the same as mobile devices). &nbsp;I quickly found out (and remembered, as I've posted about this in the past) that OpenGL ES doesn't allow variables in for loop expressions. &nbsp;It must be a constant expression (i.e. loop a fixed number of times). I made a mobile port of my GLSL noise that forced all summation functions (fBm, Turbulence, and Ridged) to loop 8 times. &nbsp;Even though this changed allowed the code to work properly in WebGL, it was stillnot working on Android. I then took a different direction and tried writing a straight Java test app for Android. &nbsp;I found out there is a major bug where Android won't report the shader compilation errors. &nbsp;It just gives you an empty string. &nbsp;Not very helpful. &nbsp;I managed to get the shader to compile, but I ran into more OpenGL issues due to mismatched vertex attributes. &nbsp;I cast aside the example in frustration. Someone who purchased a copy of GPU Noise let me know that Xcode on Mac actually reports shader compilation errors, so I begged a coworker of mine who has a Mac, Unity, and an iOS developer license to give it a try. &nbsp;As soon as he deployed it to his iPad, we saw the error that has been eluding me this entire time. &nbsp;There was a&nbsp;"Uniform precision mismatch" with some of my variables. &nbsp;I did some investigation and found out that vertex shaders in GLSL default to high precision while pixel shaders default to medium. &nbsp;I hard coded my vertex shaders to use medium precision and now almost all of my functions work on Android! &nbsp;I say almost because all of the Voronoi 3D Displacement functions seem to peg out the CPU (as before) and cause the device to freeze and crash. &nbsp;I think they're just too resource intensive to use on current mobile devices (they work on Windows and Mac just fine). &nbsp;At least the 2D Animated Voronoi functions all work on Android. Related to an earlier post, I still need to figure out why a Tegra 3 sucks so much. &nbsp;It's not just speed, but also the rendering quality. &nbsp;Here are a few&nbsp;comparisons&nbsp;for example. <a data-tooltip-position="top" aria-label="http://3.bp.blogspot.com/-ADp4XNnd1u4/UA4XCaBEltI/AAAAAAAAG_M/Yd9SwOZ4s0o/s1600/2012-07-23_18-51-45.jpg" rel="noopener nofollow" class="external-link is-unresolved" href="http://3.bp.blogspot.com/-ADp4XNnd1u4/UA4XCaBEltI/AAAAAAAAG_M/Yd9SwOZ4s0o/s1600/2012-07-23_18-51-45.jpg" target="_self"></a><img src="http://3.bp.blogspot.com/-ADp4XNnd1u4/UA4XCaBEltI/AAAAAAAAG_M/Yd9SwOZ4s0o/s320/2012-07-23_18-51-45.jpg" referrerpolicy="no-referrer" target="_self" class="is-unresolved">EVO 3D<br><a data-tooltip-position="top" aria-label="http://1.bp.blogspot.com/-DO07y44Nstc/UA4XVy59mkI/AAAAAAAAG_U/Dh8TshbA0G4/s1600/Screenshot_2012-07-23-18-55-52.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://1.bp.blogspot.com/-DO07y44Nstc/UA4XVy59mkI/AAAAAAAAG_U/Dh8TshbA0G4/s1600/Screenshot_2012-07-23-18-55-52.png" target="_self"></a><img src="http://1.bp.blogspot.com/-DO07y44Nstc/UA4XVy59mkI/AAAAAAAAG_U/Dh8TshbA0G4/s320/Screenshot_2012-07-23-18-55-52.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved">Transformer Prime<br><a data-tooltip-position="top" aria-label="http://2.bp.blogspot.com/-qXw8IQHNopQ/UA4XdPDvpxI/AAAAAAAAG_c/6obHuJXpAoQ/s1600/2012-07-23_18-51-37.jpg" rel="noopener nofollow" class="external-link is-unresolved" href="http://2.bp.blogspot.com/-qXw8IQHNopQ/UA4XdPDvpxI/AAAAAAAAG_c/6obHuJXpAoQ/s1600/2012-07-23_18-51-37.jpg" target="_self"></a><img src="http://2.bp.blogspot.com/-qXw8IQHNopQ/UA4XdPDvpxI/AAAAAAAAG_c/6obHuJXpAoQ/s320/2012-07-23_18-51-37.jpg" referrerpolicy="no-referrer" target="_self" class="is-unresolved">EVO 3D<br><a data-tooltip-position="top" aria-label="http://3.bp.blogspot.com/-lwRnlbHPaDY/UA4Xl5vEstI/AAAAAAAAG_k/eqrFv_d1DfQ/s1600/Screenshot_2012-07-23-18-55-37.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://3.bp.blogspot.com/-lwRnlbHPaDY/UA4Xl5vEstI/AAAAAAAAG_k/eqrFv_d1DfQ/s1600/Screenshot_2012-07-23-18-55-37.png" target="_self"></a><img src="http://3.bp.blogspot.com/-lwRnlbHPaDY/UA4Xl5vEstI/AAAAAAAAG_k/eqrFv_d1DfQ/s320/Screenshot_2012-07-23-18-55-37.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved">Transformer PrimeAs you can see, the Transformer Prime looks horrendous! &nbsp;I'm not sure what's causing such terrible visual artifacts. &nbsp;Hopefully someone online has an idea.Until next time...]]></description><link>https://glitchenzo.github.io/2012-07-23-unity-gpu-noise-1.3-released.html</link><guid isPermaLink="false">2012-07-23 - Unity GPU Noise 1.3 Released.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:37:07 GMT</pubDate><enclosure url="http://3.bp.blogspot.com/-ADp4XNnd1u4/UA4XCaBEltI/AAAAAAAAG_M/Yd9SwOZ4s0o/s320/2012-07-23_18-51-45.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src="http://3.bp.blogspot.com/-ADp4XNnd1u4/UA4XCaBEltI/AAAAAAAAG_M/Yd9SwOZ4s0o/s320/2012-07-23_18-51-45.jpg"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2012-06-28 - Unity GPU Noise 1.0 Released]]></title><description><![CDATA[2012-06-28GPU Noise has finally been released on the Unity Asset Store! &nbsp;<a data-tooltip-position="top" aria-label="http://u3d.as/content/re-creation-studios/gpu-noise/34Z" rel="noopener nofollow" class="external-link is-unresolved" href="http://u3d.as/content/re-creation-studios/gpu-noise/34Z" target="_self">Check it out here</a>! As you can tell from all of the past posts, this has been a long road. &nbsp;It's still not perfect though. &nbsp;It works great on Windows, but the reviewers let me know that it has some issues on Macs. &nbsp;I borrowed my friend's Mac for a little bit and found out that the issue is most likely due to the cross compiler that Unity uses to convert Cg code into GLSL. (It was creating multiple variables with the same name.) I decided to directly port the Cg code to GLSL, but it's been a rough process since the Windows version of Unity doesn't compile GLSL at all. &nbsp;This means that you don't get any errors or feedback at all to let you know if you wrote some code incorrectly. &nbsp;I had to write code, deploy to my Android phone, see if it works, and repeat. &nbsp;Over and over and over. &nbsp;Painful. &nbsp;I'm thinking about picking up a cheap Mac (gasp!) just to have something that can compile GLSL code and give me feedback. &nbsp;I'm hoping porting to GLSL fixes the problems on Mac, but I have no way to know for certain until I actually do it. As usual, I'll be tracking my progress here.]]></description><link>https://glitchenzo.github.io/2012-06-28-unity-gpu-noise-1.0-released.html</link><guid isPermaLink="false">2012-06-28 - Unity GPU Noise 1.0 Released.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:37:06 GMT</pubDate></item><item><title><![CDATA[2012-06-22 - Unity GPU Noise (Part 5)]]></title><description><![CDATA[2012-06-22And somehow 9 months have passed... To be honest, I had a lot going on in my life since my last post. &nbsp;My development laptop got stolen, my work laptop's hard drive failed, and other, more personal, things happened, which I won't get into. &nbsp;As a result of the theft, I lost some of my work. &nbsp;Not too much, just a week or two, but enough to make me unmotivated to return to my project and do the same work again. About a week ago, I decided to finally dive back into it all. &nbsp;I installed the latest Unity on my desktop and dusted off my old USB flash drive with the old copy of GPU Noise on it. &nbsp;I decided to redo almost everything in the project to base it off of the texture-less implementations of noise in order to make it as easy and cross-platform as possible to implement in Unity (and hand off to other developers). It was pretty smooth going, for the most part. &nbsp;Based on my prior experience, I knew what I was doing. &nbsp;The only big problem I ran into was trying to port&nbsp;<a data-tooltip-position="top" aria-label="http://www.opengl.org/sdk/docs/manglsl/xhtml/mod.xml" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.opengl.org/sdk/docs/manglsl/xhtml/mod.xml" target="_self">mod</a>&nbsp;from GLSL over to Cg. &nbsp;I first used&nbsp;<a data-tooltip-position="top" aria-label="http://msdn.microsoft.com/en-us/library/windows/desktop/bb509601%28v=vs.85%29.aspx" rel="noopener nofollow" class="external-link is-unresolved" href="http://msdn.microsoft.com/en-us/library/windows/desktop/bb509601%28v=vs.85%29.aspx" target="_self">fmod</a>&nbsp;in Cg, but that made the results all messed up. &nbsp;I finally found&nbsp;<a data-tooltip-position="top" aria-label="http://stackoverflow.com/questions/7610631/glsl-mod-vs-hlsl-fmod" rel="noopener nofollow" class="external-link is-unresolved" href="http://stackoverflow.com/questions/7610631/glsl-mod-vs-hlsl-fmod" target="_self">this answer</a>&nbsp;that explains the problem and how to fix it. &nbsp;Once I implemented my own mod function in the same manner as GLSL's, everything was fine again. Regarding the Android front, I'm not sure if it was something that got fixed in the Cg compiler between Unity versions, but all of my noise functions seemed to run on Android, for the most part. &nbsp;The only issue I ran into is when I tried doing the 3D Voronoi displacement, the functions consumed too much processing and crashed the device. &nbsp;This is because the displacement example has to call the function twice, which is a lot of processing. <br> Another Android "issue" I had was the performance of my devices. &nbsp;I have an HTC EVO 3D and an ASUS Transformer Prime. &nbsp;My EVO got about 47 FPS running the simple Perlin displacement. &nbsp;I assumed the Transformer Prime would do better, but it only got 9 FPS. &nbsp;Apparently the Adreno 220 outperforms the Tegra 3. &nbsp;I ran some other benchmarks which came to the same conclusion. &nbsp;I even looked at the Unity&nbsp;<a data-tooltip-position="top" aria-label="http://unity3d.com/support/documentation/ScriptReference/SystemInfo.html" rel="noopener nofollow" class="external-link is-unresolved" href="http://unity3d.com/support/documentation/ScriptReference/SystemInfo.html" target="_self">SystemInfo</a>&nbsp;objects on both devices and I was really surprised to see the that&nbsp;Transformer&nbsp;Prime only has 61 MB of video memory while the EVO 3D has 216 MB. &nbsp;I was greatly disappointed to see how poorly my Tegra 3 tablet performed. &nbsp;I'll continue to investigate the issue in order to see if there's something I can do to improve its performance. Just tonight I finally submitted my GPU Noise project to the Unity Asset Store. &nbsp;If all goes well, it should be appearing on the store in a week or less. &nbsp;Here's hoping! <br> <a data-tooltip-position="top" aria-label="http://re-creationstudios.com/unity/noise/" rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/unity/noise/" target="_self">Check out the latest demo!</a> Until next time!]]></description><link>https://glitchenzo.github.io/2012-06-22-unity-gpu-noise-(part-5).html</link><guid isPermaLink="false">2012-06-22 - Unity GPU Noise (Part 5).md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:37:06 GMT</pubDate></item><item><title><![CDATA[2011-09-25 - Unity GPU Noise (Part 4)]]></title><description><![CDATA[2011-09-25Well, I'm a stubborn individual, so I continued working on the Android version of GPU Noise. I have actually been successful and made a little progress. Not without encountering more issues, of course. First, I must say that GLSL hatesconditional branches (including forloops). The main reason why my example scene wasn't running on Android was because I used an if-else tree in my shader (<a data-tooltip-position="top" aria-label="http://recreationstudios.blogspot.com/2011/08/unity-gpu-noise-part-2.html" rel="noopener nofollow" class="external-link is-unresolved" href="http://recreationstudios.blogspot.com/2011/08/unity-gpu-noise-part-2.html" target="_self">previously a switch statement</a>) to select the noise type based upon a variable that was set on the Material by the C# side. While this works perfectly fine on Windows and DirectX, it's not the case for Android. I had to separate each noise type into its own shader/material and then have logic on the C# side to select the correct Material.This is where things start to get strange. The basic Perlin noise function worked fine (as well as Voronoi), but none of my summations (like fBm) worked. They are simply forloops that call the Perlin function repeatedly. For testing, instead of having it take a variable for the number of times to loop, I hard-coded it to 4 octaves. This didn't work either. However, if I manually unrolled the for loop to have the code repeated 4 times, it finally worked. <br>Now, a little aside about my implementation. In order to speed up the noise functions, I precompute some values and store them in various textures which the noise functions then sample from. I wanted the noise functions to be accessible in both a vertex shader and pixel shader, so I used the <a data-tooltip-position="top" aria-label="http://msdn.microsoft.com/en-us/library/bb509680%28v=vs.85%29.aspx" rel="noopener nofollow" class="external-link is-unresolved" href="http://msdn.microsoft.com/en-us/library/bb509680%28v=vs.85%29.aspx" target="_self">tex2Dlod</a>function to sample the textures. This is because tex2Dlod is the only permitted function for sampling from a vertex shader. (Automatic mip-mapping doesn't work in a vertex shader, so the developer must specify the mip-map level to use.)<br>Thinking that using tex2Dlod was somehow causing my forloop problems, I decided to look into a different implementation. I found a <a data-tooltip-position="top" aria-label="https://github.com/ashima/webgl-noise/wiki" rel="noopener nofollow" class="external-link is-unresolved" href="https://github.com/ashima/webgl-noise/wiki" target="_self">GLSL implementation of Perlin noise</a> that didn't use any arrays or texture lookups (amazing!), thus making it highly cross-platform. I promptly ported it over to Cg in Unity. I was dismayed to discover that it yielded really terrible looking visual artifacts. The problem was even worse when using any summation. I quickly made a <a data-tooltip-position="top" aria-label="http://re-creationstudios.com/webgl/noise/" rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/webgl/noise/" target="_self">test scene in WebGL</a> to test the shader in its original GLSL. Here, as you can see, it all worked perfectly. Going back to the Cg port, I went over line by line to see where it was failing. I first tried replacing the optimized "hacks" he used in place of modulus. That didn't fix it. Then, I looked at his inverse square root function. If I replaced his function with a call to <a data-tooltip-position="top" aria-label="http://msdn.microsoft.com/en-us/library/windows/desktop/bb509643%28v=vs.85%29.aspx" rel="noopener nofollow" class="external-link is-unresolved" href="http://msdn.microsoft.com/en-us/library/windows/desktop/bb509643%28v=vs.85%29.aspx" target="_self">rsqrt</a>, the artifacts disappeared!Armed with a new implementation, I tried running my test scene on Android again. And again, my summations failed. I happened to discover that the summations only worked when given certain octaves (forloop counter). This is the strangest thing of all. If I gave it 1, it worked. If I gave it 2 through 8, it failed. If I gave it 9 or greater, it worked.I must say, I'm entirely perplexed. I have all of my noise functions working on an Android device now, but only with certain ranges on the summations. Why doesn't it work with 4 octaves when it works with 10? Does anyone have any insight into this strange issue?]]></description><link>https://glitchenzo.github.io/2011-09-25-unity-gpu-noise-(part-4).html</link><guid isPermaLink="false">2011-09-25 - Unity GPU Noise (Part 4).md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:37:05 GMT</pubDate></item><item><title><![CDATA[2011-08-18 - Unity GPU Noise (Part 2)]]></title><description><![CDATA[2011-08-18Sheesh! Yet another 5 months have passed by!When I was creating the demo of GPU Noise in Unity, I kept getting a "function 'tex2Dlod' not supported in this profile" error. I couldn't figure out why except that it was an OpenGL issue. So, I simply forced my shaders to exclude OpenGL and OpenGL ES renderers (<a href="https://glitchenzo.github.io?query=tag:pragma" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#pragma">#pragma</a> exclude_renderers opengl gles). Obviously this is not the best solution, so I decided to dive into it again.<br>It turns out that the error goes away if you instead force the shader to compile to GLSL (<a href="https://glitchenzo.github.io?query=tag:pragma" class="tag is-unresolved" target="_self" rel="noopener nofollow" data-href="#pragma">#pragma</a> glsl). I have no idea why this fixes the problem, since it was an OpenGL issue in the first place, but whatever. Forcing the shaders to compile to GLSL brought up two other issues that I had to fix. GLSL doesn't support default parameters (Cg and HLSL do). This means that I had to go duplicate all of my shader functions that used them, which were a lot. GLSL doesn't support the switch statement. I had to go manually unroll my switch statements to be if-else trees. This one really confused me because all of the GLSL documentation seems to indicate that switch is indeed in the language, so this might just be a Unity issue. You can check out the updated demo here:<br><a rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/unity/noise/" target="_self">http://re-creationstudios.com/unity/noise/</a>Hopefully it works on Mac now, but I haven't been able to test it out yet. Feel free to let me know!]]></description><link>https://glitchenzo.github.io/2011-08-18-unity-gpu-noise-(part-2).html</link><guid isPermaLink="false">2011-08-18 - Unity GPU Noise (Part 2).md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:59 GMT</pubDate></item><item><title><![CDATA[2011-03-08 - Unity GPU Noise  Unity Issues]]></title><description><![CDATA[2011-03-08It's amazing how much time keeps slipping by without any posts. Another 5 months have somehow passed since my last post. That means that I have only written 2 posts in the past year! I need to get back to my good update schedule. GPU Noise in Unity First, I'd like to show a simple demo I made of various types of noise on the GPU in Unity. You can check out the live demo on the web by clicking on the image below. You need to have a Shader Model 3.0 GPU in order to run the demo. <a data-tooltip-position="top" aria-label="http://re-creationstudios.com/unity/noise/" rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/unity/noise/" target="_self"></a><img src="http://1.bp.blogspot.com/-hpkESpl8vWE/TXavIQlzvAI/AAAAAAAAFlA/lDE24WNJ7Ds/s400/noise.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> As you can see, there are 9 different types of noise in the demo and they are all implemented in Cg shaders on the GPU. <br><a data-tooltip-position="top" aria-label="http://en.wikipedia.org/wiki/Perlin_noise" rel="noopener nofollow" class="external-link is-unresolved" href="http://en.wikipedia.org/wiki/Perlin_noise" target="_self">Perlin</a> - "Standard" Perlin Noise (1 octave)
<br><a data-tooltip-position="top" aria-label="http://en.wikipedia.org/wiki/Fractional_Brownian_motion" rel="noopener nofollow" class="external-link is-unresolved" href="http://en.wikipedia.org/wiki/Fractional_Brownian_motion" target="_self">fBm</a> - fractional Brownian motion summation of Perlin Noise (8 octaves)
Turbulence - fBm variation that sums the absolute value of the noise result (8 octaves)
Ridged - fBm variation from the book "Texturing and Modeling: A Procedural Approach" that performs a special ridge function on the noise result (8 octaves)
<br><a data-tooltip-position="top" aria-label="http://en.wikipedia.org/wiki/Voronoi_diagram" rel="noopener nofollow" class="external-link is-unresolved" href="http://en.wikipedia.org/wiki/Voronoi_diagram" target="_self"><em></em></a>Voronoi (F1) - A "noise" type that uses a field of random 3D points and determines the distance to the closest point
F2 - Voronoi that determines the distance to the secondclosest point
F2 - F1 - Voronoi that determines the difference between the first and second closest points
(F1 + F2) / 2 - Voronoi that averages the distance between the two closest points
<br><a data-tooltip-position="top" aria-label="http://www.gamedev.net/blog/73/entry-1832259-gpu-terrain-generation-cell-noise-rivers-crater/" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.gamedev.net/blog/73/entry-1832259-gpu-terrain-generation-cell-noise-rivers-crater/" target="_self">Crater</a> - Voronoi variation that makes crater-like structures
Have fun messing around with the sliders and seeing how the noise can be manipulated on the fly! Unity IssuesAfter completing the GPU noise demo in Unity (it's actually been done since November), I started proceeding with implementing a procedural planet generator in Unity. It quickly introduced me to some of the issues and limitations that Unity has.
<br><a data-tooltip-position="top" aria-label="http://answers.unity3d.com/questions/29948/disable-frustum-culling" rel="noopener nofollow" class="external-link is-unresolved" href="http://answers.unity3d.com/questions/29948/disable-frustum-culling" target="_self">Cannot disable/control view frustum culling</a>.
This is the worst issue I ran into. The way I implement the planet is to have a small cube that is "blown out" to form a sphere and then offset with noise all on the GPU ( la displacement mapping). Unity has a camera system that determines which objects are inside each camera's view frustum and automatically culls (doesn't draw) any objects that are outside of the view frustum. The problem is, while the small cube is not in the view frustum, the final displaced planet is in the frustum. This causes the planet to suddenly stop rendering if the camera is pointed a certain direction. I tried several fixes such as blowing the cube up to be the same size of the planet and forcing the view angle to be the maximum value (179 degrees) when Unity does the frustum check. Neither of these got rid of the problem entirely and just reduced how much it happened. In order to fix it, game developers should have control over which objects should be culled, or be able to disable frustum culling entirely.
<br><a data-tooltip-position="top" aria-label="http://answers.unity3d.com/questions/30420/run-script-in-edit-mode-when-paused" rel="noopener nofollow" class="external-link is-unresolved" href="http://answers.unity3d.com/questions/30420/run-script-in-edit-mode-when-paused" target="_self">Cannot run editor scripts when paused</a>.
This problem stems from another problem in Unity. Unity doesn't send the View matrix (by design) or Projection matrix (current bug) to the shaders, so you need a script to send them manually. Because of this, you need to have this script continually updating the shader variables even when the game is paused. If they are not updated then the objects render in the same place on the screen no matter where you move the camera. This is a horrible problem with no real fix.
<br><a data-tooltip-position="top" aria-label="http://answers.unity3d.com/questions/30357/create-a-custom-collider" rel="noopener nofollow" class="external-link is-unresolved" href="http://answers.unity3d.com/questions/30357/create-a-custom-collider" target="_self">Cannot create a custom collider</a>.
Unity provides no simple way to create your own physics collider object. You can inherit from their built-in Collider class, but you cannot override any methods inside of it. As you can see from the link, I came up with a work-around for what I specifically was trying to accomplish: make a spherical planet collider. It is very similar to what I did in Bullet in the past.
<br><a data-tooltip-position="top" aria-label="http://forum.unity3d.com/threads/66153-Writing-depth-value-in-fragment-program" rel="noopener nofollow" class="external-link is-unresolved" href="http://forum.unity3d.com/threads/66153-Writing-depth-value-in-fragment-program" target="_self">Cannot write depth in pixel shader</a>. (<a data-tooltip-position="top" aria-label="http://www.ogre3d.org/forums/viewtopic.php?p=274238" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.ogre3d.org/forums/viewtopic.php?p=274238" target="_self">Also explained here</a>.)
I tried implementing a logarithmic depth buffer, but I was greeted with a Cg compilation error when trying to write to the depth register. This is actually a bug in the Cg compiler. It's been fixed in the compiler, but Unity is still using an old version of the compiler which has the bug. I need to test the latest releases of Unity to see if this is still a problem.
]]></description><link>https://glitchenzo.github.io/2011-03-08-unity-gpu-noise-unity-issues.html</link><guid isPermaLink="false">2011-03-08 - Unity GPU Noise  Unity Issues.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:58 GMT</pubDate><enclosure url="http://1.bp.blogspot.com/-hpkESpl8vWE/TXavIQlzvAI/AAAAAAAAFlA/lDE24WNJ7Ds/s400/noise.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://1.bp.blogspot.com/-hpkESpl8vWE/TXavIQlzvAI/AAAAAAAAFlA/lDE24WNJ7Ds/s400/noise.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2010-11-15 - Update  Unity]]></title><description><![CDATA[2010-11-15Wow! I can't really believe it's been 7 months (exactly!) since I last posted an entry here. I wish I had something to show, but sadly I do not. To be honest, I have been all over the place with my development. I experimented with a number of different things, but nothing for an extended period of time. I'm hoping to change that soon though. More on that later, first a list of the things I was working on: Shadow Mapping
I had actually never done any shadow mapping programming before, so it was more of a learning experience in understanding the concept and what is required. I implemented a simple demo in SlimDX/DirectX 11 and posted a video of it on YouTube, but it really is nothing exciting. Standard, run of the mill, shadow mapping. No fancy tricks in the implementation. Parallel City Generation
I pulled out the old procedural city generator code I blogged about before and updated and refactored the road generator to be able to run in parallel. This allowed me to draw the roads as they were being created. I thought it was pretty cool looking. My goal was to parallelize it to the point where I could implement it as a compute shader, but I couldn't seem to get it to that point. So, I kind of gave up on it. Bullet Physics
I decided to go back and start messing around with physics again, and I used XNA and BulletSharp this time. I was working on an idea that I've had brewing in the back of my brain for quite awhile. I made some decent progress and was quite happy. However, I started thinking about how I was essentially writing my own game engine (terrain, lighting, shadowing, physics integration). Plus, looking at the target platforms for XNA (Xbox 360, Windows Desktop, Windows Phone), I started wondering if that was best for me. So, that led me to the next item. Unity
For several months Unity had been looking appealing to me. Two of the biggest pulls for me were C# scripting (via the Mono Framework) and PhysX integration. The wide array of supported platforms was also a huge plus (Mac, Windows, iPhone, iPad, Web). When they announced support for Android as well, I was "sold" in a manner of speaking (as I have an Android phone myself). So, I installed the free version of Unity and tried to see if I could implement the functionality I had already implemented via BulletSharp and XNA inside of Unity scripting itself. One weekend later, I had accomplished that and more! I'll be honest, Unity is far from the perfect engine. It severely limits you due to the wide range of hardware specs that it runs on. Don't expect to be doing any tessellation or compute shaders here. Heck, it doesn't even support geometry shaders! However, it does seem to be a very well organized engine with good documentation on their webpage and a component based system that I love. I like it enough to at least fiddle around with it some more over the next couple of months. An added bonus is that my prototypes can be deployed to my server which means you (the reader) can run them in your browser without installing the them. Expect to see a Perlin Noise example soon. :-) That really has become my "Hello World" program for testing different graphics APIs. A final note I'd like to leave here is regarding some other "big" game engines. I was slightly surprised last week to hear not just one, but two game engines have essentially "imploded". Both Torque and Gamebryo are closing up shop and looking for buyers. That leaves Unity looking even stronger. Until next time!]]></description><link>https://glitchenzo.github.io/2010-11-15-update-unity.html</link><guid isPermaLink="false">2010-11-15 - Update  Unity.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:57 GMT</pubDate></item><item><title><![CDATA[2010-04-15 - Spherical Terrain Physics]]></title><description><![CDATA[2010-04-15For quite a long while I have been trying to figure out how exactly to do collision detection on my procedurally generated, tessellated, spherical terrain. The problem lies with the fact that terrain itself doesn't really exist until the GPU. I generate a simple spherical mesh on the CPU and then send it to the GPU to draw. Once there it is tessellated based upon the distance to the camera and then it is displaced via a summation of Perlin Noise. Obviously this makes it very hard to do collision detection on the CPU side. Many physics engines support a special heightmap object for terrain, but they all assume the terrain is on a plane (usually the XZ) with one axis being the displacement axis (usually the Y). Of course that wouldn't work for spherical terrain. Most physics engines also have a generic triangle mesh object. However these are usually meant to be static meshes and therefore are hard to tessellate. It would require destroying and recreating a mesh on the fly, which would be rather slow and wasteful. What I really needed was the ability to create a collision shape that was defined by an equation (the Perlin sum in my case). In the past I have always used PhysX, but since it is closed source I decided to try this out in another physics engine. I hopped onto the Bullet forums and posed the question. I was told that it should be possible if I created a new shape object that inherited from the base concave object and overrode its ProcessAllTriangles() method to use the equation. So, I went and did exactly that. Lo and behold it worked! First, I created a shape called btSphericalTerrainShape which inherits from btConcaveShape. It takes 3 parameters to setup: The center point of the terrain, the radius of the terrain (including the maximum offset of the terrain) which is used for the bounding box, and a function pointer that points to a function that defines the terrain's equation. btSphericalTerrainShape(const btVector3&amp; center, btScalar radius, btVector3 (*calcVertex)(const btVector3&amp; position, const btVector3&amp; center));
The function pointer passes along 2 parameters: the current point being evaluated (usually one of the corners of the other object's bounding box), and the center point of the terrain. This allows the terrain to be defined by practically any method desired. For example, if you wanted to define the terrain as a simple sphere with a radius of 50, you would use the following method: btVector3 calculateTerrainVertex(const btVector3&amp; position, const btVector3&amp; center) { &nbsp;&nbsp;&nbsp; return (position - center).normalized() * 50.0f; }
If you wanted to define the terrain as a sphere with a radius of 50 that was offset by 8 octaves of Perlin Noise, you would use this method: btVector3 calculateTerrainVertex(const btVector3&amp; position, const btVector3&amp; center) { &nbsp;&nbsp;&nbsp; btVector3 normalized = (position - center).normalized(); &nbsp;&nbsp;&nbsp; double result = PerlinNoise::fBm(normalized.x(), normalized.y(), normalized.z(), 8); &nbsp;&nbsp;&nbsp; return normalized * btScalar(50.0f + result * 10.0); }
Now, for the details on the ProcessAllTriangles() method. It takes an axis aligned bounding box (AABB) for the other shape being tested and a callback that is called for each triangle that collides with that bounding box. These are the steps done in the method: Calculate the 8 corners of the AABB Calculate the midpoint of each of the 6 sides of the AABB Calculate the position of the vertex on the terrain by calling the calculateTerrainVertex function pointer Determine which of the corners of the AABB are colliding with the terrain by checking if the bounding box corners are closer to the center point than the respective terrain vertices Find which 3 sides of the AABB are closest to the terrain in order to prevent extraneous triangle processing Use the callback to process each triangle that collides For the actual implementation details, be sure to download the source code for the btSphericalTerrainShape. <a data-tooltip-position="top" aria-label="http://www.re-creationstudios.com/shared/btSphericalTerrainShape.h" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.re-creationstudios.com/shared/btSphericalTerrainShape.h" target="_self">btSphericalTerrainShape.h</a><br>
<a data-tooltip-position="top" aria-label="http://www.re-creationstudios.com/shared/btSphericalTerrainShape.cpp" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.re-creationstudios.com/shared/btSphericalTerrainShape.cpp" target="_self">btSphericalTerrainShape.cpp</a>]]></description><link>https://glitchenzo.github.io/2010-04-15-spherical-terrain-physics.html</link><guid isPermaLink="false">2010-04-15 - Spherical Terrain Physics.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:57 GMT</pubDate></item><item><title><![CDATA[2010-04-08 - Sobel Filter Compute Shader]]></title><description><![CDATA[2010-04-08Thanks to Josh Petrie, I now have the Compute Shader working with the swap chain backbuffer. I decided a good first test is to use a Compute Shader to run a Sobel Filter on an image and display the result in the backbuffer. It was all very easy to get set up. First you create a DirectX 11 swap chain, just like normal. The only difference is the Usage property of the swap chain has an additional flag set which is (Usage)1024 and it represents UnorderedAccess. This allows the backbuffer to be used as an output UAV in the Compute Shader. RenderForm form = new RenderForm("SlimDX - Sobel Filter Compute Shader"); form.ClientSize = new Size(1024, 1024); SwapChainDescription swapChainDesc = new SwapChainDescription() { &nbsp;&nbsp;&nbsp; BufferCount = 1, &nbsp;&nbsp;&nbsp; Flags = SwapChainFlags.None, &nbsp;&nbsp;&nbsp; IsWindowed = true, &nbsp;&nbsp;&nbsp; ModeDescription = new ModeDescription(form.ClientSize.Width, form.ClientSize.Height, new Rational(60, 1), Format.R8G8B8A8_UNorm), &nbsp;&nbsp;&nbsp; OutputHandle = form.Handle, &nbsp;&nbsp;&nbsp; SampleDescription = new SampleDescription(1, 0), &nbsp;&nbsp;&nbsp; SwapEffect = SwapEffect.Discard, &nbsp;&nbsp;&nbsp; //(Usage)1024 = Usage.UnorderedAccess &nbsp;&nbsp;&nbsp; Usage = Usage.RenderTargetOutput | (Usage)1024 }; Device device; SwapChain swapChain; Device.CreateWithSwapChain(null, DriverType.Hardware, DeviceCreationFlags.Debug, swapChainDesc, out device, out swapChain);
The rest of the setup is standard stuff. You grab the backbuffer texture, load the image to run the filter on, and load/compile the Compute Shader. Texture2D backBuffer = Texture2D.FromSwapChain&lt;Texture2D&gt;(swapChain, 0); RenderTargetView renderView = new RenderTargetView(device, backBuffer); Texture2D flower = Texture2D.FromFile(device, "flower.jpg"); ShaderResourceView resourceView = new ShaderResourceView(device, flower); ComputeShader compute = Helper.LoadComputeShader(device, "Sobel.hlsl", "main"); UnorderedAccessView computeResult = new UnorderedAccessView(device, backBuffer);
The "render" loop doesn't contain any actual rendering. It sets up the render target and viewport like normal, but then it sets the Compute Shader and runs it. After the Compute Shader is ran, the swap chain is told to present the backbuffer, which now contains the Compute Shader output. device.ImmediateContext.OutputMerger.SetTargets(renderView); device.ImmediateContext.Rasterizer.SetViewports(new Viewport(0, 0, form.ClientSize.Width, form.ClientSize.Height, 0.0f, 1.0f)); MessagePump.Run(form, () =&gt; { &nbsp;&nbsp;&nbsp; device.ImmediateContext.ClearRenderTargetView(renderView, Color.Black); &nbsp;&nbsp;&nbsp; device.ImmediateContext.ComputeShader.Set(compute); &nbsp;&nbsp;&nbsp; device.ImmediateContext.ComputeShader.SetShaderResource(resourceView, 0); &nbsp;&nbsp;&nbsp; device.ImmediateContext.ComputeShader.SetUnorderedAccessView(computeResult, 0); &nbsp;&nbsp;&nbsp; device.ImmediateContext.ComputeShader.SetConstantBuffer(constantBuffer, 0); &nbsp;&nbsp;&nbsp; device.ImmediateContext.Dispatch(32, 32, 1); &nbsp;&nbsp;&nbsp; swapChain.Present(0, PresentFlags.None); });
That's it for the CPU side, now let's look at the GPU side. It's a standard Sobel Filter that only has an input texture and an output texture. The output can either be the Sobel result alone, or it can be the Sobel result laid over the input texture. Texture2D Input : register(t0);RWTexture2D Output : register(u0);[numthreads(32, 32, 1)]void main( uint3 threadID : SV_DispatchThreadID ){ float threshold = 0.20f; bool overlay = true; // Sample neighbor pixels // 00 01 02 // 10 __ 12 // 20 21 22 float s00 = Input[threadID.xy + float2(-1, -1)].r; float s01 = Input[threadID.xy + float2( 0, -1)].r; float s02 = Input[threadID.xy + float2( 1, -1)].r; float s10 = Input[threadID.xy + float2(-1, 0)].r; float s12 = Input[threadID.xy + float2( 1, 0)].r; float s20 = Input[threadID.xy + float2(-1, 1)].r; float s21 = Input[threadID.xy + float2( 0, 1)].r; float s22 = Input[threadID.xy + float2( 1, 1)].r; float sobelX = s00 + 2 * s10 + s20 - s02 - 2 * s12 - s22; float sobelY = s00 + 2 * s01 + s02 - s20 - 2 * s21 - s22; float edgeSqr = (sobelX * sobelX + sobelY * sobelY); float result = 1.0 - (edgeSqr &gt; threshold * threshold); //white background, black lines Output[threadID.xy] = result; if (overlay &amp;&amp; result != 0.0) Output[threadID.xy] = Input[threadID.xy]; } That's it! I already improved the code so that the threshold float and overlay boolean are in a constant buffer that is set on the CPU side, but I figured I'd keep the code posted here as simple as I could. Here was my input image:
<a data-tooltip-position="top" aria-label="http://3.bp.blogspot.com/_hGl_uKJzpS0/S77C_gLguGI/AAAAAAAAFeI/gzdFbr1Z_cA/s1600/flower.jpg" rel="noopener nofollow" class="external-link is-unresolved" href="http://3.bp.blogspot.com/_hGl_uKJzpS0/S77C_gLguGI/AAAAAAAAFeI/gzdFbr1Z_cA/s1600/flower.jpg" target="_self"></a><img src="http://3.bp.blogspot.com/_hGl_uKJzpS0/S77C_gLguGI/AAAAAAAAFeI/gzdFbr1Z_cA/s400/flower.jpg" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> And here is the the output image (input + Sobel result overlay):<br>
<a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/_hGl_uKJzpS0/S77DYn8VkFI/AAAAAAAAFeQ/i9oSo1_n_gc/s1600/flower_sobel.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/_hGl_uKJzpS0/S77DYn8VkFI/AAAAAAAAFeQ/i9oSo1_n_gc/s1600/flower_sobel.png" target="_self"></a><img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/S77DYn8VkFI/AAAAAAAAFeQ/i9oSo1_n_gc/s400/flower_sobel.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> Nothing too spectacular, but the main focus was the Compute Shader + backbuffer, not the actual Sobel Filter. Enjoy! <br>By the way, you may have noticed that my C# code snippets now use the same syntax highlighting as Visual Studio. I installed the <a data-tooltip-position="top" aria-label="http://copysourceashtml.codeplex.com/" rel="noopener nofollow" class="external-link is-unresolved" href="http://copysourceashtml.codeplex.com/" target="_self">CopySourceAsHtml</a> add-on and it seems to work pretty well.]]></description><link>https://glitchenzo.github.io/2010-04-08-sobel-filter-compute-shader.html</link><guid isPermaLink="false">2010-04-08 - Sobel Filter Compute Shader.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:50 GMT</pubDate><enclosure url="http://3.bp.blogspot.com/_hGl_uKJzpS0/S77C_gLguGI/AAAAAAAAFeI/gzdFbr1Z_cA/s400/flower.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src="http://3.bp.blogspot.com/_hGl_uKJzpS0/S77C_gLguGI/AAAAAAAAFeI/gzdFbr1Z_cA/s400/flower.jpg"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2010-04-07 - SlimDX Issue]]></title><description><![CDATA[2010-04-07In my previous post I mentioned how my next goal was to use the Compute Shader to write directly to the backbuffer. Unfortunately, it appears that this is not currently possible using SlimDX. In order to write to the backbuffer, the swap chain needs to be created with an unordered access usage flag. This means that that resource can then be used as a UAV output in a Compute Shader. There are a <a data-tooltip-position="top" aria-label="http://forum.beyond3d.com/showthread.php?t=55330" rel="noopener nofollow" class="external-link is-unresolved" href="http://forum.beyond3d.com/showthread.php?t=55330" target="_self">couple</a> <a data-tooltip-position="top" aria-label="http://users.skynet.be/fquake/" rel="noopener nofollow" class="external-link is-unresolved" href="http://users.skynet.be/fquake/" target="_self">examples</a> floating around online where people have done this using the DXGI_USAGE_UNORDERED_ACCESS flag in C++ code. In SlimDX, that enumeration has been wrapped into the Usage enumeration in the DXGI namespace. However, it is missing an UnorderedAccess option. It contains all of the other ones defined in the original C++ code though. I believe it was just a mistake and accidentally missed during the update to DX11. (At least I hope it wasn't intentional!) <br>I posted an <a data-tooltip-position="top" aria-label="http://code.google.com/p/slimdx/issues/detail?id=648" rel="noopener nofollow" class="external-link is-unresolved" href="http://code.google.com/p/slimdx/issues/detail?id=648" target="_self">issue</a> on the SlimDX Google Code page, so hopefully this gets resolved.]]></description><link>https://glitchenzo.github.io/2010-04-07-slimdx-issue.html</link><guid isPermaLink="false">2010-04-07 - SlimDX Issue.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:49 GMT</pubDate></item><item><title><![CDATA[2010-04-04 - Simple Compute Shader Example]]></title><description><![CDATA[2010-04-04The other big side of DirectX 11 is the Compute Shader. I thought I would write up a very simple example along the same lines as my tessellation example. First let me say that the Compute Shader is awesome! It opens up so many possibilities. My mind is just reeling with new ideas to try out. Also I must mention that SlimDX really does a great job of minimalizing the code necessary to use the Compute Shader. This example shows how to create a Compute Shader and then use it to launch threads that simply output the thread ID to a texture. Device device = new Device(DriverType.Hardware, DeviceCreationFlags.Debug, FeatureLevel.Level_11_0); ComputeShader compute = Helper.LoadComputeShader(device, "SimpleCompute.hlsl", "main"); Texture2D uavTexture; UnorderedAccessView computeResult = Helper.CreateUnorderedAccessView(device, 1024, 1024, Format.R8G8B8A8_UNorm, out uavTexture); device.ImmediateContext.ComputeShader.Set(compute); device.ImmediateContext.ComputeShader.SetUnorderedAccessView(computeResult, 0); device.ImmediateContext.Dispatch(32, 32, 1); Texture2D.ToFile(device.ImmediateContext, uavTexture, ImageFileFormat.Png, "uav.png");
Believe it or not, but that is the entirety of my CPU code. Here is what is going on in the code: Create a feature level 11 Device, in order to use Compute Shader 5.0 Load/Compile the HLSL code into a ComputeShader object. Create a 1024x1024 UnorderedAccesdView (UAV) object which will be used to store the output. Set the ComputeShader and UAV on the device. Run the Compute Shader by calling Dispatch (32x32x1 thread groups are dispatched). Save the output texture out to disk. My HLSL code is even simpler: RWTexture2D&lt;float4&gt; Output;[numthreads(32, 32, 1)]void main( uint3 threadID : SV_DispatchThreadID ){ Output[threadID.xy] = float4(threadID.xy / 1024.0f, 0, 1);}
As you can see a RWTexture2D object is used to store the output (this is the UAV). The shader is setup to run 32x32x1 threads. This means that since the CPU is launching 32x32x1 thread groups, then there are 1024x1024x1 separate threads being run. This equates to 1 thread per pixel in the output UAV. So, in the UAV, the color is just set based upon the thread ID. This code results in the following output image:
<a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/_hGl_uKJzpS0/S7l5JcLDytI/AAAAAAAAFdw/kalnv_r9bpc/s1600/uav.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/_hGl_uKJzpS0/S7l5JcLDytI/AAAAAAAAFdw/kalnv_r9bpc/s1600/uav.png" target="_self"></a><img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/S7l5JcLDytI/AAAAAAAAFdw/kalnv_r9bpc/s400/uav.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> Quite simple, eh? But not that interesting. We could easily do something like that with a pixel shader (although we would have to rasterize a full-screen quad to do it). We should try to do something that shows the power of the compute shader; something you couldn't do in a pixel shader before. How about drawing some primitives like lines and circles? <br>For drawing lines, let's use the <a data-tooltip-position="top" aria-label="http://en.wikipedia.org/wiki/Digital_Differential_Analyzer_%28graphics_algorithm%29" rel="noopener nofollow" class="external-link is-unresolved" href="http://en.wikipedia.org/wiki/Digital_Differential_Analyzer_%28graphics_algorithm%29" target="_self">Digital Differential Analyzer</a> algorithm. It translates to HLSL very easily. void Plot(int x, int y){ Output[uint2(x, y)] = float4(0, 0, 1, 1);}void DrawLine(float2 start, float2 end){ float dydx = (end.y - start.y) / (end.x - start.x); float y = start.y; for (int x = start.x; x &lt;= end.x; x++) { Plot(x, round(y)); y = y + dydx; }}
<br>For drawing circles let's use the <a data-tooltip-position="top" aria-label="http://en.wikipedia.org/wiki/Midpoint_circle_algorithm" rel="noopener nofollow" class="external-link is-unresolved" href="http://en.wikipedia.org/wiki/Midpoint_circle_algorithm" target="_self">Midpoint Circle</a> algorithm. For brevity I won't list it here now. Then, in my Compute Shader main function, I simply add this code:
if (threadID.x == 1023 &amp;&amp; threadID.y == 1023){ DrawLine(float2(0, 0), float2(1024, 1024)); DrawLine(float2(0, 1023), float2(1023, 0)); DrawCircle(512, 512, 250); DrawCircle(0, 512, 250);} The if check is just done to prevent the lines and circles from being drawn for every thread. This code results in the following image:<br>
<a data-tooltip-position="top" aria-label="http://1.bp.blogspot.com/_hGl_uKJzpS0/S7l76R2AahI/AAAAAAAAFd8/4S4GUGn0cdY/s1600/uav2.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://1.bp.blogspot.com/_hGl_uKJzpS0/S7l76R2AahI/AAAAAAAAFd8/4S4GUGn0cdY/s1600/uav2.png" target="_self"></a><img src="http://1.bp.blogspot.com/_hGl_uKJzpS0/S7l76R2AahI/AAAAAAAAFd8/4S4GUGn0cdY/s400/uav2.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> I must admit it seems quite odd writing a shader that draws primitives. It's like some strange recursive loop. But it definitely helps to illustrate the features of the Compute Shader and how powerful it is. You may download the source code to this example here:<br>
<a data-tooltip-position="top" aria-label="http://www.re-creationstudios.com/shared/ComputeShader11.zip" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.re-creationstudios.com/shared/ComputeShader11.zip" target="_self">ComputeShader11.zip</a> My next goal is to setup a standard DX11 Swap Chain and use the Compute Shader to write directly to the backbuffer. Well that's all for now. FYI: This is my 50th blog post! I never thought I would continue on this long. I think I should crack open a beer to celebrate.]]></description><link>https://glitchenzo.github.io/2010-04-04-simple-compute-shader-example.html</link><guid isPermaLink="false">2010-04-04 - Simple Compute Shader Example.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:49 GMT</pubDate><enclosure url="http://4.bp.blogspot.com/_hGl_uKJzpS0/S7l5JcLDytI/AAAAAAAAFdw/kalnv_r9bpc/s400/uav.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/S7l5JcLDytI/AAAAAAAAFdw/kalnv_r9bpc/s400/uav.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2010-03-09 - Watertight Adaptive Tessellation]]></title><description><![CDATA[2010-03-09The next obvious step for tessellation is to make it adaptive based upon the distance to the camera. It is important to keep the tessellated mesh watertight in order to prevent cracks from appearing between separate quads. There are five different ways (that I can think of) to address this problem. Do absolutely nothing For the longest time with my original LOD algorithm this is the path I followed. If you are okay with having nasty cracks in your mesh, then this is definitely the way to go. But that is no longer acceptable to me. Cheap fix (force all edges to be 1) If all quad edges are not subdivided at all, then there will be no cracks and it will be fast. The problem is there will be no detail at the edges, and this quickly becomes very obvious and ugly. Expensive fix (force all edges to be 64) Here is the flip-side to the previous option. All quad edges are subdivided to the maximum level. This ensures that the best detail will be used at each edge. However this is too expensive to do for all quads. Be smart about it (use adjacency information) This is the method that Jack Hoxley uses and describes <a data-tooltip-position="top" aria-label="http://www.gamedev.net/community/forums/topic.asp?topic_id=531164" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.gamedev.net/community/forums/topic.asp?topic_id=531164" target="_self">here</a>. Basically he builds a vertex buffer that contains the 4 vertices of the quad plus another 8 vertices representing the 4 adjacent quads. In the hull shader, he calculates the midpoint of each quad and then calculates the distance (and thus a tessellation factor) from the midpoint to the camera. He chooses the minimum factor for each edge in order to have the quads match. This is a pretty good solution, but it requires building a large vertex buffer containing adjacency information, as well as the additional midpoint calculation in the hull shader. Do it right (calc factors from each vertex) The next question is, can we do efficient watertight adaptive tessellation without adjacency information or the midpoint calculation? The answer is yes! If we calculate the tessellation factors from the vertices themselves, then we can guarantee that the surrounding quads will use the same factors (because they are using the same vertices). The basic algorithm is this: Calculate the tessellation factor based on camera distance for each of the 4 vertices
float distanceRange = maxDistance - minDistance;float vertex0 = lerp(minLOD, maxLOD, (1.0f - (saturate((distance(cameraPosition, op[0].position) - minDistance) / distanceRange))));float vertex1 = lerp(minLOD, maxLOD, (1.0f - (saturate((distance(cameraPosition, op[1].position) - minDistance) / distanceRange))));float vertex2 = lerp(minLOD, maxLOD, (1.0f - (saturate((distance(cameraPosition, op[2].position) - minDistance) / distanceRange))));float vertex3 = lerp(minLOD, maxLOD, (1.0f - (saturate((distance(cameraPosition, op[3].position) - minDistance) / distanceRange)))); Use the minimum value for each edge factor (pair of vertices)
output.edges[0] = min(vertex0, vertex3);output.edges[1] = min(vertex0, vertex1);output.edges[2] = min(vertex1, vertex2);output.edges[3] = min(vertex2, vertex3); Use the overall minimum value for the inside tessellation factor
float minTess = min(output.edges[1], output.edges[3]);output.inside[0] = minTess;output.inside[1] = minTess; Note: I originally thought the inside factor should be the maximum of the 4 vertices, but I after viewing it in action, I felt that the minimum was better. That's it! Simple, fast, and easy watertight adaptive tessellation. Check out the video of it in action: (I recorded the video at 1280x720, so be sure to view it at 720 to see the little details.)
]]></description><link>https://glitchenzo.github.io/2010-03-09-watertight-adaptive-tessellation.html</link><guid isPermaLink="false">2010-03-09 - Watertight Adaptive Tessellation.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:48 GMT</pubDate></item><item><title><![CDATA[2010-03-04 - Cube to Sphere Tessellation]]></title><description><![CDATA[2010-03-04My previous tessellation example was just a 2D, screen-space quad. My latest example steps into the world of 3D. No code to share, just a pretty little video. It shows a cube being tessellated on the fly to form a sphere. What's being done is each quad is being tessellated and then the vertex position is normalized. I was lazy and instead of making an entire cube with 6 sides, I only built a vertex/index buffer for 3 sides. You can only tell when I move the camera around at the end of the video. I was getting about 1500 fps for the cube and about 900 fps for the fully tessellated sphere. 63*63*3*2 = 23,814 triangles! Here ya go:
]]></description><link>https://glitchenzo.github.io/2010-03-04-cube-to-sphere-tessellation.html</link><guid isPermaLink="false">2010-03-04 - Cube to Sphere Tessellation.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:48 GMT</pubDate></item><item><title><![CDATA[2010-03-01 - Simple Tessellation Example]]></title><description><![CDATA[2010-03-01I have finally got my computer all setup with the Radeon 5450 and started doing some DirectX 11 development. Obviously the first thing I tried out was the tessellation. There are some nice sample projects included in the DirectX SDK that cover tessellation, but I felt that they were a little too ... complex. Don't get me wrong, I feel that they are great samples of doing things like model subdivision, detail tessellation, and bezier curves. I just felt that there should be a very simple demonstration of tessellation in the most basic sense. I decided to write one myself and share it here. I should note that this was written using SlimDX. I love having the power of DirectX in C#! As I stated, this is pretty much the most basic example of tessellation I could think of. It has one single quad with vertices defined in screen-space, which allows us to skip any transformation. The shader then tessellates the quad by using hard-coded tessellation factors. That's it! <a data-tooltip-position="top" aria-label="http://2.bp.blogspot.com/_hGl_uKJzpS0/S4ysssjVg6I/AAAAAAAAFac/_HBoa4KBcig/s1600-h/sdx_tessellation2.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://2.bp.blogspot.com/_hGl_uKJzpS0/S4ysssjVg6I/AAAAAAAAFac/_HBoa4KBcig/s1600-h/sdx_tessellation2.png" target="_self"></a><img src="http://2.bp.blogspot.com/_hGl_uKJzpS0/S4ysssjVg6I/AAAAAAAAFac/_HBoa4KBcig/s400/sdx_tessellation2.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> The main application code isn't that important. It just creates the vertex buffer consisting of 4 vertices. It then draws using the new "4 control point patch" primitive. All the rest of the magic happens in the HLSL code. The vertex shader isn't that impressive. It is simply a pass-through shader and passes the vertex position through to the hull shader. VS_OUTPUT VS( VS_INPUT input ){ VS_OUTPUT output; output.position = input.position; return output;}
The hull shader constant fuction simply sets the hard-coded tessellation factors for the edges and inside. Currently I have it hard-coded to a factor of 32. You may manually change this value to be anywhere from 1-64. HS_CONSTANT_OUTPUT HSConstant( InputPatch&lt;VS_OUTPUT, 4&gt; ip, uint pid : SV_PrimitiveID ){ HS_CONSTANT_OUTPUT output; float edge = 32.0f; float inside = 32.0f; output.edges[0] = edge; output.edges[1] = edge; output.edges[2] = edge; output.edges[3] = edge; output.inside[0] = inside; output.inside[1] = inside; return output;}
The hull shader itself does not perform a basis change, and therefore it passes through all 4 of the input points to the output. As you can see from the attributes, it is operating on the quad domain and it uses the standard clockwise winding. [domain("quad")][partitioning("integer")][outputtopology("triangle_cw")][outputcontrolpoints(4)][patchconstantfunc("HSConstant")]HS_OUTPUT HS( InputPatch&lt;VS_OUTPUT, 4&gt; ip, uint cpid : SV_OutputControlPointID, uint pid : SV_PrimitiveID ){ HS_OUTPUT Output; Output.position = ip[cpid].position; return Output;}
Before explaining the domain shader, let me first explain the orientation of the UV coordinates coming from the tessellator. Let's assume your vertices are defined in this manner: u 0-----1v| | | | 3-----2
The U dimension ranges from [0-1] in the direction of vertex 0 to vertex 1.
The V dimension ranges from [0-1] in the direction of vertex 0 to vertex 3. I specifically state this now because I had wrongly assumed that it was oriented such that the U and V coordinates were reversed, like so: WRONG! 1-----2 | |v| | 0-----3 u
Now, about the domain shader itself. This is normally where the samples got rather complex calculating bezier curves and such. This is the simplest algorithm I could come up with. It uses three linear interpolations to calculate the vertex position. I visualize it as sliding two lines along the the quad and marking where they intersect as the vertex. The first lerp finds the "midpoint" between vertex 0 and 1 by a factor of U.
The second lerp finds the "midpoint" between vertex 3 and 2 by a factor of U.
The third lerp finds the "midpoint" between the first and second calulated midpoints by a factor of V. This is rather hard to "draw" a diagram for, but hopefully this makes some sense: lerp1 0--|--1 | _ | lerp3 | | 3--|--2 lerp2
The color of the vertex is set based upon the tessellation UV coordinates. [domain("quad")]DS_OUTPUT DS( HS_CONSTANT_OUTPUT input, float2 UV : SV_DomainLocation, const OutputPatch&lt;HS_OUTPUT, 4&gt; patch ){ DS_OUTPUT Output; float3 topMidpoint = lerp(patch[0].position, patch[1].position, UV.x); float3 bottomMidpoint = lerp(patch[3].position, patch[2].position, UV.x); Output.position = float4(lerp(topMidpoint, bottomMidpoint, UV.y), 1); Output.color = float4(UV.yx, 1-UV.x, 1); return Output; }
The pixel shader just writes out the color. float4 PS( DS_OUTPUT input ) : SV_Target{ return input.color;}
There you have it! Hopefully this simple example of tessellating a single quad will be useful to other people and help to illustrate how the tessellator works. <br>You can download the full source to this example here: <a data-tooltip-position="top" aria-label="http://re-creationstudios.com/shared/Tessellation.zip" rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/shared/Tessellation.zip" target="_self">Tessellation.zip</a>]]></description><link>https://glitchenzo.github.io/2010-03-01-simple-tessellation-example.html</link><guid isPermaLink="false">2010-03-01 - Simple Tessellation Example.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:47 GMT</pubDate><enclosure url="http://2.bp.blogspot.com/_hGl_uKJzpS0/S4ysssjVg6I/AAAAAAAAFac/_HBoa4KBcig/s400/sdx_tessellation2.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://2.bp.blogspot.com/_hGl_uKJzpS0/S4ysssjVg6I/AAAAAAAAFac/_HBoa4KBcig/s400/sdx_tessellation2.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2010-02-19 - Quick Update]]></title><description><![CDATA[2010-02-19DirectX 11
I attended GameFest 2010. I can't say much except that I want to work with DX11 even more than before, if that was possible. As a result, I just bought a Radeon 5450 from newegg. Sure, it is a rather weak card, but it is only $35! Plus, it is much faster than the reference rasterizer and it only consumes 19 watts at full usage! Here is the card I bought:
<a rel="noopener nofollow" class="external-link is-unresolved" href="http://www.newegg.com/Product/Product.aspx?Item=N82E16814131339" target="_self">http://www.newegg.com/Product/Product.aspx?Item=N82E16814131339</a> It should hold me over until the Nvidia 400 series cards come out in a month or two. SlimDX
Talk about perfect timing! The latest version of SlimDX was just released today. The D3D11 wrapper should be even more stable than what it already was. You can download it from here:<br>
<a rel="noopener nofollow" class="external-link is-unresolved" href="http://slimdx.org/download.php" target="_self">http://slimdx.org/download.php</a>]]></description><link>https://glitchenzo.github.io/2010-02-19-quick-update.html</link><guid isPermaLink="false">2010-02-19 - Quick Update.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:46 GMT</pubDate></item><item><title><![CDATA[2009-12-27 - Procedural Cities in XNA]]></title><description><![CDATA[2009-12-27It's been quite a while since I've talked about any development I've been doing. To be honest I have been quite busy with work and flight lessons, so I don't have much time to work on my hobby projects. Lately I have been working on a procedural city generator in C#/XNA. I'm basing my work on the <a data-tooltip-position="top" aria-label="http://pcity.sourceforge.net/" rel="noopener nofollow" class="external-link is-unresolved" href="http://pcity.sourceforge.net/" target="_self">Metropolis</a> project, which was in turn based upon a research paper presented at SIGGRAPH 2001. I began with the procedural road map generator. It takes a heightmap and generates a road network from it. <br><a data-tooltip-position="top" aria-label="http://3.bp.blogspot.com/_hGl_uKJzpS0/SzcmQbTE3DI/AAAAAAAAFXM/vpJQSG9Krmo/s1600-h/map1.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://3.bp.blogspot.com/_hGl_uKJzpS0/SzcmQbTE3DI/AAAAAAAAFXM/vpJQSG9Krmo/s1600-h/map1.png" target="_self"></a><img src="http://3.bp.blogspot.com/_hGl_uKJzpS0/SzcmQbTE3DI/AAAAAAAAFXM/vpJQSG9Krmo/s400/map1.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> Zooming in you can begin to see the subdivisions between streets where buildings will be built. <br><a data-tooltip-position="top" aria-label="http://3.bp.blogspot.com/_hGl_uKJzpS0/SzcmhQfMEII/AAAAAAAAFXU/x56-I4206lY/s1600-h/map2.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://3.bp.blogspot.com/_hGl_uKJzpS0/SzcmhQfMEII/AAAAAAAAFXU/x56-I4206lY/s1600-h/map2.png" target="_self"></a><img src="http://3.bp.blogspot.com/_hGl_uKJzpS0/SzcmhQfMEII/AAAAAAAAFXU/x56-I4206lY/s400/map2.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> Zooming in even further makes the building lots even clearer. <br><a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/_hGl_uKJzpS0/Szcm7bHNQrI/AAAAAAAAFXc/K9VzVaNsnw0/s1600-h/map3.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/_hGl_uKJzpS0/Szcm7bHNQrI/AAAAAAAAFXc/K9VzVaNsnw0/s1600-h/map3.png" target="_self"></a><img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/Szcm7bHNQrI/AAAAAAAAFXc/K9VzVaNsnw0/s400/map3.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> Next, I began work on the 3D building creation. Here you can see many simple buildings all using the same texturing. <br><a data-tooltip-position="top" aria-label="http://1.bp.blogspot.com/_hGl_uKJzpS0/SzcneIs3oYI/AAAAAAAAFXk/OoieeLch7rs/s1600-h/city1.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://1.bp.blogspot.com/_hGl_uKJzpS0/SzcneIs3oYI/AAAAAAAAFXk/OoieeLch7rs/s1600-h/city1.png" target="_self"></a><img src="http://1.bp.blogspot.com/_hGl_uKJzpS0/SzcneIs3oYI/AAAAAAAAFXk/OoieeLch7rs/s400/city1.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> I then added more texture variety. <br><a data-tooltip-position="top" aria-label="http://1.bp.blogspot.com/_hGl_uKJzpS0/SzcntghxXlI/AAAAAAAAFXs/9WJKc58rTt4/s1600-h/city2.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://1.bp.blogspot.com/_hGl_uKJzpS0/SzcntghxXlI/AAAAAAAAFXs/9WJKc58rTt4/s1600-h/city2.png" target="_self"></a><img src="http://1.bp.blogspot.com/_hGl_uKJzpS0/SzcntghxXlI/AAAAAAAAFXs/9WJKc58rTt4/s400/city2.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> I finally added in the terrain with road texturing. <br><a data-tooltip-position="top" aria-label="http://1.bp.blogspot.com/_hGl_uKJzpS0/SzcoCRdCYAI/AAAAAAAAFX0/Sl51N1FTL10/s1600-h/city3.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://1.bp.blogspot.com/_hGl_uKJzpS0/SzcoCRdCYAI/AAAAAAAAFX0/Sl51N1FTL10/s1600-h/city3.png" target="_self"></a><img src="http://1.bp.blogspot.com/_hGl_uKJzpS0/SzcoCRdCYAI/AAAAAAAAFX0/Sl51N1FTL10/s400/city3.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> Zoomed out view showing the vast number of buildings generated. <br><a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/_hGl_uKJzpS0/SzcoT6ifzXI/AAAAAAAAFX8/3cKlAuKqSDw/s1600-h/city4.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/_hGl_uKJzpS0/SzcoT6ifzXI/AAAAAAAAFX8/3cKlAuKqSDw/s1600-h/city4.png" target="_self"></a><img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/SzcoT6ifzXI/AAAAAAAAFX8/3cKlAuKqSDw/s400/city4.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> And the final image showing "Central Park" (this city was generated from a heightmap of Manhattan). <br><a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/_hGl_uKJzpS0/SzcorfGRvhI/AAAAAAAAFYE/DYrAgR0vmgQ/s1600-h/city5.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/_hGl_uKJzpS0/SzcorfGRvhI/AAAAAAAAFYE/DYrAgR0vmgQ/s1600-h/city5.png" target="_self"></a><img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/SzcorfGRvhI/AAAAAAAAFYE/DYrAgR0vmgQ/s400/city5.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> I want to eventually release the source code for this, but first I need to clean up the code some more. I also need to tweak the renderer to run faster. Right now it is just brute forcing it, and doesn't utilize any form of level of detail or frustum culling.]]></description><link>https://glitchenzo.github.io/2009-12-27-procedural-cities-in-xna.html</link><guid isPermaLink="false">2009-12-27 - Procedural Cities in XNA.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:46 GMT</pubDate><enclosure url="http://3.bp.blogspot.com/_hGl_uKJzpS0/SzcmQbTE3DI/AAAAAAAAFXM/vpJQSG9Krmo/s400/map1.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://3.bp.blogspot.com/_hGl_uKJzpS0/SzcmQbTE3DI/AAAAAAAAFXM/vpJQSG9Krmo/s400/map1.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2009-10-10 - SlimDX August 2009 Release]]></title><description><![CDATA[2009-10-10A new version of SlimDX is now available. This version wraps the latest DirectX SDK release (August 2009, thus the name). This means that things like DirectX 11 and Direct2D are now officially supported (previous releases were beta). You can download the installer here:
<a rel="noopener nofollow" class="external-link is-unresolved" href="http://code.google.com/p/slimdx/" target="_self">http://code.google.com/p/slimdx/</a> You can also read a little more about this release at the GameDev.net forums:<br>
<a data-tooltip-position="top" aria-label="http://www.gamedev.net/community/forums/topic.asp?topic_id=549927" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.gamedev.net/community/forums/topic.asp?topic_id=549927" target="_self">http://www.gamedev.net/community/forums/topic.asp?topic_id=549927</a> I'm looking forward to trying it out. Unfortunately, I still don't have DX11 hardware, so I'll probably hold off on things like tessellation or the compute shader.]]></description><link>https://glitchenzo.github.io/2009-10-10-slimdx-august-2009-release.html</link><guid isPermaLink="false">2009-10-10 - SlimDX August 2009 Release.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:39 GMT</pubDate></item><item><title><![CDATA[2009-10-03 - Disappointment]]></title><description><![CDATA[2009-10-03Since I have never used the Geometry Shader, I've been reading tutorials on how to use it to generate silhouettes and stencil shadows via the adjacency information being passed through the index buffer. From my posts in the past, it is pretty obvious that I am really excited about tessellation and I want to make use of it ASAP. So, a natural thing that came to my mind was combining the two together to tessellate a mesh and then generate silhouettes. No can do. I was completely and utterly disappointed to find out that you can NOT use adjacency information alongside the tessellator. I quote from the official DirectX 11 docs: "A geometry shader that expects primitives with adjacency (for example, 6 vertices per triangle) is not valid when tessellation is active (this results in undefined behavior, which the debug layer will complain about)."]]></description><link>https://glitchenzo.github.io/2009-10-03-disappointment.html</link><guid isPermaLink="false">2009-10-03 - Disappointment.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:38 GMT</pubDate></item><item><title><![CDATA[2009-09-24 - DirectX 11 GPUs have arrived]]></title><description><![CDATA[2009-09-24The Radeon HD 5870 is now out in the wild and available for purchase. I'm still unsure if I want to buy it or wait for the 5850 coming out next month. The 5850 is $120 less than the 5870 and the specs aren't that much lower. On the Nvidia side of things, it's not looking very good. The latest rumors are that they are having incredibly low yields from their chips and as a result have delayed the launch of their DX11 GPUs to the third quarter of 2010. I wonder how this generation will play out if Nvidia's cards don't show up until almost a year after ATI's. Update:
Apparently the news of the Nvidia delay is just FUD. They have officially announced that the 300 series will still debut in December. Read about it <a data-tooltip-position="top" aria-label="http://www.brightsideofnews.com/news/2009/9/25/nvidia-says-gt300-on-schedule-for-q4-20092c-yields-are-fine.aspx" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.brightsideofnews.com/news/2009/9/25/nvidia-says-gt300-on-schedule-for-q4-20092c-yields-are-fine.aspx" target="_self">here</a>.]]></description><link>https://glitchenzo.github.io/2009-09-24-directx-11-gpus-have-arrived.html</link><guid isPermaLink="false">2009-09-24 - DirectX 11 GPUs have arrived.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:38 GMT</pubDate></item><item><title><![CDATA[2009-09-13 - Perlin Noise in DirectX 10 (Shader Model 4.0)]]></title><description><![CDATA[2009-09-13This is somewhat similar to the classic problem of <a data-tooltip-position="top" aria-label="http://www.sixside.com/fast_good_cheap.asp" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.sixside.com/fast_good_cheap.asp" target="_self">Good, Cheap, and Fast</a> where you can only have two of them at the same time. I implemented Perlin Noise entirely on the GPU, meaning no textures are precomputed and no parameters are set on the GPU. The shader is simply loaded and ran. It is a very clean solution and it is incredibly simple to add to any project. Unfortunately, it is slow. Mind you, it is still much faster than the CPU implementation, but it is slow compared to my original precomputed texture implementation. I always run my tests using 12 octaves of 3D fBm Perlin Noise summations at a resolution of 1024x1024. It yields much more stable results than just 1 calculation of Perlin Noise. My original implementation ran at about 85 fps. At first, my new simple implementation was running at about 3 fps! Even though the documentation states that HLSL automatically marks all global variables as const, if I put the const keyword before my permutation array my frame-rate jumped up to 19 fps. I added a gradient lookup table and changed the gradient calculation functions to just index into the table. However, this basically had no impact on the speed. I then reduced the permutation array from 512 to 256 and performed a modulus operation on any indexing into the array. This gave my about a 30% speed increase and got it up to about 25 fps. I tried various other tweaks, and I was able to get it to go a bit faster, but it was always at the expense of the quality of the noise (wouldn't work with negative values, would look blocky, etc). The fastest I was able to get it and still maintain the high quality Perlin Noise was 25 fps. I must say that I'm rather disappointed with these results. I had thought that constant memory indexing would be faster than texture lookups, however the texture lookup version was over 3 times faster than the memory indexing version. Perhaps I'm just missing something or I'm implementing the memory indexing incorrectly, but I don't know what I could possibly do to speed it up anymore AND keep the same quality. For the time being, it looks like texture lookups are the way to go. I've decided to upload 2 versions of the noise code. The first version is a direct port of Ken Perlin's Java code to HLSL(19 fps). The second includes the tweaks to the gradients and permutation array (25 fps). <br><a data-tooltip-position="top" aria-label="http://www.re-creationstudios.com/shared/noise.fxh" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.re-creationstudios.com/shared/noise.fxh" target="_self">First Version</a><br>
<a data-tooltip-position="top" aria-label="http://www.re-creationstudios.com/shared/noise2.fxh" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.re-creationstudios.com/shared/noise2.fxh" target="_self">Tweaked Version</a> As I have said, the major advantage to this implementation is the simplicity. All you have to do is include the header in your HLSL code and you can call the noise() and fBm() functions. That's it! You don't have to do anything else. So if you just want to drag and drop some Perlin Noise into a shader, this is the best way to do it, if you don't care about speed.]]></description><link>https://glitchenzo.github.io/2009-09-13-perlin-noise-in-directx-10-(shader-model-4.0).html</link><guid isPermaLink="false">2009-09-13 - Perlin Noise in DirectX 10 (Shader Model 4.0).md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:37 GMT</pubDate></item><item><title><![CDATA[2009-09-09 - Soon ... Very Soon]]></title><description><![CDATA[2009-09-09The August DirectX SDK was released today (shh, don't tell them it's September). This brings with it the first official release of DirectX 11! You can download it in all of it's glory here:
<a data-tooltip-position="top" aria-label="http://www.microsoft.com/downloads/details.aspx?displaylang=en&amp;FamilyID=b66e14b8-8505-4b17-bf80-edb2df5abad4" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.microsoft.com/downloads/details.aspx?displaylang=en&amp;FamilyID=b66e14b8-8505-4b17-bf80-edb2df5abad4" target="_self">August DirectX SDK</a> <br>Note: In order to run the DX11 samples on Vista, you need a patch. Unfortunately, that patch is not yet available, but when it is it should be available <a data-tooltip-position="top" aria-label="http://support.microsoft.com/kb/971644" rel="noopener nofollow" class="external-link is-unresolved" href="http://support.microsoft.com/kb/971644" target="_self">here</a>. In very related news, it looks like the first DirectX 11 GPUs will be available this month. The Radeon HD 5850 will be $300, the Radeon HD 5870 will be $400, and the Radeon HD 5870x2 will be $600.<br>
<a data-tooltip-position="top" aria-label="http://www.theinquirer.net/inquirer/news/1532355/radeon-58xx-pricing-leaked" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.theinquirer.net/inquirer/news/1532355/radeon-58xx-pricing-leaked" target="_self">Read more here</a>]]></description><link>https://glitchenzo.github.io/2009-09-09-soon-...-very-soon.html</link><guid isPermaLink="false">2009-09-09 - Soon ... Very Soon.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:31 GMT</pubDate></item><item><title><![CDATA[2009-09-08 - Byte Order Mark - The Invisible Enemy]]></title><description><![CDATA[2009-09-08Alternate Title:
EF BB BF - The Three Bytes of Doom Last night I decided to whip out a quick SlimDX / DirectX 10 project implementing Perlin Noise using Shader Model 4.0. In my Perlin Noise on the GPU article, I mentioned how much easier it would be to implement Perlin Noise using SM4.0+ vs SM3.0. I had done a quick port of Ken Perlin's Java example implementation in FX Composer a couple months back, so I thought I would be able to implement the stand-alone version in less than an hour. I wanted to test it first in a pixel shader, so I made my own custom vertex as well as a class that would build a fullscreen quad vertex buffer. I took the Perlin Noise HLSL code and put it into a header file, and made a simple two-technique shader that included the header. I fired up the code, but I quickly got an exception (E_FAIL: An undetermined error occurred (-2147467259)) at the point where I was trying to set the InputLayout of the vertex buffer to the shader signature. Not a very useful exception. At first, I thought it might have been a problem with my custom vertex format. After looking it over and comparing against other custom vertex formats I've made in the past, I determined the issue wasn't there. Next I looked at how I was creating the vertex buffer and index buffer for the fullscreen quad. That all appeared in order too. After determining that the issue was not in my custom vertex format or my fullscreen quad, I slowly stepped through the code keeping a close eye on all of the variables. I didn't think there was a problem with my shader because no errors were being output from the compiler, and it was spitting out a valid Effect. However, when stepping through and watching the variables, I saw that even though it created an Effect and the IsValid property was true, it said the TechniqueCount was zero! In fact, all of the counts were saying zero. It was as if the compiler was seeing it as an empty file. So, I next looked at my shader in detail. I thought maybe something funky was happening with the included header file, so I inlined all of the header code. I still got the exception. I thought it might be some random issue in one of my noise functions, so I changed them to all return 1.0. Exception. I triple checked all of my input and output structures. I looked over my technique description. I changed my vertex shader to be a simple pass-through and the pixel shader to just return white. Exception. What the heck was going on? I had other shaders that were compiling just fine. So, just as a "stupid" test, I copied one of the my other working shaders and pasted all of the code into my fx file, overwriting everything in it. I still got the exception! Now I knew something was really messed up somewhere. Here I had two fx files with the exact same HLSL code in them, but one was compiling while the other was not. I opened both files up using the Binary Editor in Visual Studio to see byte by byte. The file that was not compiling had three extra bytes at the beginning - EF BB BF. I deleted these three bytes, and everything worked! It turns out that that byte sequence is the Byte Order Mark. It is specifying that the file is UTF-8 encoded. Apparently this is the default for all files created in Visual Studio 2008. Unfortunately, the FX compiler in DirectX can't read UTF-8 files and just dies and returns an empty Effect. I did a quick Google search after fixing the problem and I saw that several other people had the same problem and eventually came to the same solution. I really wish the compiler would return an error in a situation like this. What I find very interesting is the fact that I have been programming shaders for over two and a half years, and I have never run into this problem before. Hopefully this post helps someone else if they encounter this same problem. Until next time...]]></description><link>https://glitchenzo.github.io/2009-09-08-byte-order-mark-the-invisible-enemy.html</link><guid isPermaLink="false">2009-09-08 - Byte Order Mark - The Invisible Enemy.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:30 GMT</pubDate></item><item><title><![CDATA[2009-08-25 - Teaser]]></title><description><![CDATA[2009-08-25I'm not yet ready to fully talk about what I'm working on, but I wanted to give a little preview to whet everyone's appetite. <a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/_hGl_uKJzpS0/SpQGJJ3N_5I/AAAAAAAAFOo/20fd3hFyVzU/s1600-h/physx_slimdx.jpg" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/_hGl_uKJzpS0/SpQGJJ3N_5I/AAAAAAAAFOo/20fd3hFyVzU/s1600-h/physx_slimdx.jpg" target="_self"></a><img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/SpQGJJ3N_5I/AAAAAAAAFOo/20fd3hFyVzU/s400/physx_slimdx.jpg" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> Yep! 3001 boxes in 1 PhysX scene and still maintaining 29.81 frames per second. The really awesome part is the fact that this is all in C#! I'll talk more about it later. Until next time...]]></description><link>https://glitchenzo.github.io/2009-08-25-teaser.html</link><guid isPermaLink="false">2009-08-25 - Teaser.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:23 GMT</pubDate><enclosure url="http://4.bp.blogspot.com/_hGl_uKJzpS0/SpQGJJ3N_5I/AAAAAAAAFOo/20fd3hFyVzU/s400/physx_slimdx.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/SpQGJJ3N_5I/AAAAAAAAFOo/20fd3hFyVzU/s400/physx_slimdx.jpg"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2009-07-29 - Infinite Depth Buffer]]></title><description><![CDATA[2009-07-29I've been planning out how I'm going to rewrite my planet algorithm once DirectX 11 is out. I've decided to focus on problems I have now that will still be a problem in DX11. One such problem that I've always been having in the past is the depth buffer. My planet is Earth-sized so in order to keep it visible as you fly away from it, I pushed the far clipping plane way out. Obviously this destroyed the precision of my depth buffer and I had big problems with Z-fighting (far off mountains were being drawn in front of closer ones). Rant: Why the heck are most GPUs these days still stuck with a 24-bit depth buffer? The Xbox 360 and my GeForce 9800M GT both only support up to a 24-bit depth buffer. DX11 level GPUs will have 64-bit floating point (double) support in shaders, so why not a 64-bit depth buffer? In the videos and screenshots I have posted in the past, I did two different things to try and fix my problem with the depth buffer. First, I had a "sliding" far clipping plane that would have a minimum value, but as you flew away from the planet, it would extend out in order to continually show the planet. My second solution was to just disable the depth buffer. Both of these solutions only worked because I was drawing only 1 planet and there were no other objects being rendered. Obviously I want to keep my depth buffer around, keep the high precision for any near objects, but continue to draw far off planets (not have them clipped by the far clipping plane). In order to fully understand my problem, I read about how exactly the depth buffer works and how a position is transfomed and then clipped. I found <a data-tooltip-position="top" aria-label="http://www.mvps.org/directx/articles/linear_z/linearz.htm" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.mvps.org/directx/articles/linear_z/linearz.htm" target="_self">this article</a> very informative about the inner workings of the GPU in terms of the depth buffer. I did not change my depth buffer to be linear like he does though. The article helped me to understand the relationship between the Z component and W component of the transformed vertex position. Between the vertex shader and the pixel shader, the Z component is divided by W in order to "normalize" the depth (range 0-1). If the Z value is greater than 1 then it is clipped. So, I needed to make it so that the normalized Z value never exceeded 1. This was a very simple thing to fix, once I understood it. In my vertex shader I check the Z value to see if it is greater than the far clipping plane value (which I pass into the shader). If it is greater, then I simply set the W component equal to the Z component. This means that the Z / W calculation thus becomes Z / Z = 1. Now I can have good depth buffer precision for things close to the camera, but I will continue to draw things even if they are an infinite (theoretically) distance away! Obviously this solution isn't perfect and there are some "gotchas". If I am drawing a planet and a moon, and the moon is behind the planet, and I am flying away from the planet, AND the moon is being drawn after the planet in the C# code, then the moon will suddenly pop in front of the planet once the planet exceeds the far clipping plane. That means I'll have to have a manager of large objects in the "local system" to make sure they are drawn in back to front order. That should be really easy to implement. Hopefully this all makes sense and it helps someone else struggling with the same problem. Until next time...Update: I would now strongly encourage people to use a Logarithmic Depth Buffer to solve all of your depth buffer precision issues. You can read about it here:<br><a data-tooltip-position="top" aria-label="http://www.gamasutra.com/blogs/BranoKemen/20090812/2725/Logarithmic_Depth_Buffer.php" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.gamasutra.com/blogs/BranoKemen/20090812/2725/Logarithmic_Depth_Buffer.php" target="_self">http://www.gamasutra.com/blogs/BranoKemen/20090812/2725/Logarithmic_Depth_Buffer.php</a>]]></description><link>https://glitchenzo.github.io/2009-07-29-infinite-depth-buffer.html</link><guid isPermaLink="false">2009-07-29 - Infinite Depth Buffer.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:22 GMT</pubDate></item><item><title><![CDATA[2009-07-01 - Perlin Noise in JavaScript]]></title><description><![CDATA[2009-07-01I apologize for not having any update for the month of June, but I was gone on vacation for a majority of it. I saw tons of places on the road trip. Illinois, Indiana, Michigan, Ontario, New York, Vermont, New Hampshire, Maine, Massachusetts, New Jersey, Delaware, Maryland, Virginia, Pennsylvania, West Virginia, and Ohio (in that order)! I had never been to the New England area of the country, so it was great being able to see it all. In terms of development, I haven't really done any since I wrote that Perlin Noise article. I've been tossing around the idea in my head to go try out <a data-tooltip-position="top" aria-label="http://slimdx.org/" rel="noopener nofollow" class="external-link is-unresolved" href="http://slimdx.org/" target="_self">SlimDX</a> again. I know, I know, I just can't make up my mind on things, right? It would just be very convenient to be writing C# again, and I found the great <a data-tooltip-position="top" aria-label="http://physxdotnet.codeplex.com/" rel="noopener nofollow" class="external-link is-unresolved" href="http://physxdotnet.codeplex.com/" target="_self">PhysX.Net</a> wrapper that should allow me to continue to use PhysX with my C# development. Plus SlimDX already is supporting DirectX 11, which is awesome! (Tessellation, here I come!) By the way, I was curious about JavaScript so I developed a simple little webpage that implements Perlin Noise in JavaScript. You can find it here:<br>
<a rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/noise/" target="_self">http://re-creationstudios.com/noise/</a> I used a Canvas element to display the result, so it won't work in Internet Explorer. Be sure to check out the source code since I implemented several different types of summation as well (fBm, turbulence, and ridged multifractal). Enjoy!]]></description><link>https://glitchenzo.github.io/2009-07-01-perlin-noise-in-javascript.html</link><guid isPermaLink="false">2009-07-01 - Perlin Noise in JavaScript.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:22 GMT</pubDate></item><item><title><![CDATA[2009-05-31 - Perlin Noise on the GPU]]></title><description><![CDATA[2009-05-31I've written a tutorial on how to implement Perlin Noise in both a pixel shader and a vertex shader. The tutorial is available over at Ziggyware. <a data-tooltip-position="top" aria-label="http://www.ziggyware.com/readarticle.php?article_id=246" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.ziggyware.com/readarticle.php?article_id=246" target="_self">http://www.ziggyware.com/readarticle.php?article_id=246</a> Check it out! I welcome any feedback. UPDATE<br>
<a rel="noopener nofollow" class="external-link is-unresolved" href="http://www.ziggyware.com/news.php?readmore=1125" target="_self">http://www.ziggyware.com/news.php?readmore=1125</a>
I found out I have won first place in the Ziggyware contest! I'm very happy that my first XNA tutorial was such a success. Perhaps I will write up more in the future. UPDATE 2
It appears that Ziggyware no longer exists, so I have shared the article, screenshots, and sample code on my server. &nbsp;You can download it all here:<br>
<a rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/shared/PerlinNoiseGPU/" target="_self">http://re-creationstudios.com/shared/PerlinNoiseGPU/</a>]]></description><link>https://glitchenzo.github.io/2009-05-31-perlin-noise-on-the-gpu.html</link><guid isPermaLink="false">2009-05-31 - Perlin Noise on the GPU.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:21 GMT</pubDate></item><item><title><![CDATA[2009-05-29 - PhysX Planet]]></title><description><![CDATA[2009-05-29<a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/_hGl_uKJzpS0/SiAd84Ta_7I/AAAAAAAAE00/UQQi0ZWa_JQ/s1600-h/physx4.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/_hGl_uKJzpS0/SiAd84Ta_7I/AAAAAAAAE00/UQQi0ZWa_JQ/s1600-h/physx4.png" target="_self"></a><img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/SiAd84Ta_7I/AAAAAAAAE00/UQQi0ZWa_JQ/s400/physx4.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> Creating planetary gravity with a force field was much easier than I was expecting. Especially after finding this thread on the official PhysX forum.<br>
<a rel="noopener nofollow" class="external-link is-unresolved" href="http://developer.nvidia.com/forums/index.php?showtopic=3201&amp;pid=9249&amp;st=0&amp;#entry9249" target="_self">http://developer.nvidia.com/forums/index.php?showtopic=3201&amp;pid=9249&amp;st=0&amp;#entry9249</a> After doing that, I got curious and I removed the sphere "planet" but I kept the gravity force field. As expected, all of the shapes grouped together to form their own planet. <br><a data-tooltip-position="top" aria-label="http://1.bp.blogspot.com/_hGl_uKJzpS0/SiAeQ_EL5CI/AAAAAAAAE08/w3kcUmiSJ98/s1600-h/physx5.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://1.bp.blogspot.com/_hGl_uKJzpS0/SiAeQ_EL5CI/AAAAAAAAE08/w3kcUmiSJ98/s1600-h/physx5.png" target="_self"></a><img src="http://1.bp.blogspot.com/_hGl_uKJzpS0/SiAeQ_EL5CI/AAAAAAAAE08/w3kcUmiSJ98/s400/physx5.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> After I kept watching it, the planet started pulsing back and forth and eventually tore itself apart in a vortex that alternated back and forth. <br><a data-tooltip-position="top" aria-label="http://2.bp.blogspot.com/_hGl_uKJzpS0/SiAemVgW0dI/AAAAAAAAE1E/SmSpD67Ex2w/s1600-h/physx6.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://2.bp.blogspot.com/_hGl_uKJzpS0/SiAemVgW0dI/AAAAAAAAE1E/SmSpD67Ex2w/s1600-h/physx6.png" target="_self"></a><img src="http://2.bp.blogspot.com/_hGl_uKJzpS0/SiAemVgW0dI/AAAAAAAAE1E/SmSpD67Ex2w/s400/physx6.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> The debris vortex started stabilizing and turned into a spinning ring. <br><a data-tooltip-position="top" aria-label="http://1.bp.blogspot.com/_hGl_uKJzpS0/SiAe3LmGeWI/AAAAAAAAE1M/ywK9L8McRcw/s1600-h/physx7.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://1.bp.blogspot.com/_hGl_uKJzpS0/SiAe3LmGeWI/AAAAAAAAE1M/ywK9L8McRcw/s1600-h/physx7.png" target="_self"></a><img src="http://1.bp.blogspot.com/_hGl_uKJzpS0/SiAe3LmGeWI/AAAAAAAAE1M/ywK9L8McRcw/s400/physx7.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> The ring kept expanding and getting bigger and bigger. <br><a data-tooltip-position="top" aria-label="http://3.bp.blogspot.com/_hGl_uKJzpS0/SiAfBFF87gI/AAAAAAAAE1U/UjXaP-mhXFU/s1600-h/physx8.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://3.bp.blogspot.com/_hGl_uKJzpS0/SiAfBFF87gI/AAAAAAAAE1U/UjXaP-mhXFU/s1600-h/physx8.png" target="_self"></a><img src="http://3.bp.blogspot.com/_hGl_uKJzpS0/SiAfBFF87gI/AAAAAAAAE1U/UjXaP-mhXFU/s400/physx8.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> I added some more cubes to the center, which formed a cool looking planet with a ring. <br><a data-tooltip-position="top" aria-label="http://1.bp.blogspot.com/_hGl_uKJzpS0/SiAfPFdWJTI/AAAAAAAAE1c/sfSmf8ss5i0/s1600-h/physx9.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://1.bp.blogspot.com/_hGl_uKJzpS0/SiAfPFdWJTI/AAAAAAAAE1c/sfSmf8ss5i0/s1600-h/physx9.png" target="_self"></a><img src="http://1.bp.blogspot.com/_hGl_uKJzpS0/SiAfPFdWJTI/AAAAAAAAE1c/sfSmf8ss5i0/s400/physx9.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> The planet at the center eventually started breaking apart and forming a ring as well, but what was most interesting was that the inner ring was rotating in the opposite direction of the outer ring. <br><a data-tooltip-position="top" aria-label="http://2.bp.blogspot.com/_hGl_uKJzpS0/SiAfUiz9RjI/AAAAAAAAE1k/aOOkppAKdBI/s1600-h/physx10.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://2.bp.blogspot.com/_hGl_uKJzpS0/SiAfUiz9RjI/AAAAAAAAE1k/aOOkppAKdBI/s1600-h/physx10.png" target="_self"></a><img src="http://2.bp.blogspot.com/_hGl_uKJzpS0/SiAfUiz9RjI/AAAAAAAAE1k/aOOkppAKdBI/s400/physx10.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved">]]></description><link>https://glitchenzo.github.io/2009-05-29-physx-planet.html</link><guid isPermaLink="false">2009-05-29 - PhysX Planet.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:21 GMT</pubDate><enclosure url="http://4.bp.blogspot.com/_hGl_uKJzpS0/SiAd84Ta_7I/AAAAAAAAE00/UQQi0ZWa_JQ/s400/physx4.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/SiAd84Ta_7I/AAAAAAAAE00/UQQi0ZWa_JQ/s400/physx4.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2009-05-28 - PhysX and DirectX 10]]></title><description><![CDATA[2009-05-28For the past week or so, I've been working on getting PhysX working in DirectX 10. I ported over my Shape3D class from my previous blog post to C++ in order to draw the boxes and spheres (no cylinders because PhysX doesn't have a cylinder shape). I set up a simple scene with a ground plane (not rendered), normal Earth gravity, two boxes and a sphere. The space bar spawns new boxes at the origin and the Alt key spawns new spheres. In my first implementation, the application would slow down to 20fps when I added about 75 shapes. I tracked down this slowdown to the creation of the vertex input layout each frame. Once I moved that out of the render loop, I could then have 1000 shapes in the scene and still maintain 30fps. I'm still trying to figure out if I can speed up the rendering even more because without rendering, the PhysX engine was able to handle 2000 shapes and maintain 60fps. I doubt I can speed it up much more though. Here are some screenshots. Pretty simple, but the debug info helps to illustrate the speeds.
<a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/_hGl_uKJzpS0/Sh7XtagaPJI/AAAAAAAAE0c/esq86suRCp4/s1600-h/physx1.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/_hGl_uKJzpS0/Sh7XtagaPJI/AAAAAAAAE0c/esq86suRCp4/s1600-h/physx1.png" target="_self"></a><img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/Sh7XtagaPJI/AAAAAAAAE0c/esq86suRCp4/s400/physx1.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> <br><a data-tooltip-position="top" aria-label="http://2.bp.blogspot.com/_hGl_uKJzpS0/Sh7X9RwI42I/AAAAAAAAE0k/aWD0vp4xPks/s1600-h/physx2.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://2.bp.blogspot.com/_hGl_uKJzpS0/Sh7X9RwI42I/AAAAAAAAE0k/aWD0vp4xPks/s1600-h/physx2.png" target="_self"></a><img src="http://2.bp.blogspot.com/_hGl_uKJzpS0/Sh7X9RwI42I/AAAAAAAAE0k/aWD0vp4xPks/s400/physx2.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> <br><a data-tooltip-position="top" aria-label="http://3.bp.blogspot.com/_hGl_uKJzpS0/Sh7YCnMERPI/AAAAAAAAE0s/3DcOSKgVtQE/s1600-h/physx3.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://3.bp.blogspot.com/_hGl_uKJzpS0/Sh7YCnMERPI/AAAAAAAAE0s/3DcOSKgVtQE/s1600-h/physx3.png" target="_self"></a><img src="http://3.bp.blogspot.com/_hGl_uKJzpS0/Sh7YCnMERPI/AAAAAAAAE0s/3DcOSKgVtQE/s400/physx3.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> I have decided to share the Visual Studio 2008 project and source code to hopefully provide a nice starting point for others. I'm not using an official license or anything, but I'll state that is it free for whatever use you desire, be it commercial, hobby, or education. <br>Download the zip file: <a data-tooltip-position="top" aria-label="http://re-creationstudios.com/shared/PhysXDX10.zip" rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/shared/PhysXDX10.zip" target="_self">here</a> Next, I'm going to work on using static triangle meshes in PhysX to have a displaced sphere making up a planet, as well as using force fields to simulate planetary gravity.]]></description><link>https://glitchenzo.github.io/2009-05-28-physx-and-directx-10.html</link><guid isPermaLink="false">2009-05-28 - PhysX and DirectX 10.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:13 GMT</pubDate><enclosure url="http://4.bp.blogspot.com/_hGl_uKJzpS0/Sh7XtagaPJI/AAAAAAAAE0c/esq86suRCp4/s400/physx1.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/Sh7XtagaPJI/AAAAAAAAE0c/esq86suRCp4/s400/physx1.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2009-04-19 - Boxes, Cylinders, and Spheres (Oh My)]]></title><description><![CDATA[2009-04-19<a data-tooltip-position="top" aria-label="http://1.bp.blogspot.com/_hGl_uKJzpS0/Set2UIvP26I/AAAAAAAAExk/gJAEYxXL8Cc/s1600-h/shapes_wireframe.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://1.bp.blogspot.com/_hGl_uKJzpS0/Set2UIvP26I/AAAAAAAAExk/gJAEYxXL8Cc/s1600-h/shapes_wireframe.png" target="_self"></a><img src="http://1.bp.blogspot.com/_hGl_uKJzpS0/Set2UIvP26I/AAAAAAAAExk/gJAEYxXL8Cc/s400/shapes_wireframe.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> After deciding to use PhysX in combination with DirectX 11 last week, I thought about how I would go about drawing simple 3D shapes. In the samples and lessons, PhysX uses GLUT with has some shape drawing functions built-in. While DX9 has similar functions, neither DX10 nor XNA do. I believe it is safe to assume that DX11 will not have them either. I can understand why they were removed. They don't really make sense anymore in a programmable pipeline system. What is the vertex format of the shape created? While most people these days get around it by creating a mesh in a 3D modeling application and then importing it into their game, I prefer to have my simple 3D shapes constructed programatically. This allows me to easily change the detail of the mesh without worrying about exporting/importing an entire new model. Instead of implementing it in DX10 and C++ first, I decided to implement it in XNA. This allowed me to focus on the algorithms themselves and not have to worry about any C++ issues getting in the way. My initial implementation was a static class that had static methods in it that built the shapes and returned the vertex buffer and index buffer. This worked well, but I thought it still placed too much burden on the user to remember how many vertices they had just created and how many triangles they were going to draw. In order to make things simpler, I changed it to be a normal, instantiated class that contained the static methods that created an instance of the class. This allowed me to store the vertex count, triangle count, as well as the buffers in instance properties in the class. I even threw in a Draw method to make it incredibly simple to use the generated shape. Because this is such a basic, fundamental class that can benefit several people ( have seen various people requesting something like this), I have decided to share it with the public. You may download the C# file from here:<br>
<a rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/shared/Shape3D.cs" target="_self">http://re-creationstudios.com/shared/Shape3D.cs</a> You can also download the entire test project here:<br>
<a rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/shared/ShapeTest.zip" target="_self">http://re-creationstudios.com/shared/ShapeTest.zip</a> To use, simply create a shape using one of the static methods:
Shape3D sphere = Shape3D.CreateSphere(GraphicsDevice, 1, 12, 12); To draw, in your Effect block, call the Draw method on the shape:
sphere.Draw(GraphicsDevice); The Create methods are made to follow the same structure as the DX9 shape drawing functions. You can read more about those here:<br>
<a data-tooltip-position="top" aria-label="http://msdn.microsoft.com/en-us/library/bb172976%28VS.85%29.aspx" rel="noopener nofollow" class="external-link is-unresolved" href="http://msdn.microsoft.com/en-us/library/bb172976%28VS.85%29.aspx" target="_self">http://msdn.microsoft.com/en-us/library/bb172976(VS.85).aspx</a> <br><a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/_hGl_uKJzpS0/Set21Az6gwI/AAAAAAAAExs/uEkKdN3khc8/s1600-h/shapes_solid.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/_hGl_uKJzpS0/Set21Az6gwI/AAAAAAAAExs/uEkKdN3khc8/s1600-h/shapes_solid.png" target="_self"></a><img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/Set21Az6gwI/AAAAAAAAExs/uEkKdN3khc8/s400/shapes_solid.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved">]]></description><link>https://glitchenzo.github.io/2009-04-19-boxes,-cylinders,-and-spheres-(oh-my).html</link><guid isPermaLink="false">2009-04-19 - Boxes, Cylinders, and Spheres (Oh My).md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:13 GMT</pubDate><enclosure url="http://1.bp.blogspot.com/_hGl_uKJzpS0/Set2UIvP26I/AAAAAAAAExk/gJAEYxXL8Cc/s400/shapes_wireframe.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://1.bp.blogspot.com/_hGl_uKJzpS0/Set2UIvP26I/AAAAAAAAExk/gJAEYxXL8Cc/s400/shapes_wireframe.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2009-04-12 - Tactical RPG]]></title><description><![CDATA[2009-04-12I've been engrossed with learning about DX11 lately. I've looked at slide presentations, listened to audio recordings of speeches, and read various articles discussing the new features being introduced. I believe it's a great understatement to say that I'm excited about DX11. I've finally come to the conclusion that once I have a DX11 GPU, I'm going to rewrite my procedural planet code using DX11. In the meantime, I've decided to take about 1 month to implement a prototype for a tactical RPG I've been thinking about. I started about 2 weeks ago, and I plan to finish it by the end of April. One of my main goals is to have it completely mouse driven so that it can be played on a tablet. I believe it is coming along rather well. I have a really nice 2D camera set up that behaves similar to Google Maps. You can use the mouse to drag around the view and you can zoom in and out using the scroll wheel. I have basic movement and attacking implemented as well. I even have one of my graphic designer friends making up some art for me. Overall, it should shape up to be a pretty decent prototype. Maybe I will even release it to the public, source and all. PhysX New content for Banjo-Kazooie: Nuts &amp; Bolts was released last week. As a result, I pulled out the game again and played it some more. I wasted several hours just messing around with the vehicle editor to make various contraptions. I started thinking about how much fun it was to just tinker around like that without really following any goals, and then I started wondering about how hard it would be to implement a similar system myself. Almost 4 years ago, I had implemented a "domino simulator" using what was then known as the NovodeX physics engine. It is now known as PhysX, is owned by Nvidia, and has hardware acceleration. So, I downloaded the SDK and played around with some of the samples. First, the good. I was simply astounded by how many samples were provided in the SDK. There are 37 samples and 89 "lessons", all with documentation. It is amazing. Plus, the hardware acceleration really helps speed the physics engine up. One of the samples was getting about 40fps in software mode and 130fps in hardware mode. That was on a 9800M GT. The bad is more about C++ than PhysX. I decided to create a C++ project from scratch and then add all of the libraries and code necessary to get the first lesson from the SDK working. It was horrific. It took me 3 hours to get everything to compile and run. In the end, here is what was in my project: 5 include directories
3 static libraries added to both the project and VS itself had to add one directly to solution to get to compile
12 include files (separate from the include directories)
8 cpp files
1 dll Remember, all of that was to run the FIRST lesson, which is just three shapes on a plane. In C#, it would have been 3-4 DLLs and one CS file. As I said, this is more of a complaint about C++ and not PhysX. I forgot how tedious it was to setup a project for the first time. I do plan to stick with PhysX though, because once I do port my procedural planet code over to C++/DX11, then I will want a nice physics engine to go along with it, and it might was well be the only one with hardware acceleration. Until next time...]]></description><link>https://glitchenzo.github.io/2009-04-12-tactical-rpg.html</link><guid isPermaLink="false">2009-04-12 - Tactical RPG.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:12 GMT</pubDate></item><item><title><![CDATA[2009-03-18 - Craters]]></title><description><![CDATA[2009-03-18Another quick update. I have been working on adding craters to the procedural moon. I implemented a Voronoi diagram shader in HLSL and then I tweak it with quite a few different parameters to generate conical pits that are distorted slightly with fBm noise. <a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/_hGl_uKJzpS0/ScHmnrGSYII/AAAAAAAAEqk/2NcJ1ivHtMk/s1600-h/screenshot_633730149444987250.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/_hGl_uKJzpS0/ScHmnrGSYII/AAAAAAAAEqk/2NcJ1ivHtMk/s1600-h/screenshot_633730149444987250.png" target="_self"></a><img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/ScHmnrGSYII/AAAAAAAAEqk/2NcJ1ivHtMk/s400/screenshot_633730149444987250.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> <br><a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/_hGl_uKJzpS0/ScHmnHYkXpI/AAAAAAAAEqc/5NiwNLKnRLA/s1600-h/screenshot_633730148917177250.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/_hGl_uKJzpS0/ScHmnHYkXpI/AAAAAAAAEqc/5NiwNLKnRLA/s1600-h/screenshot_633730148917177250.png" target="_self"></a><img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/ScHmnHYkXpI/AAAAAAAAEqc/5NiwNLKnRLA/s400/screenshot_633730148917177250.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> <br><a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/_hGl_uKJzpS0/ScHmm8dJ6uI/AAAAAAAAEqU/4_wOvGBZRPM/s1600-h/screenshot_633730145382897250.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/_hGl_uKJzpS0/ScHmm8dJ6uI/AAAAAAAAEqU/4_wOvGBZRPM/s1600-h/screenshot_633730145382897250.png" target="_self"></a><img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/ScHmm8dJ6uI/AAAAAAAAEqU/4_wOvGBZRPM/s400/screenshot_633730145382897250.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> <br><a data-tooltip-position="top" aria-label="http://3.bp.blogspot.com/_hGl_uKJzpS0/ScHmmlzxFOI/AAAAAAAAEqM/KUTGvlrkGwk/s1600-h/screenshot_633730144191097250.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://3.bp.blogspot.com/_hGl_uKJzpS0/ScHmmlzxFOI/AAAAAAAAEqM/KUTGvlrkGwk/s1600-h/screenshot_633730144191097250.png" target="_self"></a><img src="http://3.bp.blogspot.com/_hGl_uKJzpS0/ScHmmlzxFOI/AAAAAAAAEqM/KUTGvlrkGwk/s400/screenshot_633730144191097250.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> I tried for quite a while to get rims around the edges of the craters, but I couldn't get it to work. I tried using a colormap to alter the Voronoi results, but I was having issues with the it. I will continue to tinker around with it because I think having rims would add quite a bit. Interesting fact: If I add even more fBm noise to the crater distortions, it forms pretty cool canyons: <br><a data-tooltip-position="top" aria-label="http://3.bp.blogspot.com/_hGl_uKJzpS0/ScHo20VExxI/AAAAAAAAEqs/1OmQc-LnC8E/s1600-h/screenshot_633730133103237250.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://3.bp.blogspot.com/_hGl_uKJzpS0/ScHo20VExxI/AAAAAAAAEqs/1OmQc-LnC8E/s1600-h/screenshot_633730133103237250.png" target="_self"></a><img src="http://3.bp.blogspot.com/_hGl_uKJzpS0/ScHo20VExxI/AAAAAAAAEqs/1OmQc-LnC8E/s400/screenshot_633730133103237250.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved">]]></description><link>https://glitchenzo.github.io/2009-03-18-craters.html</link><guid isPermaLink="false">2009-03-18 - Craters.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:11 GMT</pubDate><enclosure url="http://4.bp.blogspot.com/_hGl_uKJzpS0/ScHmnrGSYII/AAAAAAAAEqk/2NcJ1ivHtMk/s400/screenshot_633730149444987250.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/ScHmnrGSYII/AAAAAAAAEqk/2NcJ1ivHtMk/s400/screenshot_633730149444987250.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2009-03-03 - That's No Moon ...]]></title><description><![CDATA[2009-03-03Quick update. First, I switched to more "moon-like" textures. <a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/_hGl_uKJzpS0/Sa4cmIfH-nI/AAAAAAAAEoc/-j82Tr1Ti9E/s1600-h/screenshot_633716335233050000.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/_hGl_uKJzpS0/Sa4cmIfH-nI/AAAAAAAAEoc/-j82Tr1Ti9E/s1600-h/screenshot_633716335233050000.png" target="_self"></a><img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/Sa4cmIfH-nI/AAAAAAAAEoc/-j82Tr1Ti9E/s400/screenshot_633716335233050000.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> Then, I tweaked some of the parameters to my existing noise function. <br><a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/_hGl_uKJzpS0/Sa4c2LxT5qI/AAAAAAAAEok/e6AksskdaUA/s1600-h/screenshot_633716350965900000.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/_hGl_uKJzpS0/Sa4c2LxT5qI/AAAAAAAAEok/e6AksskdaUA/s1600-h/screenshot_633716350965900000.png" target="_self"></a><img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/Sa4c2LxT5qI/AAAAAAAAEok/e6AksskdaUA/s400/screenshot_633716350965900000.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> Finally, I started messing around with sums of two different noises. <br><a data-tooltip-position="top" aria-label="http://1.bp.blogspot.com/_hGl_uKJzpS0/Sa4dNPOIHhI/AAAAAAAAEos/jiyho6f4gzI/s1600-h/screenshot_633717145869190000.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://1.bp.blogspot.com/_hGl_uKJzpS0/Sa4dNPOIHhI/AAAAAAAAEos/jiyho6f4gzI/s1600-h/screenshot_633717145869190000.png" target="_self"></a><img src="http://1.bp.blogspot.com/_hGl_uKJzpS0/Sa4dNPOIHhI/AAAAAAAAEos/jiyho6f4gzI/s400/screenshot_633717145869190000.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> Here's a detail shot showing the "better" noise at the surface. <br><a data-tooltip-position="top" aria-label="http://1.bp.blogspot.com/_hGl_uKJzpS0/Sa4debv_RTI/AAAAAAAAEo0/NiTbHfeTc_o/s1600-h/screenshot_633717147640710000.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://1.bp.blogspot.com/_hGl_uKJzpS0/Sa4debv_RTI/AAAAAAAAEo0/NiTbHfeTc_o/s1600-h/screenshot_633717147640710000.png" target="_self"></a><img src="http://1.bp.blogspot.com/_hGl_uKJzpS0/Sa4debv_RTI/AAAAAAAAEo0/NiTbHfeTc_o/s400/screenshot_633717147640710000.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> There's a lot more work to do!]]></description><link>https://glitchenzo.github.io/2009-03-03-that's-no-moon-....html</link><guid isPermaLink="false">2009-03-03 - That's No Moon ....md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:36:04 GMT</pubDate><enclosure url="http://4.bp.blogspot.com/_hGl_uKJzpS0/Sa4cmIfH-nI/AAAAAAAAEoc/-j82Tr1Ti9E/s400/screenshot_633716335233050000.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/Sa4cmIfH-nI/AAAAAAAAEoc/-j82Tr1Ti9E/s400/screenshot_633716335233050000.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2009-02-19 - Fixed Lighting + Higher Res]]></title><description><![CDATA[2009-02-19As I mentioned in my previous post, I was getting some strange vertical lines appearing in my deferred lighting result. After I turned down the ambient light to make the lighting a bit more realistic, the lines became even more pronounced. Casting that problem aside for a bit, I decided to increase the resolution because 800x600 just wasn't cutting it anymore. I went with a widescreen resolution because both my laptop and my desktop have widescreen screens. I settled on 1280x720 because 1920x1200 would just be overkill right now, in my mind. The problem with increasing the resolution was that the lines got even worse! Now I was getting horizontal lines as well as vertical lines, so it looked like a big checkerboard mess. I spent several days trying to figure out what was going wrong. At first I thought it was a bad driver/GPU in my laptop. So, I went to test it on my desktop, but I found out that my power supply was dead. Luckily my brother let me remote into his PC and run the app. I got the exact same results, so I knew it wasn't my GPU. I then installed FX Composer to have a better debugging IDE. I soon discovered that I was using wrong texel offsets to sample neighbors in the world position texture. This removed the lines from FX Composer, but they were still appearing in XNA. I was messing around with my sampler filters when I finally fixed the problem by switching them from Point to Linear. While it does get rid of the lines, it comes at a cost. I am now getting about 18fps average. Obviously the change in resolution also figures into that as well. I have some interesting new screenshots to share. <a data-tooltip-position="top" aria-label="http://2.bp.blogspot.com/_hGl_uKJzpS0/SZ5fSps77nI/AAAAAAAAEnQ/g5orMF9GyQc/s1600-h/screenshot_633706820613754000.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://2.bp.blogspot.com/_hGl_uKJzpS0/SZ5fSps77nI/AAAAAAAAEnQ/g5orMF9GyQc/s1600-h/screenshot_633706820613754000.png" target="_self"></a><img src="http://2.bp.blogspot.com/_hGl_uKJzpS0/SZ5fSps77nI/AAAAAAAAEnQ/g5orMF9GyQc/s400/screenshot_633706820613754000.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> <br><a data-tooltip-position="top" aria-label="http://1.bp.blogspot.com/_hGl_uKJzpS0/SZ5ffHOIHqI/AAAAAAAAEnY/UOeqeanXSBw/s1600-h/screenshot_633706821899854000.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://1.bp.blogspot.com/_hGl_uKJzpS0/SZ5ffHOIHqI/AAAAAAAAEnY/UOeqeanXSBw/s1600-h/screenshot_633706821899854000.png" target="_self"></a><img src="http://1.bp.blogspot.com/_hGl_uKJzpS0/SZ5ffHOIHqI/AAAAAAAAEnY/UOeqeanXSBw/s400/screenshot_633706821899854000.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> <br><a data-tooltip-position="top" aria-label="http://1.bp.blogspot.com/_hGl_uKJzpS0/SZ5frUvLc_I/AAAAAAAAEng/uWii2u2Puls/s1600-h/screenshot_633706822814114000.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://1.bp.blogspot.com/_hGl_uKJzpS0/SZ5frUvLc_I/AAAAAAAAEng/uWii2u2Puls/s1600-h/screenshot_633706822814114000.png" target="_self"></a><img src="http://1.bp.blogspot.com/_hGl_uKJzpS0/SZ5frUvLc_I/AAAAAAAAEng/uWii2u2Puls/s400/screenshot_633706822814114000.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> <br><a data-tooltip-position="top" aria-label="http://1.bp.blogspot.com/_hGl_uKJzpS0/SZ5fzF4UR_I/AAAAAAAAEno/YyBJarON4z0/s1600-h/screenshot_633706823310614000.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://1.bp.blogspot.com/_hGl_uKJzpS0/SZ5fzF4UR_I/AAAAAAAAEno/YyBJarON4z0/s1600-h/screenshot_633706823310614000.png" target="_self"></a><img src="http://1.bp.blogspot.com/_hGl_uKJzpS0/SZ5fzF4UR_I/AAAAAAAAEno/YyBJarON4z0/s400/screenshot_633706823310614000.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved">]]></description><link>https://glitchenzo.github.io/2009-02-19-fixed-lighting-+-higher-res.html</link><guid isPermaLink="false">2009-02-19 - Fixed Lighting + Higher Res.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:56 GMT</pubDate><enclosure url="http://2.bp.blogspot.com/_hGl_uKJzpS0/SZ5fSps77nI/AAAAAAAAEnQ/g5orMF9GyQc/s400/screenshot_633706820613754000.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://2.bp.blogspot.com/_hGl_uKJzpS0/SZ5fSps77nI/AAAAAAAAEnQ/g5orMF9GyQc/s400/screenshot_633706820613754000.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2009-02-08 - Deferred Lighting]]></title><description><![CDATA[2009-02-08This weekend I implemented a lighting system like the one I talked about in my last two blog posts. I'm calling it deferred lighting because it doesn't do any lighting calculation until I have render targets for the scene. I have one render pass that has two targets: one containing the diffuse color of the scene, and the other containing the world position of each pixel. In a second render pass, I calculate the normal of each pixel by sampling it's neighboring pixel world positions. I then simply do a standard lighting calculation using the normal and the diffuse color of the scene. It also has much better performance compared to the brute force 32 noise calculations method. At low altitudes I was getting 16fps with the noise method and 33fps with the deferred method. At high altitudes I was getting 12fps and 30fps, respectively. As you can see, I was getting at least double the framerate all the time. Now for some pretty pictures. They are not much different from my previous lighting pictures, the important thing is that they are being rendered much faster now. I also fixed a slight bug I had in the previous lighting that made the light direction the same for every side of the planet (there was no dark side). There are some strange vertical lines that are appearing which you can see in some of the screenshots below. I'm not sure why they are there, but I will continue to investigate them. <a data-tooltip-position="top" aria-label="http://2.bp.blogspot.com/_hGl_uKJzpS0/SY-P7XdPDlI/AAAAAAAAElU/haYTnNZIa-g/s1600-h/screenshot_633697120860460000.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://2.bp.blogspot.com/_hGl_uKJzpS0/SY-P7XdPDlI/AAAAAAAAElU/haYTnNZIa-g/s1600-h/screenshot_633697120860460000.png" target="_self"></a><img src="http://2.bp.blogspot.com/_hGl_uKJzpS0/SY-P7XdPDlI/AAAAAAAAElU/haYTnNZIa-g/s400/screenshot_633697120860460000.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> <br><a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/_hGl_uKJzpS0/SY-QPSjh9wI/AAAAAAAAElc/XvHhxikWE0s/s1600-h/screenshot_633697121969750000.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/_hGl_uKJzpS0/SY-QPSjh9wI/AAAAAAAAElc/XvHhxikWE0s/s1600-h/screenshot_633697121969750000.png" target="_self"></a><img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/SY-QPSjh9wI/AAAAAAAAElc/XvHhxikWE0s/s400/screenshot_633697121969750000.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> <br><a data-tooltip-position="top" aria-label="http://3.bp.blogspot.com/_hGl_uKJzpS0/SY-QXVsQH7I/AAAAAAAAElk/HANxU-XqM7Q/s1600-h/screenshot_633697122316720000.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://3.bp.blogspot.com/_hGl_uKJzpS0/SY-QXVsQH7I/AAAAAAAAElk/HANxU-XqM7Q/s1600-h/screenshot_633697122316720000.png" target="_self"></a><img src="http://3.bp.blogspot.com/_hGl_uKJzpS0/SY-QXVsQH7I/AAAAAAAAElk/HANxU-XqM7Q/s400/screenshot_633697122316720000.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> <br><a data-tooltip-position="top" aria-label="http://1.bp.blogspot.com/_hGl_uKJzpS0/SY-QfvyRj1I/AAAAAAAAEls/5_CFz5Fv0m4/s1600-h/screenshot_633697122704560000.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://1.bp.blogspot.com/_hGl_uKJzpS0/SY-QfvyRj1I/AAAAAAAAEls/5_CFz5Fv0m4/s1600-h/screenshot_633697122704560000.png" target="_self"></a><img src="http://1.bp.blogspot.com/_hGl_uKJzpS0/SY-QfvyRj1I/AAAAAAAAEls/5_CFz5Fv0m4/s400/screenshot_633697122704560000.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> In the last picture you can see the detailed designs that are being generated for the terrain itself. Just to show a difference between the lit vs diffuse renderings, here is the diffuse texture alone for the last picture. <br><a data-tooltip-position="top" aria-label="http://3.bp.blogspot.com/_hGl_uKJzpS0/SY-RDnRDTJI/AAAAAAAAEl0/3AElfSrodCg/s1600-h/diffuse.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://3.bp.blogspot.com/_hGl_uKJzpS0/SY-RDnRDTJI/AAAAAAAAEl0/3AElfSrodCg/s1600-h/diffuse.png" target="_self"></a><img src="http://3.bp.blogspot.com/_hGl_uKJzpS0/SY-RDnRDTJI/AAAAAAAAEl0/3AElfSrodCg/s400/diffuse.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved">]]></description><link>https://glitchenzo.github.io/2009-02-08-deferred-lighting.html</link><guid isPermaLink="false">2009-02-08 - Deferred Lighting.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:55 GMT</pubDate><enclosure url="http://2.bp.blogspot.com/_hGl_uKJzpS0/SY-P7XdPDlI/AAAAAAAAElU/haYTnNZIa-g/s400/screenshot_633697120860460000.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://2.bp.blogspot.com/_hGl_uKJzpS0/SY-P7XdPDlI/AAAAAAAAElU/haYTnNZIa-g/s400/screenshot_633697120860460000.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2008-12-22 - Starfields  Nebulas]]></title><description><![CDATA[2008-12-22Instead of focusing on craters (which I implied I was going to do last time), I decided to look into generating starfields and distant (ie 2D) nebulas. I started on simple starfields and I had a working solution in less than an hour by simply drawing star sprites in random positions. This yields the following result:
<a data-tooltip-position="top" aria-label="http://1.bp.blogspot.com/_hGl_uKJzpS0/SU9VRM5DmhI/AAAAAAAAEgY/6-ar9ics2Oc/s1600-h/stars.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://1.bp.blogspot.com/_hGl_uKJzpS0/SU9VRM5DmhI/AAAAAAAAEgY/6-ar9ics2Oc/s1600-h/stars.png" target="_self"></a><img src="http://1.bp.blogspot.com/_hGl_uKJzpS0/SU9VRM5DmhI/AAAAAAAAEgY/6-ar9ics2Oc/s400/stars.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> Next, in order to make the stars more interesting, I looked into implementing nebula clouds. I knew that some summation of Perlin Noise would be the best solution. So, I decided to implement a Perlin Noise function in C#. I have a really fast implementation in HLSL, but I wanted the full power of breakpoints and variable watches. I ended up using a standard fBm summation with an exponential filter applied to it. This helped to produce this nebula cloud image:<br>
<a data-tooltip-position="top" aria-label="http://3.bp.blogspot.com/_hGl_uKJzpS0/SU9WoJHNNOI/AAAAAAAAEgg/xU5RIUQoAf8/s1600-h/nebula.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://3.bp.blogspot.com/_hGl_uKJzpS0/SU9WoJHNNOI/AAAAAAAAEgg/xU5RIUQoAf8/s1600-h/nebula.png" target="_self"></a><img src="http://3.bp.blogspot.com/_hGl_uKJzpS0/SU9WoJHNNOI/AAAAAAAAEgg/xU5RIUQoAf8/s400/nebula.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> I still need to blend these two results together and construct them into a decent cubemap. World of Warcraft + 360 Controller All of that work done on the starfields and nebulas was done a couple weeks ago. My co-workers recently pressured me into playing World of Warcraft again. (About 6 months ago, I got up to level 18, and then quit.) As I was playing I kept thinking about how bad the controls were. I was moving my hands all over the keyboard to use all of my skills. It was fine for just grinding along and completing quests, but grouping and duels I always performed horribly. I desparately wanted to play with a game controller, however World of Warcraft didn't support them. There were a couple of applications that other people had written to allow gamepads, but I didn't care for them either. One was very ackward and built up macro commands that you had to then "submit" by pulling the right trigger. Another one seemed decent, but it had a subscription fee of $20 a year. I decided that if I wanted something done right, I had to do it myself. So, I threw together a quick XNA application that read the 360 controller input. It would then use the Win32 function SendInput to place keyboard and mouse input events into the Windows input queue. I mapped out all of the controls and I was then able to play World of Warcraft using a 360 controller! I can target enemies, target allies, use all 12 skills on the current action bar, switch action bars, loot corpses, and even move the camera with full analog control using the 360 controller! It has completely changed the game for me and I even won my first duel last night. I have now taken the app and added in mappings for Call of Duty 4 for my brother. I'm planning on converting the project to be more generalized so that the input mapping can be defined in XML and easily changed without recompiling.]]></description><link>https://glitchenzo.github.io/2008-12-22-starfields-nebulas.html</link><guid isPermaLink="false">2008-12-22 - Starfields  Nebulas.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:51 GMT</pubDate><enclosure url="http://1.bp.blogspot.com/_hGl_uKJzpS0/SU9VRM5DmhI/AAAAAAAAEgY/6-ar9ics2Oc/s400/stars.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://1.bp.blogspot.com/_hGl_uKJzpS0/SU9VRM5DmhI/AAAAAAAAEgY/6-ar9ics2Oc/s400/stars.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2008-12-04 - Lighting Revisited (AKA I'm Back)]]></title><description><![CDATA[2008-12-04So, after almost 3 months of being sidetracked with various other projects I came up with, I finally decided to come back to C# and XNA with welcome arms. And I have come back in a big way, in my opinion. After discussing it with one of my friends, I decided that it would be best to procedurally generate a moon instead of a planet. This greatly simplifies many things; no atmosphere, no fog, no water, no vegetation, etc. However, this meant that I needed to figure out how to properly do two things: generate craters and have realistic lighting. You may recall that I had a previous blog entry about my attempts with realistic lighting. [<a rel="noopener nofollow" class="external-link is-unresolved" href="http://recreationstudios.blogspot.com/2008/07/do-you-see-light.html" target="_self">http://recreationstudios.blogspot.com/2008/07/do-you-see-light.html</a>] In the end, I determined that it would be too difficult to do now, and easy to do in the future once I had geometry shader support. So, I had settled with simple spherical lighting across the entire planet. So, it took me quite a bit of effort to even start looking at alternative ways to render realistic lighting. In the past I was trying to calculate the other two vertices of the triangle in the vertex shader. It was with a great facepalm that I realized that what I was trying to find was the tangent of the surface and then I could use that to adjust the spherical normal. Well, as you may remember from your math classes, a tangent is calculated by taking the derivative of the original function. So, I looked into quite a few articles about how to find the derivative of a Perlin Noise function. This article was very informative, but I wasn't quite sure on what speeds would be on the GPU:<br>
<a rel="noopener nofollow" class="external-link is-unresolved" href="http://rgba.scenesp.org/iq/computer/articles/morenoise/morenoise.htm" target="_self">http://rgba.scenesp.org/iq/computer/articles/morenoise/morenoise.htm</a> Finally, I found an article by Ken Perlin himself that shows how to approximate the derivative:<br>
<a data-tooltip-position="top" aria-label="http://http.developer.nvidia.com/GPUGems/gpugems_ch05.html" rel="noopener nofollow" class="external-link is-unresolved" href="http://http.developer.nvidia.com/GPUGems/gpugems_ch05.html" target="_self">http://http.developer.nvidia.com/GPUGems/gpugems_ch05.html</a> (Section 5.6) With this little nugget of knowlege I went into my shader and wrote a function to do exactly that. float3 NoiseDerivative(float3 position, float e)
{
//calculate the height values using Perlin Noise
float F0 = ridgedmf(position*noiseScale, 8);
float Fx = ridgedmf(float3(position.x+e, position.y, position.z)*noiseScale, 8);
float Fy = ridgedmf(float3(position.x, position.y+e, position.z)*noiseScale, 8);
float Fz = ridgedmf(float3(position.x, position.y, position.z+e)*noiseScale, 8);
float3 dF = float3(Fx-F0, Fy-F0, Fz-F0) / e; //calculate the actual normal return normalize(position - dF); } Then I simply added a call to this function in my pixel shader:
input.Normal = NoiseDerivative(input.Normal, 0.000001); Lo and behold, it worked! Check out the pics:<br>
<a data-tooltip-position="top" aria-label="http://3.bp.blogspot.com/_hGl_uKJzpS0/STjiaeajk-I/AAAAAAAAD_Q/lGYb2fiPP0U/s1600-h/screenshot_633640314480390000.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://3.bp.blogspot.com/_hGl_uKJzpS0/STjiaeajk-I/AAAAAAAAD_Q/lGYb2fiPP0U/s1600-h/screenshot_633640314480390000.png" target="_self"></a><img src="http://3.bp.blogspot.com/_hGl_uKJzpS0/STjiaeajk-I/AAAAAAAAD_Q/lGYb2fiPP0U/s400/screenshot_633640314480390000.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> <br><a data-tooltip-position="top" aria-label="http://2.bp.blogspot.com/_hGl_uKJzpS0/STjis9AcQhI/AAAAAAAAD_Y/5J1pSE5BFWs/s1600-h/screenshot_633640314863860000.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://2.bp.blogspot.com/_hGl_uKJzpS0/STjis9AcQhI/AAAAAAAAD_Y/5J1pSE5BFWs/s1600-h/screenshot_633640314863860000.png" target="_self"></a><img src="http://2.bp.blogspot.com/_hGl_uKJzpS0/STjis9AcQhI/AAAAAAAAD_Y/5J1pSE5BFWs/s400/screenshot_633640314863860000.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved">]]></description><link>https://glitchenzo.github.io/2008-12-04-lighting-revisited-(aka-i'm-back).html</link><guid isPermaLink="false">2008-12-04 - Lighting Revisited (AKA I'm Back).md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:50 GMT</pubDate><enclosure url="http://3.bp.blogspot.com/_hGl_uKJzpS0/STjiaeajk-I/AAAAAAAAD_Q/lGYb2fiPP0U/s400/screenshot_633640314480390000.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://3.bp.blogspot.com/_hGl_uKJzpS0/STjiaeajk-I/AAAAAAAAD_Q/lGYb2fiPP0U/s400/screenshot_633640314480390000.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2008-11-07 - Sidetracked]]></title><description><![CDATA[2008-11-07Wow, it has been awhile and I haven't really had time to work on my graphics projects. I have been really busy at work. When I do finally make it home, I usually get sidetracked with other things. I finally got to level 60 in Mass Effect. I am over halfway through the excellent novel Prey by Michael Crichton (I can't believe he's dead now). I have also been piecing together ideas for my own novel (I've always wanted to write a novel). In terms of the DirectX 10 work, I did manage to get multiple render targets working. However, I got sidetracked by a bright idea I came up with involving using "strokes" generated in the geometry shader to do some NPR post processing. I was having a hell of a time trying to get multiple vertex buffers working. As I was investigating though, I found out that it wouldn't work anyway because the buffer size is limited to 16-bits (65,536 vertices). I needed more than that ... alot more. It would be a rather long explanation to explain why, so I'll just say that I was trying to essentially use the vertex shader as a pixel shader. XNA 3.0 is out now, and I'm really surprised that I have not yet downloaded it. It sounds like they added in some nice features though (new Media classes, ClickOnce deployment, etc.). I am really missing C#, so I may just go back to XNA and just wait for it (or some other C# graphics library) to get Geometry Shader support. I was also reading about some of the features that are going to be in C# 4.0, and I am really excited. They are finally adding in optional parameters. Plus they are adding a dynamic type, which could prove useful in some cases.]]></description><link>https://glitchenzo.github.io/2008-11-07-sidetracked.html</link><guid isPermaLink="false">2008-11-07 - Sidetracked.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:50 GMT</pubDate></item><item><title><![CDATA[2008-10-07 - It's getting close]]></title><description><![CDATA[2008-10-07I've been continuing my work in DirectX 10, and it has been relatively slow progress, but progress nonetheless. I managed to render the simple character model that comes with the DirectX SDK using the first pass of my pencil shader. The first pass applies 6 different pencil textures based upon how lit that part of the model is. It is currently using the given texture coordinates of the model, so it doesn't look as good as it potentially could. That's an improvement for another time though. I have been busy working on getting the second pass of the pencil shader working. It's pretty much just a Sobel filter that is applied to the normal map of the scene. In order to get the Sobel filter working though, I had to first figure out how to do post-processing image filters in DirectX 10. Obviously the first step was to render a full-screen textured quad. In XNA, I "cheated" and just used a SpriteBatch. It's not the most efficient way, but it allowed for the fastest development. There ARE sprites in DX10, but I figured I might as well do it the "proper" way this time. So, I set up my own vertex format (with Position and Texure Coords), created my own vertex buffer (with the 4 vertices positioned in clipspace), and my own index buffer. I then wrote a simple shader that simply passed the vertices through the vertex shader, and applied the texture in the pixel shader. I fired up the app for the first time and Vista completely froze! Ctrl-Alt-Del didn't work, the mouse didn't move, nothing. So I shut it down and restarted and I got the Blue Screen of Death! I booted back into Safe mode and it said that my video card driver had gotten screwed up. I was able to boot back into Windows regularly the next time without changing anything. I set a breakpoint in my code and stepped through the Update/Render loop about a dozen times without any errors, so I just let it run free again. The exact same problems occurred again, thus causing a reboot. I had no idea what I was doing wrong to screw up my computer, so I looked at several of the DX tutorials line by line. I realized that I had forgotten to tell the video card what my vertex input layout was. I added in the 3 lines of code to do it, and bam, everything worked! So I now have full screen textured quads working in DX10. An added bonus is since I positioned the vertices in clipspace, then it works on any resolution without requiring any updates or changes, plus there are no matrix multiplications that are needed to be done. The next task I have to work on is to get mutiple render targets working in DX10. I need this because as I mentioned earlier, my goal is to render a normal map of the scene, and then pass that normal map into the Sobel filter shader.]]></description><link>https://glitchenzo.github.io/2008-10-07-it's-getting-close.html</link><guid isPermaLink="false">2008-10-07 - It's getting close.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:49 GMT</pubDate></item><item><title><![CDATA[2008-09-26 - DirectX 10]]></title><description><![CDATA[2008-09-26I've decided to finally start dabbling with DirectX 10. The main reason behind it is that I want to work with Geometry Shaders. There is no official C# wrapper around DX10, but I did manage to find two third-party ones. One had not been updated since April 2006, so I threw that one out the window. The other, SlimDX, has been in very active development and a new version was just released this month. I downloaded it and played with some of the samples and was rather impressed. However, SlimDX also provides a wrapper around DX9 and it is very clear that that was the priority of the project. There are quite a few things missing from the DX10 wrapper that would have been very useful. So, instead of fighting through a third-party C# wrapper, I figured I might as well go back to the straight C++ version. This has the advantage of having tons of official samples and tutorials from Microsoft. However, this has the major disadvantage that I have not worked in C++ directly for almost 4 years. It is rather rough going back to C++ from C#. There were so many helpful things built into C# that aided in rapid development. I mean, C++ doesn't even have a string type, you have to use char arrays. (Edit: I forgot that it does support strings, but you have to include the header for it first. Doh!) I feel like I'm stepping back into the dark ages! :-P I'm hoping to have just the basic C++ code to draw a model using a shader, and then all of the rest of my work will be in HLSL. We shall see! (Edit: I found a really helpful C++ tutorial for getting me back up to speed. <a rel="noopener nofollow" class="external-link is-unresolved" href="http://www.cplusplus.com/doc/tutorial/" target="_self">http://www.cplusplus.com/doc/tutorial/</a> )]]></description><link>https://glitchenzo.github.io/2008-09-26-directx-10.html</link><guid isPermaLink="false">2008-09-26 - DirectX 10.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:49 GMT</pubDate></item><item><title><![CDATA[2008-09-14 - Switching Gears]]></title><description><![CDATA[2008-09-14So I was chatting with one of my friends about what was up next on the todo list for my procedural planet. I explained that I was working on fog and that after that I would focus on water. He suggested that I get HDR and Depth of Field put in next. I then mentioned how I want to get Atmospheric Scattering in as well. With all of these features laid out, the project seems rather daunting. That is easily several months worth of work right there. (I still do have a full time job!) I started thinking about how to make it easier, yet still make it stand out. I mean no matter how many awesome looking things I put in, I will never even come close to the level of Crysis. I am only one guy! So, I decided I should focus more on something that would be feasible for a team of one to accomplish in a lifetime. Time for a personal history lesson! Back when I first started fiddling around with XNA (over 2 years ago now), I also started looking into shaders for the first time. I have always been interested in Non-Photorealistic Rendering (cel shading, painterly rendering, hatching, etc), so I thought that might be a good subject to test with shaders. In my research, I came across a great paper about doing real-time pencil sketch rendering. <a data-tooltip-position="top" aria-label="http://cg.postech.ac.kr/research/pencil_rendering/" rel="noopener nofollow" class="external-link is-unresolved" href="http://cg.postech.ac.kr/research/pencil_rendering/" target="_self">http://cg.postech.ac.kr/research/pencil_rendering/</a> In January 2007, I began work on my own pencil shader. I actually started with 4 separate shaders that would require all models to be rendered 4 times. Fairly quickly I realised that I could speed things up greatly by having 1 shader with 4 passes. I tinkered around with it, and other things, for several months before I found out about using multiple render targets. Using this, I was able to get it down to 3 passes. Not long after that, I demoed the shader in a job interview and I actually got a job as an XNA Game Developer! That job lasted until the company got bought out by a larger company. Toward the end of my employment there, I started getting into procedural generatation, and that's how I came to have the procedural planet that I have today. As you know, I have a new laptop now, and during the transfer of files from my old laptop, I saw my old pencil shader again. It had gone untouched since the day I demoed it in my job interview. Yesterday I finally decided to take all of the code and update it to XNA 2.0 and clean up what I could. I realized that I had learned quite a bit over the last year about both XNA and C#, so I was able to make the code much cleaner. Not only that, but I was also able to get the shader down to 2 passes! This gave me a 100fps speed boost. (On my GeForce 9800 GT, the 4 pass = 470fps, 3 pass = 480fps, 2 pass = 580fps.) This has really given me a desire to work on NPR stuff again. So, currently my next goal is to have a procedural planet that is rendered using my pencil shader.]]></description><link>https://glitchenzo.github.io/2008-09-14-switching-gears.html</link><guid isPermaLink="false">2008-09-14 - Switching Gears.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:49 GMT</pubDate></item><item><title><![CDATA[2008-09-02 - Procedural Texturing]]></title><description><![CDATA[2008-09-02Well I am now producing what in my opinion are decent procedural textures for the planetary terrain. They are generated per pixel every frame. This has the advantage of allowing infinite resolution as well as eliminating any texture coordinate warpings around a sphere, since the textures are actually 3D. As I mentioned before, this does require a significant performance hit. I have managed to simplify the texture generation to the point of having reasonable framerates while maintaining decent texture quality. What I am doing is calculating 4 separate textures using 2 octaves of turbulence noise at different scales for each one. These 4 textures represent sand, grass, rock, and snow. They are then blended together based upon the terrain height to generate a final texture. I am getting anywhere between 25-50 frames per second depending upon how many pixels of the terrain are taking up the viewport. The average for normal travel is 35 frames per second. Here are some screenshots of the results.
<a data-tooltip-position="top" aria-label="http://3.bp.blogspot.com/_hGl_uKJzpS0/SL4ZGiOwXTI/AAAAAAAAD1Q/_1N8grogr3w/s1600-h/screenshot_633559021775571043.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://3.bp.blogspot.com/_hGl_uKJzpS0/SL4ZGiOwXTI/AAAAAAAAD1Q/_1N8grogr3w/s1600-h/screenshot_633559021775571043.png" target="_self"></a><img src="http://3.bp.blogspot.com/_hGl_uKJzpS0/SL4ZGiOwXTI/AAAAAAAAD1Q/_1N8grogr3w/s400/screenshot_633559021775571043.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"><a data-tooltip-position="top" aria-label="http://3.bp.blogspot.com/_hGl_uKJzpS0/SL4ZRamtO4I/AAAAAAAAD1Y/u1KHgUVFV8s/s1600-h/screenshot_633559024006521043.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://3.bp.blogspot.com/_hGl_uKJzpS0/SL4ZRamtO4I/AAAAAAAAD1Y/u1KHgUVFV8s/s1600-h/screenshot_633559024006521043.png" target="_self"></a><img src="http://3.bp.blogspot.com/_hGl_uKJzpS0/SL4ZRamtO4I/AAAAAAAAD1Y/u1KHgUVFV8s/s400/screenshot_633559024006521043.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"><a data-tooltip-position="top" aria-label="http://3.bp.blogspot.com/_hGl_uKJzpS0/SL4Zcx-XfsI/AAAAAAAAD1g/zoXxPe4FMbo/s1600-h/screenshot_633559888068550000.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://3.bp.blogspot.com/_hGl_uKJzpS0/SL4Zcx-XfsI/AAAAAAAAD1g/zoXxPe4FMbo/s1600-h/screenshot_633559888068550000.png" target="_self"></a><img src="http://3.bp.blogspot.com/_hGl_uKJzpS0/SL4Zcx-XfsI/AAAAAAAAD1g/zoXxPe4FMbo/s400/screenshot_633559888068550000.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved">]]></description><link>https://glitchenzo.github.io/2008-09-02-procedural-texturing.html</link><guid isPermaLink="false">2008-09-02 - Procedural Texturing.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:49 GMT</pubDate><enclosure url="http://3.bp.blogspot.com/_hGl_uKJzpS0/SL4ZGiOwXTI/AAAAAAAAD1Q/_1N8grogr3w/s400/screenshot_633559021775571043.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://3.bp.blogspot.com/_hGl_uKJzpS0/SL4ZGiOwXTI/AAAAAAAAD1Q/_1N8grogr3w/s400/screenshot_633559021775571043.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2008-09-01 - New Laptop, New Opportunities]]></title><description><![CDATA[2008-09-01It's been awhile since I've written an update. As expected I got slightly side-tracked by Too Human, but what was an even worse offender was Mass Effect. I picked it up at a sale at Toys R Us, and I became addicted to it. I am currently working on my third playthrough of the game. I finally received my new laptop 3 days ago. I haven't had much time to do programming on it because I had to first install all of my desired applications, transfer all of my files from my old laptop, and then prepare my old laptop for my sister. I did manage to run a "benchmark" on the new laptop though. In the past, I wrote an XNA app that generates a texture using Perlin Noise in a pixel shader. This is usually a good evaluator of a GPU's performance. Here are some specs: Generating 12 octaves of 1024x1024 3D fractional Brownian motion Perlin Noise:
8600 GT ~20 frames per second
9800 GT ~80 frames per second Yep! My new laptop's GPU is 4 times faster than my desktop! Just to put a little perspective on it, these results mean that my new GPU was performing over 1 billion perlin noise calculations a second! I also started fiddling around briefly with generating procedural textures for the planetary terrain. My idea was to use 4 different noise calculations per pixel and then blend the results together based on the planetary height of the pixel. As expected though, there was a severe penalty for doing a noise calculation per pixel. I never did get up to 4 calculations. Here are my initial findings, on my 9800 GT of course! ~120 fps using 4 existing textures
~40 fps using 1 8-octave ridged multifractal per pixel
~30 fps using 2 8-octave ridged multifractals per pixel The performance hit is not linear though, so I expect that if I did 4 noise calcs, I would be getting about 20fps. However, that is on a 9800 GT, which is one of the best cards on the market now. Sure there are about half a dozen better cards, but how many people really have them? I do have some ideas to potentially speed it up though. I could reduce the number of octaves, but then increase the scale. I could also try to make a fancy gradient so that I don't have to use as many different noise calcs. Here are some screenshots showing different simple gradients using just 1 noise calc.<a data-tooltip-position="top" aria-label="http://2.bp.blogspot.com/_hGl_uKJzpS0/SLxCVK3PfbI/AAAAAAAAD1A/nSyuGhur5M0/s1600-h/screenshot_633558672610121043.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://2.bp.blogspot.com/_hGl_uKJzpS0/SLxCVK3PfbI/AAAAAAAAD1A/nSyuGhur5M0/s1600-h/screenshot_633558672610121043.png" target="_self"></a><img src="http://2.bp.blogspot.com/_hGl_uKJzpS0/SLxCVK3PfbI/AAAAAAAAD1A/nSyuGhur5M0/s400/screenshot_633558672610121043.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"><a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/_hGl_uKJzpS0/SLxBk9g-0wI/AAAAAAAAD04/rgXmF70DPLw/s1600-h/screenshot_633558672309191043.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/_hGl_uKJzpS0/SLxBk9g-0wI/AAAAAAAAD04/rgXmF70DPLw/s1600-h/screenshot_633558672309191043.png" target="_self"></a><img src="http://4.bp.blogspot.com/_hGl_uKJzpS0/SLxBk9g-0wI/AAAAAAAAD04/rgXmF70DPLw/s400/screenshot_633558672309191043.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> <br><a data-tooltip-position="top" aria-label="http://2.bp.blogspot.com/_hGl_uKJzpS0/SLxCkHgnqMI/AAAAAAAAD1I/ySpal6nGsKY/s1600-h/screenshot_633558673372751043.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://2.bp.blogspot.com/_hGl_uKJzpS0/SLxCkHgnqMI/AAAAAAAAD1I/ySpal6nGsKY/s1600-h/screenshot_633558673372751043.png" target="_self"></a><img src="http://2.bp.blogspot.com/_hGl_uKJzpS0/SLxCkHgnqMI/AAAAAAAAD1I/ySpal6nGsKY/s400/screenshot_633558673372751043.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved">]]></description><link>https://glitchenzo.github.io/2008-09-01-new-laptop,-new-opportunities.html</link><guid isPermaLink="false">2008-09-01 - New Laptop, New Opportunities.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:48 GMT</pubDate><enclosure url="http://2.bp.blogspot.com/_hGl_uKJzpS0/SLxCVK3PfbI/AAAAAAAAD1A/nSyuGhur5M0/s400/screenshot_633558672610121043.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://2.bp.blogspot.com/_hGl_uKJzpS0/SLxCVK3PfbI/AAAAAAAAD1A/nSyuGhur5M0/s400/screenshot_633558672610121043.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2008-08-17 - Relaxing]]></title><description><![CDATA[2008-08-17I decided that since I had accomplished so much by pretty much working non-stop for almost a month, I was going to take a break for a bit. So, I have not worked on my procedural planet for this past week. Of course, I could never really break myself away from it, so I have been reading books and websites to research the next phase. I even put together an HLSL project to do some experimentation. So, don't worry, progress is still being made, just at a much slower rate now. I'm guessing I will start working on it again this week. After I get my new laptop (sometime after the 28th) I'm hoping to really pick up the pace again. Although, I do have a word of warning: I may get distracted with DirectX 10 and Geometry Shaders. We shall see. (Not to mention that Too Human comes out on Tuesday, Tales of Vesperia next week, Infinite Undiscovery the week after, and Spore the week after that! Too many good games coming out so soon.) Until next time.]]></description><link>https://glitchenzo.github.io/2008-08-17-relaxing.html</link><guid isPermaLink="false">2008-08-17 - Relaxing.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:48 GMT</pubDate></item><item><title><![CDATA[2008-08-10 - Success]]></title><description><![CDATA[2008-08-10I have completed the items on my to-do list! I finally stopped the terrain from disappearing (for the most part ... I still had two instances where it happened). I discovered that I had a key subtraction backwards. How it even worked at all before, I will never know. I got each terrain level to move at its own stepping distance by storing and updating a world matrix for each level. Luckily my CPU was hardly being used at all so I could easily spare the CPU cycles to do these extra calculations. I fixed the gap between separate levels by simply making the square mesh slightly larger. Previously, the mesh would extend from (-1, -1) to (1, 1), but I updated it so that the range is (-1.25, -1.25) to (1.25, 1.25). Now for what you've been waiting for: a new video. In fact this time I have two new videos for your enjoyment. One showing off the new terrain, and another showing it in wireframe mode. Normal Terrain: Wireframe: On a separate note I just ordered a new laptop, so I will finally be able to do development on my laptop again. My current laptop only has a GeForce 6100, so it couldn't handle my shaders anymore (no unified pipeline). My new laptop has a GeForce 9800 GT which is about 20 times faster than my current GPU. It will be awesome!]]></description><link>https://glitchenzo.github.io/2008-08-10-success.html</link><guid isPermaLink="false">2008-08-10 - Success.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:47 GMT</pubDate></item><item><title><![CDATA[2008-08-06 - No real progress]]></title><description><![CDATA[2008-08-06I have been busy playing Braid, which is a great game that just got released on the Xbox Live Arcade. Therefore, I haven't really put much time into the procedural planet. I did put in some code that would always display the calculated angle between the camera and the terrain mesh in order to see if that was causing the disappearing errors. I actually believe it is, although I'm not quite sure why. First, I was surprised to see that probably a quarter of the time, the result was NaN. Even more surprising is that my terrain works perfectly even when the result is NaN. The errors occur when the result suddenly comes back as pi randomly. I should never be getting an angle that big back. Heck I shouldn't ever be getting pi/2. I will continue to investigate this problem (when I have time between Braid of course).]]></description><link>https://glitchenzo.github.io/2008-08-06-no-real-progress.html</link><guid isPermaLink="false">2008-08-06 - No real progress.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:47 GMT</pubDate></item><item><title><![CDATA[2008-08-02 - Everything revolves around the camera]]></title><description><![CDATA[2008-08-02Well I fixed the problems I was having with the camera. First, let me explain why I was having trouble. I had my planet centered at the origin (0,0,0) and I gave it a radius of about 6.5 million meters. I initialized the camera position to be right at ground level of the planet (6.5 million meters plus the height of the tallest mountain [I use 100,000 meters]). My camera always looks at a spot 1 meter in front of its position. Once you are dealing with positions up in the millions (about 6.6 million), the accuracy is lost and so it doesn't always register that 1 meter difference. I found an article online where someone was having similar issues with having the sun at the origin and having the camera out at Earth's distance (about 150 billion meters = 1 AU). He fixed the problem by always making the camera situated at the origin and just positioning all objects based on the camera position. I thought I would give that a try. I didn't have translation code for my planet yet, so I had to first write that and get it debugged. Once I had that working, it was pretty simple to switch the coordinates around (I added 2 lines of code and commented 1 out). Now my camera works perfectly even when dealing with a planet with a radius of 6.5 million. I also managed to tweak the Z-fighting occuring with the depth buffer. So it looks alot better than what it did, but it's still not perfect and there are still triangles fighting with each other on the horizon. As soon as I have that fixed, I'll post some more screenshots.]]></description><link>https://glitchenzo.github.io/2008-08-02-everything-revolves-around-the-camera.html</link><guid isPermaLink="false">2008-08-02 - Everything revolves around the camera.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:47 GMT</pubDate></item><item><title><![CDATA[2008-07-31 - Planets are Too Big]]></title><description><![CDATA[2008-07-31Last night I decided to increase the scale of the planet to Earth's size. The original size of the radius was 60,000 meters. Earth's radius is about 6.5 million meters. So, I had to make my planet over 100 times larger. Unfortunately, all sorts of problems arose from attempting to do this. First, my depth buffer went to crap. If I wanted to be able to see anything from even a low altitude, I had to extend the far clipping plane back to at least 1 million meters. This resulted in all sorts of errors with triangles that were fighting over their depths because the range was trying to be stretched over such a long distance. The second problem that occurred was that my camera was rotating in "steps". If I moved the mouse up, instead of smoothly rotating the view upwards, it would snap every Pi/4 or so. This snapping problem was alleviated by shrinking the size of the planet. Shrunk in half it was still too bad to use, shrunk by 4x was much better, but the problem was completely gone if I shrunk by 10x. I really need to fix all of these problems so that I can have Earth-sized planets. There are many other planets that are even larger than Earth so this is very important. I have found some articles online where people have found solutions to these problems. I'm just unsure of how feasible these solutions are for XNA (they are all OpenGL solutions). On a side note, I switched my Perlin noise function from fBm to ridged multifractal and it looks much better. I am very impressed with the terrain results. I would post screenshots, but with the depth issues and such, I figured I would wait.]]></description><link>https://glitchenzo.github.io/2008-07-31-planets-are-too-big.html</link><guid isPermaLink="false">2008-07-31 - Planets are Too Big.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:47 GMT</pubDate></item><item><title><![CDATA[2008-07-30 - Go Simple, Go Fast]]></title><description><![CDATA[2008-07-30I've made the executive decision to just go with the simple spherical lighting. It's already working and it's 3 times faster than the surface normal generation method. Besides, it will be simple to calculate the surface normal in a geometry shader later. Unfortunately XNA doesn't support geometry shaders currently. However if it ever adds that functionality in the future, I'll be able to add very realistic lighting rather quickly. I'm now going to move onto something else. What that is exactly, I'm still not sure of. I have a list of TODOs, but I need to determine which one is a higher priority right now.]]></description><link>https://glitchenzo.github.io/2008-07-30-go-simple,-go-fast.html</link><guid isPermaLink="false">2008-07-30 - Go Simple, Go Fast.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:46 GMT</pubDate></item><item><title><![CDATA[2008-07-29 - Do You See the Light]]></title><description><![CDATA[2008-07-29I promised myself that I wouldn't post another update until I had lighting on my planetary terrain. I have partially fulfilled that promise. While I did successfully get lighting on the terrain, it is not as realistic as I want it. I currently have two solutions. The first is that I'm simply illuminating the planet as a sphere. While this looks great in places where the light is coming straight down, it looks bad on the edges where there should be long shadows. (Ignore the square-ish terrain.)
<a data-tooltip-position="top" aria-label="http://bp0.blogger.com/_hGl_uKJzpS0/SI_t_yewJHI/AAAAAAAADyI/x1vu2ZR9Xdo/s1600-h/screenshot2.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://bp0.blogger.com/_hGl_uKJzpS0/SI_t_yewJHI/AAAAAAAADyI/x1vu2ZR9Xdo/s1600-h/screenshot2.png" target="_self"></a><img src="http://bp0.blogger.com/_hGl_uKJzpS0/SI_t_yewJHI/AAAAAAAADyI/x1vu2ZR9Xdo/s400/screenshot2.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> <br>The second solution I have actually tries to calculate the surface normal in the vertex shader. I estimate where the neighboring vertices are to the right and above the current vertex. I calculate the two edge vectors and then take the cross product of them to acquire the normal of the surface. While this all sounds good and makes sense in theory, it isn't yielding the correct results. I have random shadow and light "splotches" scattering over the planet, except for one quarter-sphere (is that what a half of a hemisphere is called?) that tu<a data-tooltip-position="top" aria-label="http://bp0.blogger.com/_hGl_uKJzpS0/SI_s7rY1lRI/AAAAAAAADyA/3sVOtc7uDQs/s1600-h/screenshot.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://bp0.blogger.com/_hGl_uKJzpS0/SI_s7rY1lRI/AAAAAAAADyA/3sVOtc7uDQs/s1600-h/screenshot.png" target="_self"></a><img src="http://bp0.blogger.com/_hGl_uKJzpS0/SI_s7rY1lRI/AAAAAAAADyA/3sVOtc7uDQs/s400/screenshot.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved">rns out all black. On a sidenote that's rather strange, if I use the XNA screenshot component that I wrote, the shadows all come out as white. If I use Alt-Print Screen and capture the whole window, it comes out as black (which is what is actually displayed). Check out the white versions:
[Edit: Ha ha! I didn't realize until I posted the screenshots that they aren't coming out as white, they are coming out as transparent, which makes much more sense!)<br>
<a data-tooltip-position="top" aria-label="http://bp1.blogger.com/_hGl_uKJzpS0/SI_uqXKD24I/AAAAAAAADyQ/irZ16aRBWnA/s1600-h/screenshot_633529635357812500.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://bp1.blogger.com/_hGl_uKJzpS0/SI_uqXKD24I/AAAAAAAADyQ/irZ16aRBWnA/s1600-h/screenshot_633529635357812500.png" target="_self"></a><img src="http://bp1.blogger.com/_hGl_uKJzpS0/SI_uqXKD24I/AAAAAAAADyQ/irZ16aRBWnA/s400/screenshot_633529635357812500.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"><br>
<a data-tooltip-position="top" aria-label="http://bp2.blogger.com/_hGl_uKJzpS0/SI_sImC3UlI/AAAAAAAADx4/nZVjjdbX5ig/s1600-h/screenshot_633529629442343750.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://bp2.blogger.com/_hGl_uKJzpS0/SI_sImC3UlI/AAAAAAAADx4/nZVjjdbX5ig/s1600-h/screenshot_633529629442343750.png" target="_self"></a><img src="http://bp2.blogger.com/_hGl_uKJzpS0/SI_sImC3UlI/AAAAAAAADx4/nZVjjdbX5ig/s400/screenshot_633529629442343750.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved">]]></description><link>https://glitchenzo.github.io/2008-07-29-do-you-see-the-light.html</link><guid isPermaLink="false">2008-07-29 - Do You See the Light.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:46 GMT</pubDate><enclosure url="http://bp0.blogger.com/_hGl_uKJzpS0/SI_t_yewJHI/AAAAAAAADyI/x1vu2ZR9Xdo/s400/screenshot2.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://bp0.blogger.com/_hGl_uKJzpS0/SI_t_yewJHI/AAAAAAAADyI/x1vu2ZR9Xdo/s400/screenshot2.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2008-07-23 - Rotation Solved]]></title><description><![CDATA[2008-07-23Well I implemented my pseudocode in XNA last night, made just some minor changes, and then I had a working rotating mesh. The guidance I received from Steve Hazen on the official XNA forums really helped me out and pointed me in the right direction. I would post the code here, but I don't know how to post it without it looking atrocious. I have the code posted in the XNA forums:
<a rel="noopener nofollow" class="external-link is-unresolved" href="http://forums.xna.com/forums/p/14547/76204.aspx" target="_self">http://forums.xna.com/forums/p/14547/76204.aspx</a> As you can see from the final postings, Steve recommends some tweaks to the code that would increase accuracy and make it more efficient. I'm really happy to finally have this problem solved. It took me four days to finally get a working solution. Now I can move on to the next item to implement. It's going to be tough as well, but no where near as tough as the rotation. At least that's what I'm hoping. Until next time...]]></description><link>https://glitchenzo.github.io/2008-07-23-rotation-solved.html</link><guid isPermaLink="false">2008-07-23 - Rotation Solved.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:46 GMT</pubDate></item><item><title><![CDATA[2008-07-22 - Rotation Solution]]></title><description><![CDATA[2008-07-22I think I may have a solution to the rotation problems I was having. I have pseudocode scrawled out on some paper I found. (Along with several drawings of 3D axes with angles, cones, and cameras in various positions.) My goal tonight is to implement the pseudocode in XNA and experiment with it. I'll report my findings tomorrow. Until next time...]]></description><link>https://glitchenzo.github.io/2008-07-22-rotation-solution.html</link><guid isPermaLink="false">2008-07-22 - Rotation Solution.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:45 GMT</pubDate></item><item><title><![CDATA[2008-07-21 - Rotation Issues]]></title><description><![CDATA[2008-07-21I have been working hard on coming up with a new LOD algorithm that eliminates that pesky "water" effect. I think I have a pretty good idea for a system that would not only remove that problem, but would also make the vertex shader faster. Unfortunately I am currently stuck facing some problems with rotations. I have a mesh that I want to rotate around a sphere so that is always points at the camera. I could create a billboard matrix and use that, but there is a problem. That would create the water effect again. What I need to do is move the mesh in steps. If the camera moves beyond an angle threshold for either left/right or up/down, then the mesh should be moved one step in the appropriate direction. I decided to use spherical coordinates to calculate the horizontal and vertical angles of the camera. This works great until you reach the north or south poles. Once you cross the poles, the mesh is rotated 180 degrees. Here is the reason why that happens: The "vertical" angle, theta, ranges from 0 to pi. Where 0 is pointing down the -Y axis and pi is pointing up the +Y axis. The "horizontal" angle, phi, ranges from 0 to 2pi. Where 0 is pointing along the +X axis, pi/2 is pointing along the +Z axis, pi is pointing along the -X axis, and 3pi/2 is pointing along the -Z axis. In the case when the camera passes over the north (+Y) pole, theta is at its peak (pi) but then starts decreasing as you continue to the other side. Whereas phi essentially gets +pi added to it (or -pi depending up where the pole is crossed). That is why the object is being rotated 180 degrees (pi radians). Whew! The problem is that I don't know how to fix this rotation. I have been tinkering around with it for the last several days to no avail. I certainly hope I come up with a solution soon. I really want to continue work on my new LOD algorithm. Until next time...]]></description><link>https://glitchenzo.github.io/2008-07-21-rotation-issues.html</link><guid isPermaLink="false">2008-07-21 - Rotation Issues.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:45 GMT</pubDate></item><item><title><![CDATA[2008-07-20 - LOD Algorithm]]></title><description><![CDATA[2008-07-20I thought I would explain the algorithm I used for the planetary LOD in more detail. When you first start the program, two meshes are generated: a cone and a ring. Both of these meshes are configurable at creation. For a cone, you can define how many "slices" it is broken into (imagine a pie and cutting into equal slices). For a ring, you can define how many slices as well as how many inner rings the ring has. For example, you can have a ring mesh that is made up of five inner rings and split into forty-five slices. Both of these meshes are scaled to a unit sphere (its actual just a hemisphere) which is centered at the the origin and "points" out along the -Z axis. At the lowest level of detail, the planet is just a cone. If the level is increased, the cone is shrunk in half and a ring is drawn attached to the bottom of the cone. If the level is increased again, the cone is shrunk in half again, the existing ring is shrunk in half, and another new ring is attached to the bottom of the existing ring. This process continues until the highest level of detail is reached. <a data-tooltip-position="top" aria-label="http://bp3.blogger.com/_hGl_uKJzpS0/SINzTgjIG_I/AAAAAAAADxM/J6jT1WFejEA/s1600-h/screenshot_633520093963593750.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://bp3.blogger.com/_hGl_uKJzpS0/SINzTgjIG_I/AAAAAAAADxM/J6jT1WFejEA/s1600-h/screenshot_633520093963593750.png" target="_self"></a><img src="http://bp3.blogger.com/_hGl_uKJzpS0/SINzTgjIG_I/AAAAAAAADxM/J6jT1WFejEA/s400/screenshot_633520093963593750.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> The resizing of the meshes is all done in the vertex shader. The terrain height is also calculated in the vertex shader via 8 octaves of fBm Perlin noise. This means that after the mesh generation in the beginning, the CPU does practically nothing. It just keeps track of what the current level is, and updates the shader parameter as necessary. The hemisphere is updated every frame to be centered at the camera by simply calculating a billboard matrix as the world matrix of the hemisphere. Well that should give you a decent grasp of how my LOD algorithm functions. As I mentioned in my previous post, it's not perfect because the centering of the hemisphere every frame really has a nasty looking "water" effect. I'm already at work on fixes for that, so if I get that working, I'll post what I did. I'll leave you with a quick video of my LOD algorithm at work. <br><a data-tooltip-position="top" aria-label="http://www.youtube.com/v/-vMqOy2-xsc&amp;hl=en&amp;fs=1&amp;rel=0" rel="noopener nofollow" class="external-link is-unresolved" href="http://www.youtube.com/v/-vMqOy2-xsc&amp;hl=en&amp;fs=1&amp;rel=0" target="_self">http://www.youtube.com/v/-vMqOy2-xsc&amp;hl=en&amp;fs=1&amp;rel=0</a>]]></description><link>https://glitchenzo.github.io/2008-07-20-lod-algorithm.html</link><guid isPermaLink="false">2008-07-20 - LOD Algorithm.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:45 GMT</pubDate><enclosure url="http://bp3.blogger.com/_hGl_uKJzpS0/SINzTgjIG_I/AAAAAAAADxM/J6jT1WFejEA/s400/screenshot_633520093963593750.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://bp3.blogger.com/_hGl_uKJzpS0/SINzTgjIG_I/AAAAAAAADxM/J6jT1WFejEA/s400/screenshot_633520093963593750.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2008-07-19 - Planetary LOD]]></title><description><![CDATA[2008-07-19I have been spending the last week writing my own implementation of an LOD system for a planet. It is inspired by Spherical Clipmaps, but it is not an actual implementation of them. As I said, I began writing it last week (exactly a week ago today) and I finally have it all up and running (using real-time 3D Perlin Noise in the Vertex Shader and texture blending, no less!). Unfortunately, I have it running too smoothly, if you can believe that. I have the vertices being updated and centered under the camera every frame. This leads to the terrain looking similar to flowing water as you fly around the planet. As long as the camera is stationary, everything looks great. You can spin the camera around and look at all of the terrain around you. As soon as you start moving though, the "water" effect is very apparent. I first tried to fix it by having the terrain position updated only once a second, but that looked terrible. So, I ended up saving the old camera position and then calculating the angle between the current camera position and the old position each frame. If the angle becomes greater than a threshold (I used something like Pi/64, yes that's sixty-four!) then I update the terrain position. This looks alot better than the time-based updating and it removes the "water" effect. Unfortunately, it also makes the terrain very "poppy". For example, if you see a mountain in the distance and you start to fly toward it, you would suddenly see more detail "pop" in as you got closer. I think what I have now is pretty decent, but I want to have very smooth terrain, with no popping and no water effect. So, I'm kind of back to the drawing board trying to think of a system that fixes both of those problems. Not everything I have now is throw-away code though. I think I should be able to carry over alot from this project to the updated LOD system.]]></description><link>https://glitchenzo.github.io/2008-07-19-planetary-lod.html</link><guid isPermaLink="false">2008-07-19 - Planetary LOD.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Mon, 29 Dec 2025 14:35:44 GMT</pubDate></item><item><title><![CDATA[2022-03-20 - Announcing Pipeline]]></title><description><![CDATA[2022-03-20In my last post, I mentioned that I was working on something big in my free-time and that more information would be coming around GDC.Well, GDC begins tomorrow, so it's time for me to announce <a data-tooltip-position="top" aria-label="http://pipeline.graphics" rel="noopener nofollow" class="external-link is-unresolved" href="http://pipeline.graphics" target="_self">Pipeline</a>.<br><a data-tooltip-position="top" aria-label="https://blogger.googleusercontent.com/img/a/AVvXsEi0K7xXqx2Eh63hK3HKAHeOkJ8jG1ivel8Kj7id1WEtL5IyKLg9AS1gWyzSSWfS-wsFtyzHBSdiVeYG0mSECKiCtDPNPzHl_LJaWiBdaPrGGbu7vo80njO24NXBOZC-q4DX9f6Uei0AV24FSnFINzU1uPTehCg9sgEs1h0IgAr7gobtDumYltxf2SiEyA" rel="noopener nofollow" class="external-link is-unresolved" href="https://blogger.googleusercontent.com/img/a/AVvXsEi0K7xXqx2Eh63hK3HKAHeOkJ8jG1ivel8Kj7id1WEtL5IyKLg9AS1gWyzSSWfS-wsFtyzHBSdiVeYG0mSECKiCtDPNPzHl_LJaWiBdaPrGGbu7vo80njO24NXBOZC-q4DX9f6Uei0AV24FSnFINzU1uPTehCg9sgEs1h0IgAr7gobtDumYltxf2SiEyA" target="_self"></a><img src="https://blogger.googleusercontent.com/img/a/AVvXsEi0K7xXqx2Eh63hK3HKAHeOkJ8jG1ivel8Kj7id1WEtL5IyKLg9AS1gWyzSSWfS-wsFtyzHBSdiVeYG0mSECKiCtDPNPzHl_LJaWiBdaPrGGbu7vo80njO24NXBOZC-q4DX9f6Uei0AV24FSnFINzU1uPTehCg9sgEs1h0IgAr7gobtDumYltxf2SiEyA" referrerpolicy="no-referrer" target="_self" class="is-unresolved">Pipeline is a&nbsp;data-driven, interactive, runtime editor of the entire DirectX 12 pipeline. It merges together my love of low-level graphics rendering and tools.It's still very early and nowhere near a full 1.0 release, but I figured it was usable enough to have folks start tinkering with it and give me feedback.<br>Check out <a data-tooltip-position="top" aria-label="https://github.com/GlitchEnzo/PipelineSamples" rel="noopener nofollow" class="external-link is-unresolved" href="https://github.com/GlitchEnzo/PipelineSamples" target="_self">sample projects here</a>.<br>Read <a data-tooltip-position="top" aria-label="https://github.com/GlitchEnzo/PipelineSamples/wiki" rel="noopener nofollow" class="external-link is-unresolved" href="https://github.com/GlitchEnzo/PipelineSamples/wiki" target="_self">documentation here</a>.<br>If you encounter&nbsp;any problems or want to request features, you can <a data-tooltip-position="top" aria-label="https://github.com/GlitchEnzo/PipelineSamples/issues" rel="noopener nofollow" class="external-link is-unresolved" href="https://github.com/GlitchEnzo/PipelineSamples/issues" target="_self">do that here</a>.I'm excited to continue to improve Pipeline by adding new features and making it a much more powerful tool for graphics developers to utilize.]]></description><link>https://glitchenzo.github.io/2022-03-20-announcing-pipeline.html</link><guid isPermaLink="false">2022-03-20 - Announcing Pipeline.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Sun, 28 Dec 2025 15:21:42 GMT</pubDate><enclosure url="https://blogger.googleusercontent.com/img/a/AVvXsEi0K7xXqx2Eh63hK3HKAHeOkJ8jG1ivel8Kj7id1WEtL5IyKLg9AS1gWyzSSWfS-wsFtyzHBSdiVeYG0mSECKiCtDPNPzHl_LJaWiBdaPrGGbu7vo80njO24NXBOZC-q4DX9f6Uei0AV24FSnFINzU1uPTehCg9sgEs1h0IgAr7gobtDumYltxf2SiEyA" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="https://blogger.googleusercontent.com/img/a/AVvXsEi0K7xXqx2Eh63hK3HKAHeOkJ8jG1ivel8Kj7id1WEtL5IyKLg9AS1gWyzSSWfS-wsFtyzHBSdiVeYG0mSECKiCtDPNPzHl_LJaWiBdaPrGGbu7vo80njO24NXBOZC-q4DX9f6Uei0AV24FSnFINzU1uPTehCg9sgEs1h0IgAr7gobtDumYltxf2SiEyA"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2008-08-08 - Huh]]></title><description><![CDATA[2008-08-08Well I beat Braid last night. I think it took me about 6 hours total to beat it. It's a very good game and I highly recommend it. That is, if you enjoy "action puzzle" type games (think along the lines of Portal). There are 60 puzzles in the game and I was able to do 59 of them myself. I couldn't figure out one of them and I tried it for an hour. I finally looked online and I learned about a dynamic of the game that I wasn't even aware of. I had read a posting on the XNA forums about how matrix transformations can cause slight errors over time, so I added code after my transformations to renormalize the vectors and even recalculate the cross products in order to maintain orthogonality. However, when I fired up the program, the terrain was disappearing even more! The angle between the two vectors is still randomly coming up as NaN and Pi. Sigh, well I guess I know what I'm working on this weekend.]]></description><link>https://glitchenzo.github.io/2008-08-08-huh.html</link><guid isPermaLink="false">2008-08-08 - Huh.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Sun, 28 Dec 2025 15:20:31 GMT</pubDate></item><item><title><![CDATA[2014-02-23 - Dart on Cloud 9 IDE]]></title><description><![CDATA[2014-02-23Although I haven't talked much about it, I've been doing quite a bit of JavaScript &amp; HTML development in my free-time for the past year. &nbsp;I had done web development for several years before that, but it was very basic and involved simply editing files via Notepad and uploading them to my server. &nbsp;This workflow was very inefficient for me and made me hesitant to continue development since it was so cumbersome. &nbsp;I sought out a solution for being able to develop directly in a web browser using a browser-based IDE. I discovered that there were several solutions, each at various levels of features, stability, and ease of use. &nbsp;I tried <a data-tooltip-position="top" aria-label="http://koding.com/" rel="noopener nofollow" class="external-link is-unresolved" href="http://koding.com/" target="_self">Koding</a>,&nbsp;<a data-tooltip-position="top" aria-label="http://orionhub.org/" rel="noopener nofollow" class="external-link is-unresolved" href="http://orionhub.org/" target="_self">Orion</a>, and <a data-tooltip-position="top" aria-label="http://c9.io/" rel="noopener nofollow" class="external-link is-unresolved" href="http://c9.io/" target="_self">Cloud 9</a>. &nbsp;Cloud 9 stood out as the best of the bunch with a very friendly layout, tons of supported languages, a variety of software pre-installed (Java, Python, Git, etc), and a full Linux terminal to use. While I was able to write a powerful HTML5 music player and lay down a nice foundation for a WebGL engine all using JavaScript &amp; HTML, it was rather painful for me. &nbsp;JavaScript is not a very fun or easy language to use. &nbsp;I found I was constantly fighting against the language to build even the simplest of structures. <br> I had briefly looked at <a data-tooltip-position="top" aria-label="http://dartlang.org/" rel="noopener nofollow" class="external-link is-unresolved" href="http://dartlang.org/" target="_self">Dart</a>a year ago and decided that I would rather write "pure" JavaScript instead of writing in a higher level language that simply compiled down to JavaScript. &nbsp;However, after looking at various benchmarks that compared Dart compiled JavaScript with native JavaScript, it made me reconsider my decision. &nbsp;Another big push was from one of my co-workers who was writing a simple WebGL game using Dart. &nbsp;We were able to sit down and compare Dart and JavaScript code side by side to see similarities and differences. &nbsp;That convinced me to install the Dart IDE and give it a whirl. &nbsp;There are some odd quirks to it since it does get compiled down to JavaScript, but for the most part it felt like C# or Java, which is great for me (10 years of C# development experience). However, switching to Dart means that I have to resort to the old style of editing code on a specific machine and then uploading it to my server over and over. &nbsp;I would prefer to use a web IDE like Cloud 9. &nbsp;While Cloud 9 supports syntax highlighting for Dart, it doesn't provide the Dart VM or any way to compile the Dart code to JavaScript. Since Cloud 9 is simply running Red Hat Enterprise Linux (RHEL), I decided to import the Dart SDK for Linux directly into a new workspace. &nbsp;Unfortunately, I immediately ran into a problem. &nbsp;I couldn't run the Dart VM because the binary had been compiled using GNU C Library (glibc) version 2.15. &nbsp;In fact, Google uses Ubuntu 12.04 "Precise Pangolin" to compile Dart which uses glibc 2.15. &nbsp;It turns out that the version of Red Hat on Cloud 9 (RHEL 6.5) only has glibc version 2.12. I tried three different options to try and get Dart working on Cloud 9. 1) Compile Dart in a virtual machine
I downloaded Virtual Box and the latest 64-bit version of Ubuntu (13.10). &nbsp;Unfortunately, Virtual Box doesn't support 64-bit OSs on my machine because it apparently doesn't have some visualization enhancements. Not only that, but I also found out that Ubuntu 13.10 uses an even higher version of glibc (2.17). 2) Compile Dart directly in Cloud 9<br>
I figured since Cloud 9 supports Java, C, Python, Git, Subversion, etc I would just try to pull in the source directly into a Cloud 9 workspace and compile it there, using <a data-tooltip-position="top" aria-label="https://code.google.com/p/dart/wiki/BuildingOnCentOS" rel="noopener nofollow" class="external-link is-unresolved" href="https://code.google.com/p/dart/wiki/BuildingOnCentOS" target="_self">this</a> as a guide. &nbsp;I spent massive amounts of time trying to get this to work, but alas I was not successful. &nbsp;I could list all of the things I tried, but in the end it simply did not work. &nbsp;Whenever I would try to compile, the compiler would crash trying to compile SQLite. &nbsp;I believe it has something to do with the version of the compiler (Cloud 9 has GCC v4.4.7 and Dart apparently needs 4.6.0). 3) Use a patched Dart SDK<br>
Some people were having very <a data-tooltip-position="top" aria-label="https://code.google.com/p/dart/issues/detail?id=11920" rel="noopener nofollow" class="external-link is-unresolved" href="https://code.google.com/p/dart/issues/detail?id=11920" target="_self">similar issues</a> to me when trying to use Dart on CentOS. &nbsp;One guy built a <a data-tooltip-position="top" aria-label="https://github.com/sestegra/patch-dartsdk-linux" rel="noopener nofollow" class="external-link is-unresolved" href="https://github.com/sestegra/patch-dartsdk-linux" target="_self">patch</a>that would pull in the dependencies directly from the Ubuntu repo and put them alongside the Dart SDK. &nbsp;This caused all sorts of bad things to happen such as random files getting locked by Cloud 9 itself and random seg faults. So ... I decided to go back to step 1 1 - Again) Compile Dart in a virtual machine<br>
I downloaded the <a data-tooltip-position="top" aria-label="http://releases.ubuntu.com/lucid/" rel="noopener nofollow" class="external-link is-unresolved" href="http://releases.ubuntu.com/lucid/" target="_self">32-bit Ubuntu 10.04</a>, which uses glibc 2.11, and installed it in Virtual Box. &nbsp;I followed <a data-tooltip-position="top" aria-label="https://code.google.com/p/dart/wiki/BuildDartSDKOnUbuntu10_04" rel="noopener nofollow" class="external-link is-unresolved" href="https://code.google.com/p/dart/wiki/BuildDartSDKOnUbuntu10_04" target="_self">this guide</a> in order to get the latest Dart source code and build the SDK. &nbsp;I then zipped up the built Dart SDK, uploaded it via FTP to my server, and then pulled it back down onto my Windows machine. &nbsp;I extracted the SDK, and then uploaded it to Cloud 9. &nbsp;I did have to force all of the binaries to have executable permissions, since Cloud 9 doesn't give them it by default. I then uploaded the default "Hello World" text reversal Dart project, and wrote simple Node.js wrappers around dart2js and pub to make them easier to access. &nbsp;I now have Dart compiling and running on Cloud 9! Let me know if you have any questions or want examples/details of anything.]]></description><link>https://glitchenzo.github.io/2014-02-23-dart-on-cloud-9-ide.html</link><guid isPermaLink="false">2014-02-23 - Dart on Cloud 9 IDE.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Wed, 24 Sep 2025 01:08:40 GMT</pubDate></item><item><title><![CDATA[2016-01-21 - Post Ideas]]></title><description><![CDATA[2016-01-21Environment Variables (and why they suck)
- only loaded into application once at start. &nbsp;can't detect changes.
- case sensitive. &nbsp;what's it supposed to be? &nbsp;who knows!
- no good built-in editor, must resort to third party Barrier of Entry (game engines, VR, etc)
- monetarily as well as pick up and play ability Ageism in Software (old folks don't change) JIRA (why it sucks)
- clunky, way too many fields. &nbsp;not intuitive. &nbsp;use GitHub issues (and waffl.io) as a model]]></description><link>https://glitchenzo.github.io/2016-01-21-post-ideas.html</link><guid isPermaLink="false">2016-01-21 - Post Ideas.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Wed, 24 Sep 2025 01:08:34 GMT</pubDate></item><item><title><![CDATA[2016-05-27 - Unity Issues]]></title><description><![CDATA[2016-05-27I've been using Unity for over 6 years. &nbsp;While it has many aspects that I love, no engine is without issues. &nbsp;Over the years, I've encountered many of these issues, some of which I've found workarounds for. &nbsp;Several times now, someone will ask me, "Didn't you encounter this issue? &nbsp;How did you solve it?" &nbsp;And I'll usually answer, "Yeah, I've encountered that, but I don't remember the details". &nbsp;What follows is my list of Unity issues. &nbsp;I'll try to keep it up to date as best I can for issues I encounter, as well as provide any workarounds I come up with. Issue #1: No adjacency information in geometry shaders
You cannot construct a mesh filled with adjacency information, which is incredibly useful for many things.
Workaround: None Issue #2: Frustum culling cannot be disabled
Let's say you have an object that has it's vertices displaced in a shader. &nbsp;If the object is outsidethe view frustum and the displacement places the vertices insidethe frustum, Unity won't render it. Another example: If you have created a mesh consisting of screenspace/viewspace vertices, Unity won't render that mesh unless the containing object is inside the view frustum. It would be great to be able to disabled frustum culling on specific objects, or even disable it entirely, but there is no such ability. Workaround: Change camera view angle. &nbsp;Change object bounds. Change object position temporarily. Issue #3: Generic ReflectionTypeLoadException&nbsp;error
This error is incredibly frustrating, especially when you are dealing with a lot of DLLs. &nbsp;This error can occur for many reasons, and Unity never gives you any details inside the Editor. It could mean that you're missing a DLL. &nbsp;Dig through the editor log file to try to figure out what. It could mean a DLL targets the wrong .NET version (&gt; 3.5). &nbsp;Which DLL? &nbsp;Who knows. Workaround: Scour through the editor log to find any info to help. &nbsp;Good luck trying to support a giant team of developers. &nbsp;You basically have to have them email you the log file.]]></description><link>https://glitchenzo.github.io/2016-05-27-unity-issues.html</link><guid isPermaLink="false">2016-05-27 - Unity Issues.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Wed, 24 Sep 2025 01:08:25 GMT</pubDate></item><item><title><![CDATA[2011-09-15 - Unity GPU Noise (Part 3)]]></title><description><![CDATA[2011-09-15As I mentioned <a data-tooltip-position="top" aria-label="http://recreationstudios.blogspot.com/2011/08/unity-gpu-noise-part-2.html" rel="noopener nofollow" class="external-link is-unresolved" href="http://recreationstudios.blogspot.com/2011/08/unity-gpu-noise-part-2.html" target="_self">previously</a>, I had updated my GPU Noise to hopefully get it working on Macs. One of my friends tried the web player build on his Mac, and I was saddened to see that it still came out as a black, non-displaced sphere. <br>As I was investigating, I found the <a data-tooltip-position="top" aria-label="http://unity3d.com/support/documentation/ScriptReference/Shader-isSupported.html" rel="noopener nofollow" class="external-link is-unresolved" href="http://unity3d.com/support/documentation/ScriptReference/Shader-isSupported.html" target="_self">Shader.isSupported</a> API which looked like it might be helpful. I noticed in the documentation, however, that it will return true if any of the Fallback shaders will work. In my noise shader, I had given it a fallback of "VertexLit", thus why only a flat, black sphere was rendered on the Mac. I didn't want the API to always return true (since VertexLit obviously was working), so I commented out the Fallback statement. Bad move! Not only did the web player fail to load on a Mac, it completely locked the entire OS requiring a reboot! Since my friend's Mac is a dual-boot with Windows 7 on it, I had him try it out on the Windows side. Everything worked perfectly!<br>In order to help me with debugging possible hardware issues, I wrote a simple little Unity web player that listed the hardware specs according to how Unity sees the machine. It's been pretty interesting and helpful. You can run it <a data-tooltip-position="top" aria-label="http://re-creationstudios.com/unity/info/" rel="noopener nofollow" class="external-link is-unresolved" href="http://re-creationstudios.com/unity/info/" target="_self">over here</a>.<br>Using that app, I was able to see that the Mac only runs OpenGL 2.1! For comparison, when I forced my Windows build to run in OpenGL mode (using<a data-tooltip-position="top" aria-label="http://unity3d.com/support/documentation/Manual/Command%20Line%20Arguments.html" rel="noopener nofollow" class="external-link is-unresolved" href="http://unity3d.com/support/documentation/Manual/Command%20Line%20Arguments.html" target="_self">-force-opengl</a>), it reported that it was running OpenGL 4.1. My hatred for Apple increases daily.<br>Deciding to switch gears for a bit, I started looking into deploying the GPU Noise on my EVO 3D to see how it ran. (No, I don't have a personal Android license for Unity yet, but I do have one from work. I;m not going to publish anything from it, just use it to test my stuff after work.) So, I got everything setup and sent my package over to my phone, where I was greeted with the "Powered by Unity" splashscreen. That was it; it never made it beyond that point. I hooked up <a data-tooltip-position="top" aria-label="http://developer.android.com/guide/developing/tools/adb.html#logcat" rel="noopener nofollow" class="external-link is-unresolved" href="http://developer.android.com/guide/developing/tools/adb.html#logcat" target="_self">logcat</a>and added some debug lines to see what errors were occurring. That wasn't helpful at all. It showed Unity loading, timing out, and then reloading. My level file was never loaded, none of my scripts were ever executed. If I switched my Material to be something else (I used a particle material), it would load properly and run. So, it was an issue with my noise Material, but I have no idea what, due to the lack of errors.As it stands now, I'm not quite sure how to proceed. Do I release this on the Unity Asset Store as it is now and put a disclaimer that it only works on Windows currently, or do I invest more time and effort to get it working on Mac/Android first? Opinions?]]></description><link>https://glitchenzo.github.io/2011-09-15-unity-gpu-noise-(part-3).html</link><guid isPermaLink="false">2011-09-15 - Unity GPU Noise (Part 3).md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Wed, 24 Sep 2025 01:05:02 GMT</pubDate></item><item><title><![CDATA[2025-09-20 - Text Rendering in HLSL]]></title><description><![CDATA[<a data-tooltip-position="top" aria-label="https://gist.github.com/GlitchEnzo/df92cb01b7b7c11685e94fcf613d8d58" rel="noopener nofollow" class="external-link is-unresolved" href="https://gist.github.com/GlitchEnzo/df92cb01b7b7c11685e94fcf613d8d58" target="_self">You can view the entire text.hlsl file you can include here</a>.For a long time, I've wanted a way to directly output text to a render target from HLSL. It would be similar to printf debugging, but output directly to the screen instead of to a log file somewhere.<br>There have already been some <a data-tooltip-position="top" aria-label="https://therealmjp.github.io/posts/hlsl-printf/" rel="noopener nofollow" class="external-link is-unresolved" href="https://therealmjp.github.io/posts/hlsl-printf/" target="_self">other efforts</a> to add printf style support to shaders, but that usually involves outputting strings to a buffer, and then reading that buffer back on the CPU.While a common approach to rendering text is to use a texture of a font and then drawing textured quads for each glyph, I wanted to use a different approach. I wanted to avoid binding a texture entirely and use a vector font.I had previous written debug shape drawing functions in HLSL to draw things like lines, circles, and boxes. For a vector font, I would only need lines, so I was prepared from that side of thing.<br>A perfect, simple, vector line-based font are the <a data-tooltip-position="top" aria-label="https://paulbourke.net/dataformats/hershey/" rel="noopener nofollow" class="external-link is-unresolved" href="https://paulbourke.net/dataformats/hershey/" target="_self">Hershey set</a>.<br>I downloaded the full Hershey set of <a data-tooltip-position="top" aria-label="https://paulbourke.net/dataformats/hershey/hershey.zip" rel="noopener nofollow" class="external-link is-unresolved" href="https://paulbourke.net/dataformats/hershey/hershey.zip" target="_self">Roman characters</a> and immediately began writing a simple C# script in <a data-tooltip-position="top" aria-label="https://www.linqpad.net/" rel="noopener nofollow" class="external-link is-unresolved" href="https://www.linqpad.net/" target="_self">LINQPad</a> to process the file.<br>An important thing to note is that the original Hershey file is hard-wrapped at 72 characters. This small thing caused me some issues until I saw it mentioned <a data-tooltip-position="top" aria-label="https://coolbutuseless.github.io/package/hershey/articles/hershey-font-format.html" rel="noopener nofollow" class="external-link is-unresolved" href="https://coolbutuseless.github.io/package/hershey/articles/hershey-font-format.html" target="_self">here</a>.In order to verify that my C# parser was working correctly, I wrote code to write out each glyph to a Bitmap.<br><img alt="hershey.bmp" src="https://glitchenzo.github.io/attachments/hershey.bmp" target="_self" style="width: 300px; max-width: 100%;"><br>
With all of the glyphs being properly processed and written, I then moved on to mapping the characters I wanted into the standard ASCII set. Luckily, there are already .hmp files which do exactly this for each of the different font styles in the Hershey set. I was interested in only the <a data-tooltip-position="top" aria-label="https://paulbourke.net/dataformats/hershey/romans.hmp" rel="noopener nofollow" class="external-link is-unresolved" href="https://paulbourke.net/dataformats/hershey/romans.hmp" target="_self">Roman Simplex</a> mapping. With very little effort, I was soon outputting the appropriate glyphs.With the glyphs defined, I wrote more C# code to output HLSL code to draw the glyphs. I started with a simple, brute-force solution where I output a large switch statement, with a case for each ASCII character. Each case would have a series of DrawLine() calls that would represent the glyph.The function signature is this:float2 DrawCharacter(RWTexture2D&lt;float4&gt; Output, uint CharacterCode, float2 Position, float4 Color)
For the character H, it would generate this:case 72: // "H" (Hershey #508) DrawLineDDA(Output, float2(Position.x + -7, Position.y + -12), float2(Position.x + -7, Position.y + 9), Color); DrawLineDDA(Output, float2(Position.x + 7, Position.y + -12), float2(Position.x + 7, Position.y + 9), Color); DrawLineDDA(Output, float2(Position.x + -7 * Scale, Position.y + -2), float2(Position.x + 7, Position.y + -2), Color); Position.x += 32; break;
This generated over 1200 lines in a single HLSL function, but it worked ... mostly.<br>
<img alt="Screenshot 2025-09-04 180756.png" src="https://glitchenzo.github.io/attachments/screenshot-2025-09-04-180756.png" target="_self">It would take about 2-3 seconds to compile the HLSL, which is long, but not ridiculous. The main problem was, it would take three minutes to generate the PSO the first time when calling SetPipelineState in D3D12 on a PC with an i9-14900K and an RTX 4090. That was completely unacceptable!I did attempt swapping the attribute on the switch statement to be [branch], [call], etc, but it did nothing to change the compilation or PSO creation time. It was clear I needed a different approach.I figured that since all I needed were the x and y positions for the vertices for the lines, then I could store each line in an array, and use the exact same DrawCharacter() function with no massive switch statement.float2 DrawCharacter(RWTexture2D&lt;float4&gt; Output, uint CharacterCode, float2 Position, float4 Color)
{ int ArrayIndex = CharacterCode - 32; int LineCount = RomanSimplexFont[ArrayIndex][0]; int Width = RomanSimplexFont[ArrayIndex][1]; for (int i = 2; i &lt; LineCount; i++) { float2 Start = float2(Position.x + RomanSimplexFont[ArrayIndex][i], Position.y + RomanSimplexFont[ArrayIndex][i+1]); float2 End = float2(Position.x + RomanSimplexFont[ArrayIndex][i+2], Position.y + RomanSimplexFont[ArrayIndex][i+3]); DrawLineDDA(Output, Start, End, Color); } return Position + float2(Width, 0);
}
I changed my C# to output a simple two dimensional int array. Unfortunately, it obviously needed all of the glyphs to have the same size, which was the largest symbol, which is the @ symbol with 48 lines. 48 lines with 2 vertices per line and 2 integers per vertex equaled 192 integers for 95 ASCII characters.int RomanSimplexFont[95][192]
For the character H, it would generate this: 3, 32, // ASCII 72 "H" (Hershey #508) -7, -12, -7, 9, 7, -12, 7, 9, -7, -2, 7, -2,
0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
Note all of the zeros that are needs to pad it out to fill the 192 integers.So, I generated the entire array, went to compile the shader ... and it failed. My constant buffer was larger than the limit of 65,536 bytes or 16,384 ints. I was using 95 * 192 = 18,240 ints. However!<br>The compiler wasn't reporting that my array was the expected 72,960 bytes. Instead, it was reporting that it was 297,972 bytes, which was nearly 4 times larger than expected! I was cursed (yet again) by the <a data-tooltip-position="top" aria-label="https://learn.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl-packing-rules" rel="noopener nofollow" class="external-link is-unresolved" href="https://learn.microsoft.com/en-us/windows/win32/direct3dhlsl/dx-graphics-hlsl-packing-rules" target="_self">HLSL packing rules</a> for constant buffers, which have bitten me so many times in the past.So, I updated the code generator to create an array of int4 which resulted in the expected 74,480 bytes.int4 RomanSimplexFont[95][49]
However, this is still obviously over the 65,536 limit, so I needed to do something to get the Hershey data under the 64K.I attempted to use the int16_t4 data type (enabled via the DXC -enable-16bit-types flag), which I assumed would cut my array size in half. int16_t4 RomanSimplexFont[95][49]
But, surprisingly, it stayed the exact same size. This is due to DXC/HLSL treating any constant buffer array as 32-bit, even if you explicitly use a 16-bit value. It will automatically pad the values. Note that if you create an array inside a function, it will be the correct size.Since all of the coordinates are less than abs(128), that means I can use an 8-bit signed number to represent each one. So, I could pack all 4 coordinates of a line into a single 32-bit int. That means I could store 4 lines in each int4!I updated my C# code yet again to perform all of the proper bit-packing and generate the HLSL array. It only needed to 13 int4s per glyph due to the @ symbol having 48 lines. That is 12 int4s + 1 extra to store the line count, width, left padding, and right padding.static const int4 RomanSimplexFont[96][13]
For the character H, it would generate this: // ASCII 72 "H" (Hershey #508) int4(3, 22, -11, 11), int4(-101385975, 133433097, -100792322, 0), int4(0,0,0,0), int4(0,0,0,0), int4(0,0,0,0), int4(0,0,0,0), int4(0,0,0,0), int4(0,0,0,0), int4(0,0,0,0), int4(0,0,0,0), int4(0,0,0,0), int4(0,0,0,0), int4(0,0,0,0),
This worked and I was able to render text with a 2-3 second shader compilation and a negligible PSO compilation!<br><img alt="Pasted image 20250918204229.png" src="https://glitchenzo.github.io/attachments/pasted-image-20250918204229.png" target="_self">Outputting static text alone isn't as useful. I would obviously want to output numeric values that were constantly changing, such as frame-rates or pixel values. Unfortunately, HLSL has no string processing or string functions at all. I found a C custom implementation of itoa and I ported it over to HLSL easily.void itoa(int value, inout uint buffer[256])
Similarly, I did the same for ftoa.void ftoa(float value, inout uint buffer[256], int afterpoint = 2)
As you can see, and as I have stated, there is no native string support in HLSL. You must use an array of uints. This because a big problem when you want to define a string literal.const uint helloStr[] =&nbsp; {'H','e','l','l','o',',',' ','W','o','r','l','d','!',};
Gross!So, I wrote my own custom TEXT() preprocessor macro. Before I compile the HLSL text, I use regular expressions in (hacky, ugly) C++ to find TEXT() and automatically expand the string to a uint array.const char* shaderCodeText = "ORIGINAL HLSL SOURCE HERE";
std::string originalShaderCodeString(shaderCodeText);
std::regex regexTextPattern("TEXT\\(.*\"\\)"); auto words_begin = std::sregex_iterator(originalShaderCodeString.begin(), originalShaderCodeString.end(), regexTextPattern);
auto words_end = std::sregex_iterator(); std::sregex_iterator i = words_begin;
while (i != words_end)
{ std::smatch match = *i; // remove TEXT(" from the start and ") from the end std::string actualString = match.str().erase(0, 6); actualString = actualString.erase(actualString.size() - 2); std::string output = "{"; int charIndex = 0; for (char c : actualString) { output += "'"; output += c; output += "',"; charIndex++; } while (charIndex &lt; 255) { output += "0,"; charIndex++; } output += "0}"; size_t pos = 0; while ((pos = originalShaderCodeString.find(match.str(), pos)) != std::string::npos) { originalShaderCodeString.replace(pos, match.length(), output); pos += output.length(); // Move past the newly inserted substring } i = std::sregex_iterator(originalShaderCodeString.begin(), originalShaderCodeString.end(), regexTextPattern);
} shaderCodeText = originalShaderCodeString.c_str();
So the above line becomes this:const uint helloStr[] =&nbsp;TEXT("Hello, World!");
Much better!There are still major limitations, mainly due to C limitations, not HLSL.
You cannot re-initialize an array with a literal. helloStr = TEXT("Changed string!"); \\ fails to compile You cannot pass an array literal in as a function argument. DrawText(TEXT("My string literal arg!")); \\ fails to compile uint printStr[] = TEXT("Hello, World!");
REINIT_TEXT(printStr, "Second case"); // this will break if there are 2+
// add a number counter?
uint _temp_reinit_text_array_0[] = { 'S','e','c', etc };
strcpy(printStr, _temp_reinit_text_array_0);
To provide some more C-esque support for strings, I did add my own custom implementations of strcat and strcpy.void strcat(in uint stringA[256], in uint stringB[256], inout uint outString[256])
void strcpy(inout uint destination[256], in uint source[256])
<br><img alt="Pasted image 20250918211125.png" src="https://glitchenzo.github.io/attachments/pasted-image-20250918211125.png" target="_self">Here is the HLSL source code for the above screenshot:uint printStr[] = TEXT("The quick brown fox jumped over the lazy dog!");
DrawText(gOutput, printStr, float2(0, 530), 0.75f); uint tempStr[] = TEXT("itoa + cursor = ");
strcpy(printStr, tempStr);
float2 cursor = DrawText(gOutput, printStr, float2(0, 580), 2.0f, float4(1, 0, 0, 1)); itoa(1234567890, tempStr);
DrawText(gOutput, tempStr, cursor, 2.0f, float4(1, 0, 0, 1)); ftoa(3.14159f, printStr, 3);
const uint tempStr2[] = TEXT("ftoa + strcat = "); uint concatStr[256];
strcat(tempStr2, printStr, concatStr);
DrawText(gOutput, concatStr, float2(0, 650), 3.0f, float4(1, 0, 1, 1));
I now have a text renderer, fully implemented in HLSL, which can be used by any shader to output to any RWTexture, including the back-buffer. There are still many things I would like to add and improve.
I would like to optimize the number lines needed to draw the @ symbol in order to reduce the array size It needs 48 lines and the next most expensive character &amp; needs 33, so we could potentially save 3 int4s per character, which would be a reduction of 4,560 bytes. I already have in scale, but I would love to add in full transform/rotation.
I have cursor advancement, but I have no concept of wrapping or line breaks, which would be nice for multiline text on the screen.
The given string is completely drawn on the current single GPU thread. I would like to utilize the GPU threading more, perhaps through work graphs. Ideally it would be 1 glyph per thread, or even 1 line per thread.
While I have seen decent performance on various GPUs, I have seen terrible performance on some, so I would like to optimize for all hardware, if possible. For the 3-line text image above I was seeing these (completely unscientific) frame times: GeForce RTX 4090 = 3 ms
GeForce 970M = 25 ms
Intel HD Graphics 620 = 19,000 ms (ouch!) ]]></description><link>https://glitchenzo.github.io/2025-09-20-text-rendering-in-hlsl.html</link><guid isPermaLink="false">2025-09-20 - Text Rendering in HLSL.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Sun, 21 Sep 2025 02:16:27 GMT</pubDate><enclosure url="https://glitchenzo.github.io/attachments/hershey.bmp" length="0" type="image/bmp"/><content:encoded>&lt;figure&gt;&lt;img src="https://glitchenzo.github.io/attachments/hershey.bmp"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20250918211125]]></title><description><![CDATA[<img src="https://glitchenzo.github.io/attachments/pasted-image-20250918211125.png" target="_self">]]></description><link>https://glitchenzo.github.io/attachments/pasted-image-20250918211125.html</link><guid isPermaLink="false">Attachments/Pasted image 20250918211125.png</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Fri, 19 Sep 2025 01:11:25 GMT</pubDate><enclosure url="https://glitchenzo.github.io" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="https://glitchenzo.github.io"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Pasted image 20250918204229]]></title><description><![CDATA[<img src="https://glitchenzo.github.io/attachments/pasted-image-20250918204229.png" target="_self">]]></description><link>https://glitchenzo.github.io/attachments/pasted-image-20250918204229.html</link><guid isPermaLink="false">Attachments/Pasted image 20250918204229.png</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Fri, 19 Sep 2025 00:42:29 GMT</pubDate><enclosure url="https://glitchenzo.github.io" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="https://glitchenzo.github.io"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Screenshot 2025-09-04 180756]]></title><description><![CDATA[<img src="https://glitchenzo.github.io/attachments/screenshot-2025-09-04-180756.png" target="_self">]]></description><link>https://glitchenzo.github.io/attachments/screenshot-2025-09-04-180756.html</link><guid isPermaLink="false">Attachments/Screenshot 2025-09-04 180756.png</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Fri, 19 Sep 2025 00:13:11 GMT</pubDate><enclosure url="https://glitchenzo.github.io" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src="https://glitchenzo.github.io"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[hershey]]></title><description><![CDATA[<img src="https://glitchenzo.github.io/attachments/hershey.bmp" target="_self">]]></description><link>https://glitchenzo.github.io/attachments/hershey.html</link><guid isPermaLink="false">Attachments/hershey.bmp</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Thu, 18 Sep 2025 23:24:03 GMT</pubDate><enclosure url="https://glitchenzo.github.io/attachments/hershey.bmp" length="0" type="image/bmp"/><content:encoded>&lt;figure&gt;&lt;img src="https://glitchenzo.github.io/attachments/hershey.bmp"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2017-07-22 - Making Blender Like Unity]]></title><description><![CDATA[2017-07-22I'm not an artist let alone a 3D modeler. &nbsp;Whenever I open a 3D modelling app, I quickly become frustrated due to cumbersome user interfaces that are different than everything else I'm used to. Game editors and videos games don't have user interfaces even remotely similar to 3D modelling apps. Several years ago, I was able to tweak Blender to behave somewhat like Unity. However I soon after lost that computer as well as the configuration. I kept meaning to configure it again, but I never remembered what I had done. Today, I finally installed the latest Blender (2.78c) and decided to get it configured correctly again. Here is what I did. 1) Open the User Preferences In the Info window (the default menu bar on the top), select File&nbsp;&nbsp;User Preferences <a data-tooltip-position="top" aria-label="https://2.bp.blogspot.com/-AG5Mqyk2ug8/WXOV8SItZQI/AAAAAAAAdMo/TvkAZCD-D9MDHMFpAWPI7hdSDfzJ3DEjQCLcBGAs/s1600/show_user_prefs.png" rel="noopener nofollow" class="external-link is-unresolved" href="https://2.bp.blogspot.com/-AG5Mqyk2ug8/WXOV8SItZQI/AAAAAAAAdMo/TvkAZCD-D9MDHMFpAWPI7hdSDfzJ3DEjQCLcBGAs/s1600/show_user_prefs.png" target="_self"></a><img src="https://2.bp.blogspot.com/-AG5Mqyk2ug8/WXOV8SItZQI/AAAAAAAAdMo/TvkAZCD-D9MDHMFpAWPI7hdSDfzJ3DEjQCLcBGAs/s320/show_user_prefs.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> In the User Preferences window click the Inputtab <br><a data-tooltip-position="top" aria-label="https://4.bp.blogspot.com/-fYDwWcOt6_s/WXOWesh1aLI/AAAAAAAAdMs/AxHGCrg-dvEaw9KpMWhqlul8D7hY_wvdgCLcBGAs/s1600/user_prefs.png" rel="noopener nofollow" class="external-link is-unresolved" href="https://4.bp.blogspot.com/-fYDwWcOt6_s/WXOWesh1aLI/AAAAAAAAdMs/AxHGCrg-dvEaw9KpMWhqlul8D7hY_wvdgCLcBGAs/s1600/user_prefs.png" target="_self"></a><img src="https://4.bp.blogspot.com/-fYDwWcOt6_s/WXOWesh1aLI/AAAAAAAAdMs/AxHGCrg-dvEaw9KpMWhqlul8D7hY_wvdgCLcBGAs/s400/user_prefs.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> 2) Make the Left Mouse Button the selection button Blender is very strange in that it defaults to use the right mouse button for selection. &nbsp;Let's change that to the standard left mouse button. In the left column, set the left mouse button. <br><a data-tooltip-position="top" aria-label="https://2.bp.blogspot.com/-8UoasF5KsVI/WXOXBL5BzdI/AAAAAAAAdNE/WhBVPYH_FsUKjcTs5zE8QPDc-kFbHn83gCEwYBhgL/s1600/select_with.png" rel="noopener nofollow" class="external-link is-unresolved" href="https://2.bp.blogspot.com/-8UoasF5KsVI/WXOXBL5BzdI/AAAAAAAAdNE/WhBVPYH_FsUKjcTs5zE8QPDc-kFbHn83gCEwYBhgL/s1600/select_with.png" target="_self"></a><img src="https://2.bp.blogspot.com/-8UoasF5KsVI/WXOXBL5BzdI/AAAAAAAAdNE/WhBVPYH_FsUKjcTs5zE8QPDc-kFbHn83gCEwYBhgL/s1600/select_with.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> 3) Ensure View Navigation is set to Walk Blender allows for two navigation modes: Walkand Fly. Flymight sound like what we want, but it behaves more like a spaceship where the rotational speed is based on the position of the mouse onscreen and you use the mouse wheel to control "throttle". Walkis actually what we want, since it behaves like standard FPS controls. &nbsp;This is the default setting in Blender, but we should ensure it is set. <br><a data-tooltip-position="top" aria-label="https://1.bp.blogspot.com/-gf-iDlHgHOM/WXOXBZWHLRI/AAAAAAAAdNY/17Eq6Zy4g_k-_RexTfqYPOpIZSZCphfzQCEwYBhgL/s1600/view_navigation.png" rel="noopener nofollow" class="external-link is-unresolved" href="https://1.bp.blogspot.com/-gf-iDlHgHOM/WXOXBZWHLRI/AAAAAAAAdNY/17Eq6Zy4g_k-_RexTfqYPOpIZSZCphfzQCEwYBhgL/s1600/view_navigation.png" target="_self"></a><img src="https://1.bp.blogspot.com/-gf-iDlHgHOM/WXOXBZWHLRI/AAAAAAAAdNY/17Eq6Zy4g_k-_RexTfqYPOpIZSZCphfzQCEwYBhgL/s1600/view_navigation.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> You should also ensure that the Gravitycheckbox is unchecked (the default) to prevent falling due to gravity. 4) Create a new input configuration called Unity We don't want to muck with any of the existing input binding configurations, so let's create our own. Click the&nbsp;+ button next to the Blender/Max/Maya settings. <br><a data-tooltip-position="top" aria-label="https://2.bp.blogspot.com/-AsjX_a2wbic/WXOYkkejl7I/AAAAAAAAdNg/m3havMNO3R4e9TIw4402oqSCUp6HcwjzACLcBGAs/s1600/new_input_config.png" rel="noopener nofollow" class="external-link is-unresolved" href="https://2.bp.blogspot.com/-AsjX_a2wbic/WXOYkkejl7I/AAAAAAAAdNg/m3havMNO3R4e9TIw4402oqSCUp6HcwjzACLcBGAs/s1600/new_input_config.png" target="_self"></a><img src="https://2.bp.blogspot.com/-AsjX_a2wbic/WXOYkkejl7I/AAAAAAAAdNg/m3havMNO3R4e9TIw4402oqSCUp6HcwjzACLcBGAs/s1600/new_input_config.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> Give it the name "Unity" (or whatever you want) and click OK. <br><a data-tooltip-position="top" aria-label="https://1.bp.blogspot.com/-jUCvDwKDSP8/WXOXBA9MIfI/AAAAAAAAdNY/EdFf-Er6E2IS7jWRYfokDnIg-8cRFyvgACEwYBhgL/s1600/new_input_config2.png" rel="noopener nofollow" class="external-link is-unresolved" href="https://1.bp.blogspot.com/-jUCvDwKDSP8/WXOXBA9MIfI/AAAAAAAAdNY/EdFf-Er6E2IS7jWRYfokDnIg-8cRFyvgACEwYBhgL/s1600/new_input_config2.png" target="_self"></a><img src="https://1.bp.blogspot.com/-jUCvDwKDSP8/WXOXBA9MIfI/AAAAAAAAdNY/EdFf-Er6E2IS7jWRYfokDnIg-8cRFyvgACEwYBhgL/s320/new_input_config2.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> Ensure that is now your selected input configuration. 5) Disable the setting of the 3D cursor Normally the left mouse button sets a "3D cursor" in Blender. I'm sure it's useful to many people but I find it confusing and gets in the way. Since we switched left mouse to be selection, Blender switches the right mouse button to set the 3D cursor. &nbsp;We don't want this, so we disable it in the input bindings. 3D View&nbsp;&nbsp;3D View (Global)&nbsp;&nbsp;Set 3D Cursor <br><a data-tooltip-position="top" aria-label="https://1.bp.blogspot.com/-yZeWg9D2Vmo/WXOXBQrmYsI/AAAAAAAAdNY/h-YQptrPKS4xhq1dp4DMNJtugyj8IkaPACEwYBhgL/s1600/set_3d_cursor.png" rel="noopener nofollow" class="external-link is-unresolved" href="https://1.bp.blogspot.com/-yZeWg9D2Vmo/WXOXBQrmYsI/AAAAAAAAdNY/h-YQptrPKS4xhq1dp4DMNJtugyj8IkaPACEwYBhgL/s1600/set_3d_cursor.png" target="_self"></a><img src="https://1.bp.blogspot.com/-yZeWg9D2Vmo/WXOXBQrmYsI/AAAAAAAAdNY/h-YQptrPKS4xhq1dp4DMNJtugyj8IkaPACEwYBhgL/s400/set_3d_cursor.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> 6) Create new input binding for Right Mouse Button to enter View Navigation mode This took a bit of sleuthing, and is one of the most important parts. Blender lets you enter View Navigationmode by hitting Shift+F. &nbsp;Searching through the input bindings I found the Python command Blender binds to that key combo. <br><a data-tooltip-position="top" aria-label="https://4.bp.blogspot.com/-RVQiBCLD1LA/WXOXBQ-526I/AAAAAAAAdNY/JEwEoLjycio8G4ec-xnxtAsBeNy1vapOwCEwYBhgL/s1600/view_navigation_keyboard.png" rel="noopener nofollow" class="external-link is-unresolved" href="https://4.bp.blogspot.com/-RVQiBCLD1LA/WXOXBQ-526I/AAAAAAAAdNY/JEwEoLjycio8G4ec-xnxtAsBeNy1vapOwCEwYBhgL/s1600/view_navigation_keyboard.png" target="_self"></a><img src="https://4.bp.blogspot.com/-RVQiBCLD1LA/WXOXBQ-526I/AAAAAAAAdNY/JEwEoLjycio8G4ec-xnxtAsBeNy1vapOwCEwYBhgL/s320/view_navigation_keyboard.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> We now want to replicate that functionality for the right mouse button. In the 3D View&nbsp;&nbsp;3D View (Global) section, add a new input binding by clicking the + Add New button <br><a data-tooltip-position="top" aria-label="https://3.bp.blogspot.com/-yb8wbYPZObY/WXOXA7EAYZI/AAAAAAAAdNY/syAczpZcGO008uGzDlqYCPXDKCgkn_H7ACEwYBhgL/s1600/add_new.png" rel="noopener nofollow" class="external-link is-unresolved" href="https://3.bp.blogspot.com/-yb8wbYPZObY/WXOXA7EAYZI/AAAAAAAAdNY/syAczpZcGO008uGzDlqYCPXDKCgkn_H7ACEwYBhgL/s1600/add_new.png" target="_self"></a><img src="https://3.bp.blogspot.com/-yb8wbYPZObY/WXOXA7EAYZI/AAAAAAAAdNY/syAczpZcGO008uGzDlqYCPXDKCgkn_H7ACEwYBhgL/s1600/add_new.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> Now, change the input to be when the right mouse button is pressed. Enter the view3d.navigate Python command to the binding. Like so: <br><a data-tooltip-position="top" aria-label="https://4.bp.blogspot.com/-gKBjaJwbT-4/WXOXBrOCHwI/AAAAAAAAdNY/Mvqo8d-_RmotZWqwxRxko9iDEQqIbuEsACEwYBhgL/s1600/view_navigation_mouse.png" rel="noopener nofollow" class="external-link is-unresolved" href="https://4.bp.blogspot.com/-gKBjaJwbT-4/WXOXBrOCHwI/AAAAAAAAdNY/Mvqo8d-_RmotZWqwxRxko9iDEQqIbuEsACEwYBhgL/s1600/view_navigation_mouse.png" target="_self"></a><img src="https://4.bp.blogspot.com/-gKBjaJwbT-4/WXOXBrOCHwI/AAAAAAAAdNY/Mvqo8d-_RmotZWqwxRxko9iDEQqIbuEsACEwYBhgL/s640/view_navigation_mouse.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> 7) Disable the Right Mouse Button from cancelling View Navigation mode By default the View Navigation mode is cancelled by any right mouse button action. We want Blender to leave View Navigation mode when we release the right mouse button, but we want it to retain our final position and orientation. In Blender the is Confirmaction, versus the Cancelaction, which resets to view to whatever it was before View Navigation mode was entered. In the 3D View&nbsp;&nbsp;View3D Walk Modal section, disable the right mouse cancelling binding. <br><a data-tooltip-position="top" aria-label="https://3.bp.blogspot.com/-NesUfpup2FI/WXOXA_6TKNI/AAAAAAAAdNY/V084NvjQGQU4HkxoNB5q1U6_RBHmpcMPACEwYBhgL/s1600/cancel.png" rel="noopener nofollow" class="external-link is-unresolved" href="https://3.bp.blogspot.com/-NesUfpup2FI/WXOXA_6TKNI/AAAAAAAAdNY/V084NvjQGQU4HkxoNB5q1U6_RBHmpcMPACEwYBhgL/s1600/cancel.png" target="_self"></a><img src="https://3.bp.blogspot.com/-NesUfpup2FI/WXOXA_6TKNI/AAAAAAAAdNY/V084NvjQGQU4HkxoNB5q1U6_RBHmpcMPACEwYBhgL/s400/cancel.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> 8) Add new Right Mouse Button confirmation Now to make Blender save the position when releasing the mouse butotn, we have to bind it to the Confirmaction. In the 3D View&nbsp;&nbsp;View3D Walk Modal&nbsp;section, add a new input binding by clicking the + Add New button <br><a data-tooltip-position="top" aria-label="https://3.bp.blogspot.com/-yb8wbYPZObY/WXOXA7EAYZI/AAAAAAAAdNY/syAczpZcGO008uGzDlqYCPXDKCgkn_H7ACEwYBhgL/s1600/add_new.png" rel="noopener nofollow" class="external-link is-unresolved" href="https://3.bp.blogspot.com/-yb8wbYPZObY/WXOXA7EAYZI/AAAAAAAAdNY/syAczpZcGO008uGzDlqYCPXDKCgkn_H7ACEwYBhgL/s1600/add_new.png" target="_self"></a><img src="https://3.bp.blogspot.com/-yb8wbYPZObY/WXOXA7EAYZI/AAAAAAAAdNY/syAczpZcGO008uGzDlqYCPXDKCgkn_H7ACEwYBhgL/s1600/add_new.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> Then, set the right mouse release to be confirm, like so: <br><a data-tooltip-position="top" aria-label="https://2.bp.blogspot.com/-axJ5PRCcl5c/WXOXAzT-c2I/AAAAAAAAdNY/_V49UUpKtlID6aXWmYOiqgob8S58TOrvgCEwYBhgL/s1600/confirm.png" rel="noopener nofollow" class="external-link is-unresolved" href="https://2.bp.blogspot.com/-axJ5PRCcl5c/WXOXAzT-c2I/AAAAAAAAdNY/_V49UUpKtlID6aXWmYOiqgob8S58TOrvgCEwYBhgL/s1600/confirm.png" target="_self"></a><img src="https://2.bp.blogspot.com/-axJ5PRCcl5c/WXOXAzT-c2I/AAAAAAAAdNY/_V49UUpKtlID6aXWmYOiqgob8S58TOrvgCEwYBhgL/s400/confirm.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved">That's it! &nbsp;You should now be able to use the right mouse button to fly around a Blender scene just like in the Unity editor!]]></description><link>https://glitchenzo.github.io/2017-07-22-making-blender-like-unity.html</link><guid isPermaLink="false">2017-07-22 - Making Blender Like Unity.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Tue, 04 Mar 2025 17:55:16 GMT</pubDate><enclosure url="https://2.bp.blogspot.com/-AG5Mqyk2ug8/WXOV8SItZQI/AAAAAAAAdMo/TvkAZCD-D9MDHMFpAWPI7hdSDfzJ3DEjQCLcBGAs/s320/show_user_prefs.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="https://2.bp.blogspot.com/-AG5Mqyk2ug8/WXOV8SItZQI/AAAAAAAAdMo/TvkAZCD-D9MDHMFpAWPI7hdSDfzJ3DEjQCLcBGAs/s320/show_user_prefs.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2011-09-12 - Procedural Primitives (Unity Asset Store)]]></title><description><![CDATA[2011-09-12<a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/-v_cl7zyKqNM/Tm5UDoFRJKI/AAAAAAAAF8M/uvDx0n3IW8E/s1600/screen1.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/-v_cl7zyKqNM/Tm5UDoFRJKI/AAAAAAAAF8M/uvDx0n3IW8E/s1600/screen1.png" target="_self"></a><img src="http://4.bp.blogspot.com/-v_cl7zyKqNM/Tm5UDoFRJKI/AAAAAAAAF8M/uvDx0n3IW8E/s400/screen1.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> <br>I've released my first package, Procedural Primitives, on the Unity Asset Store. <a data-tooltip-position="top" aria-label="http://u3d.as/content/re-creation-studios/procedural-primitives/1XM" rel="noopener nofollow" class="external-link is-unresolved" href="http://u3d.as/content/re-creation-studios/procedural-primitives/1XM" target="_self">Check it out here</a>.<br>It's based on the code I wrote to generate primitives in XNA. You can read about that code and download it on my old blog post <a data-tooltip-position="top" aria-label="http://recreationstudios.blogspot.com/2009/04/boxes-cylinders-and-spheres-oh-my.html" rel="noopener nofollow" class="external-link is-unresolved" href="http://recreationstudios.blogspot.com/2009/04/boxes-cylinders-and-spheres-oh-my.html" target="_self">here</a>.Basically, it allows you to create your own primitive 3D shapes (planes, cylinders, cones, and boxes) in Unity. Sure, Unity already has all of these as built-in primitives, but you can't change the resolution of these shapes at all. Plus, they provide no ability to create just the Mesh object and not a full GameObject. Procedural Primitives lets you pick the quality you want and gives you the option to create only the Mesh or the a full GameObject containing MeshFilter, MeshRenderer, and Collider components.Procedural Primitives allows you to create the shapes either in the Unity Editor by way of a custom editor window, or you can call the methods in script.To create them in the editor, you choose GameObject --&gt; Create Other --&gt; Procedural Primitive from the menu:<br><a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/-Z3RhFXBoWoU/Tm5USuWlpMI/AAAAAAAAF8U/0btpyulpCyo/s1600/screen4.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/-Z3RhFXBoWoU/Tm5USuWlpMI/AAAAAAAAF8U/0btpyulpCyo/s1600/screen4.png" target="_self"></a><img src="http://4.bp.blogspot.com/-Z3RhFXBoWoU/Tm5USuWlpMI/AAAAAAAAF8U/0btpyulpCyo/s400/screen4.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> A new window will pop up that will allow you to tweak several parameters (depending upon the chosen shape) and then create a new primitive shape.<br><a data-tooltip-position="top" aria-label="http://2.bp.blogspot.com/-Oc0rr3j5-yY/Tm5VbGfZMdI/AAAAAAAAF8g/BQ0PXsvdgZQ/s1600/screen5.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://2.bp.blogspot.com/-Oc0rr3j5-yY/Tm5VbGfZMdI/AAAAAAAAF8g/BQ0PXsvdgZQ/s1600/screen5.png" target="_self"></a><img src="http://2.bp.blogspot.com/-Oc0rr3j5-yY/Tm5VbGfZMdI/AAAAAAAAF8g/BQ0PXsvdgZQ/s400/screen5.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved"> To create a new shape in script, you simply call one of the static methods on the Primitive class along with the desired parameters: <br><a data-tooltip-position="top" aria-label="http://4.bp.blogspot.com/-F_YoB4iBGk4/Tm5a54j0QxI/AAAAAAAAF8s/uC7O5D5hwEs/s1600/screen6.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://4.bp.blogspot.com/-F_YoB4iBGk4/Tm5a54j0QxI/AAAAAAAAF8s/uC7O5D5hwEs/s1600/screen6.png" target="_self"></a><img src="http://4.bp.blogspot.com/-F_YoB4iBGk4/Tm5a54j0QxI/AAAAAAAAF8s/uC7O5D5hwEs/s400/screen6.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved">All money I get from the sales of Procedural Primitives will help fund my purchase of an Android license of Unity. I'm currently preparing my noise package release. It should be coming out sometime in the next week.]]></description><link>https://glitchenzo.github.io/2011-09-12-procedural-primitives-(unity-asset-store).html</link><guid isPermaLink="false">2011-09-12 - Procedural Primitives (Unity Asset Store).md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Sun, 05 Jan 2025 21:50:15 GMT</pubDate><enclosure url="http://4.bp.blogspot.com/-v_cl7zyKqNM/Tm5UDoFRJKI/AAAAAAAAF8M/uvDx0n3IW8E/s400/screen1.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://4.bp.blogspot.com/-v_cl7zyKqNM/Tm5UDoFRJKI/AAAAAAAAF8M/uvDx0n3IW8E/s400/screen1.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2023-12-31 - A Look Back Over 2023]]></title><description><![CDATA[2023-12-31This is my longest blog post by far!It's been 21 months since I last posted on here, which is a ridiculous amount of time. But, importantly (to me at least), I still haven't missed a single year since I began this blog 16 years ago. Dang, that makes me feel old. So, what have I been busy doing for this period of time?A lot of my time, energy, and mental problem-solving have been spent toward work. I've been busy leading a team where we come up with new rendering tech for <a data-tooltip-position="top" aria-label="https://store.steampowered.com/app/1430190/Killing_Floor_3/" rel="noopener nofollow" class="external-link is-unresolved" href="https://store.steampowered.com/app/1430190/Killing_Floor_3/" target="_self">Killing Floor 3</a>. I probably can't go into much detail without divulging trade secrets, but my team focuses on making state-of-the-art gore systems. I would love for us to be able to present our solution as a GDC talk, or something similar.<br>I've been continuing work on <a data-tooltip-position="top" aria-label="http://pipeline.graphics/" rel="noopener nofollow" class="external-link is-unresolved" href="http://pipeline.graphics/" target="_self">Pipeline</a> off and on, but it's going much slower than I anticipated. I'd love to implement some cutting edge features like raytracing, more mesh shaders, indirect drawing, and virtual texturing (with sampler feedback), but I find myself getting distracted with serialization, UI interface, and pondering the best ways to make undo/redo systems. Looking over the new shader <a data-tooltip-position="top" aria-label="https://devblogs.microsoft.com/directx/d3d12-work-graphs-preview/" rel="noopener nofollow" class="external-link is-unresolved" href="https://devblogs.microsoft.com/directx/d3d12-work-graphs-preview/" target="_self">Work Graphs</a>, I wonder when I'll actually catch up to the latest graphics features. I'd also love to tinker with the new <a data-tooltip-position="top" aria-label="https://devblogs.microsoft.com/directx/windows-directml-with-npus/" rel="noopener nofollow" class="external-link is-unresolved" href="https://devblogs.microsoft.com/directx/windows-directml-with-npus/" target="_self">DirectML</a> features.<br>Lately, I've been focused on parsing the <a data-tooltip-position="top" aria-label="https://github.com/microsoft/DirectX-Headers/blob/main/include/directx/d3d12.h" rel="noopener nofollow" class="external-link is-unresolved" href="https://github.com/microsoft/DirectX-Headers/blob/main/include/directx/d3d12.h" target="_self">C++ DX12 header</a> to auto-generate most of the boilerplate code for me automatically, but that is also taking far more effort than I originally anticipated. I find myself making very custom parsing and generation code to create the wrappers, which kind of defeats the original intention and purpose. Ideally, the auto-generation would create the XML serialization and ImGui methods with little to no specialized generation code. Should this instead auto-generate the starting point instead of the the final methods? Something for me to think about and consider.This year I turned 40. That number still seems very large to me and I don't feel anywhere close to what I thought that age would feel like.
What do they do with engineers who turn 40? They take them out back and shoot them. Primer To celebrate my birthday, I travelled to St. Croix in the US Virgin Islands. I had never been to the Caribbean before, and it was beautiful. My goal is to eventually visit the South Pacific and in some ways, the Caribbean islands could be considered a "poor man's" South Pacific. Okay, maybe not that poor of a man.I'm a big fan of whiskey, so I decided to splurge for my 40th birthday. I bought a $400 bottle of Japanese whiskey. I figured a bottle that cost $10 per year of my life was worth it. Honestly, I would say it's not the best whiskey I've ever had, but it was quite tasty.I'm very proud to say that just weeks before my 40th birthday I took and passed my checkride to be able to get my Private Pilot's License! I actually began my pilot lessons back in 2008, which is 14 years ago. I stopped my lessons in 2010, thinking I would be taking a temporary hiatus, which ended up lasting over 11 years. You just never know how life will distract you and lead you in different directions.I don't yet have my own plane and I'm not a member of a flying club or anything, so the only way I can fly currently is to rent a plane, which is quite expensive. I've been researching lots of different aircraft trying to figure out which one best fits my mission. I've been mainly considering the Cessna 170, Ran's S-21 Outbound, Van's RV-14 or RV-15 (not yet available), or Zenith CH-750 Super Duty. In fact, this past summer I went and visited the Zenith factory in Missouri. Who knows what I'll eventually end up with though. It will likely be a completely different and random plane that I can afford to buy and fly while I potentially build my own plane.I would also love to continue to extend my license with a tailwheel endorsement and an instrument rating. Getting my pilot's license makes me think of my unofficial "bucket list" of things I want to accomplish in my life. I now have several published games with my name in the credits, which was one of my major life goals. Getting a pilot's license and my own plane is another.What remaining goals to I have?
Be the author of a published fiction book
I've been working on a multi-book story for nearly 20 years at this point. I've written several drafts of the first book but I never got it to a state where I can even send it to a publisher.
Be the lead engineer/designer of my own published indie game
I've attempted to work with artists in my free-time at least twice now to make an indie game. The problem is that it's hard to keep myself and others motived on a project that we're all doing for free, with the hope of success later in the future. One of goals would be to try to use as little human and financial resources as possible. This raises the question of generative AI, the latest hot topic. I could likely utilize generative AI for art, animation, music, sound effects, text to speech, etc. These would all greatly help a single developer be able to make a full and complete game in a reasonable amount of time.While I do have this dev blog, you'll notice that I don't update it very often anymore. This directly correlates to my general note-taking in life. I will write a bunch of notes in one place and then never gather them together into anything meaningful. And they often get lost over time and especially after job changes. (For example, I used to have tons of notes for Unity, but now that I haven't used Unity professionally for over 6 years, I have no idea where those notes went or how useful they still are.)I've often admired friends and co-workers who keep copious, well-organized notes. Unsurprisingly, this made them extremely knowledgeable and also made them grow tremendously. I would like to apply these same aspects to myself.<br>I started using <a data-tooltip-position="top" aria-label="https://www.tangentnotes.com/" rel="noopener nofollow" class="external-link is-unresolved" href="https://www.tangentnotes.com/" target="_self">Tangent Notes</a>, mainly for a way to organize my world-building for my book series I mentioned above. However, I soon found it very helpful for organizing all of my notes. I transitioned over to <a data-tooltip-position="top" aria-label="https://obsidian.md/" rel="noopener nofollow" class="external-link is-unresolved" href="https://obsidian.md/" target="_self">Obsidian</a>, mainly due to <a data-tooltip-position="top" aria-label="https://obsidian.md/sync" rel="noopener nofollow" class="external-link is-unresolved" href="https://obsidian.md/sync" target="_self">Obsidian Sync</a>, and I now have separate "vaults" for novel-writing, hobbies, work, and even blog posts.Speaking of these blog posts. I think it's time that I transition away from Blogger/Blogspot. It's served we well over the past 16 years, but I now want something I have more direct control over. Ideally, I can write all of my posts in Markdown in Obsidian and export those as HTML to be hosted on GitHub (or my own server). I've already begun some work in this regard, but it's not ready for a full transition yet.2023 was a big year for me with some big accomplishments and changes. I consider myself to be very lucky with my life and career and I hope that continues though 2024 and into the future.Until next time...]]></description><link>https://glitchenzo.github.io/2023-12-31-a-look-back-over-2023.html</link><guid isPermaLink="false">2023-12-31 - A Look Back Over 2023.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Sun, 31 Dec 2023 19:24:55 GMT</pubDate></item><item><title><![CDATA[2019-12-11 - How to Get a Job in the Video Game Industry]]></title><description><![CDATA[2019-12-11I've been neglecting this blog. While I've been working as a professional game developer for the past 12 years (yowza!), a little over two and a half years ago I]]></description><link>https://glitchenzo.github.io/2019-12-11-how-to-get-a-job-in-the-video-game-industry.html</link><guid isPermaLink="false">2019-12-11 - How to Get a Job in the Video Game Industry.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Sun, 31 Dec 2023 19:09:12 GMT</pubDate></item><item><title><![CDATA[2013-12-12 - Breaking Radio Silence]]></title><description><![CDATA[2013-12-12Boy have things been busy for me! &nbsp;I'm now going to do something rare and dive into more detail into my personal life, so feel free to skip this entire post if you want development related information. Since my last post, I've moved twice and changed jobs. &nbsp;In August and September 2012, my previous employer's parent company had tasked us with the simultaneous development of four games in order to present them at a big expo in Las Vegas. &nbsp;For a team of 12 people, this was quite a task, but we were successful and were all quite happy to see the games on the show floor in October 2012. We returned home in high spirits and full of new ideas to implement. &nbsp;There was a meeting scheduled with our parent company just days after we got back. &nbsp;We all thought it would be congratulatory and a&nbsp;discussion&nbsp;of future projects. &nbsp;Instead, they announced that our entire studio was being laid off and we had three hours to gather our things and leave. &nbsp;Being the first time I've ever been laid off, it was quite shocking to me. I immediately began searching everywhere for a new job: San Francisco, Sacramento, Salt Lake City, Montreal, Orlando, etc. &nbsp;I ended up accepting a position in Reno for a small-ish casino game developer. &nbsp;I'm basically the resident "Unity expert" and I help guide the best practices in it's use (reduce memory usage, improve artist workflow, etc). I also help plan and develop Unity tools and template projects as well. I decided to move to be closer to the new office. &nbsp;Plus, I figured it was finally time for me to move out of an apartment into a house. &nbsp;That involved not only moving all of my stuff, but also getting much more&nbsp;furniture&nbsp;to fill the house. &nbsp;One of my major intentions of moving into a house was to get a puppy, but it turned out I was misinformed and my landlord didn't allow dogs. So, I had to move againto a house that really did allow dogs. &nbsp;I now have a Chocolate Labradoodle puppy named <a data-tooltip-position="top" aria-label="http://en.wikipedia.org/wiki/Fenrir" rel="noopener nofollow" class="external-link is-unresolved" href="http://en.wikipedia.org/wiki/Fenrir" target="_self">Fenrir</a>. I've also been occupied with developing a relationship with a fantastic woman, but that's all I'll say about that, since that is a little too personal. So, although life has been quite busy the past several months, it has also been relatively good! I've been tinkering around with Unity 4.x as well as testing out various web IDEs for doing WebGL development. &nbsp;The 2D workflow in Unity 4.3 looks fantastic and I want to play around with it more. Oh, and I also got braces on my teeth since my last post. &nbsp;So I'm one of those weird adults with a brace-face. I'll probably be looking into actually updating my assets on the Unity Asset Store sometime soon.]]></description><link>https://glitchenzo.github.io/2013-12-12-breaking-radio-silence.html</link><guid isPermaLink="false">2013-12-12 - Breaking Radio Silence.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Sun, 31 Dec 2023 18:52:48 GMT</pubDate></item><item><title><![CDATA[2019-12-31 - Another Year]]></title><description><![CDATA[2019-12-31I started this devblog 11 years ago (wow!) to showcase the game development tech I had been working on in my free time. Almost three years ago I (finally) got a job in an actual AAA game dev studio. In those three years I've been busy working on several games but I've also been very active on a private, internal devblog shared by the studio. Unfortunately, that leaves little desire to write different devblogs in my freetime.&nbsp; On a positive note, I'm scratching the devblog itch with something officially supported by my employer, which is great. So the lack of posts here shouldn't been seen as me no longer working on any game dev projects.&nbsp; In fact, quite the opposite is true. I'm not going to commit to posting here more, because that frankly seems untenable. I hope to keep up the minimum of one per year, which I barely hit this year. Onward to 2020!]]></description><link>https://glitchenzo.github.io/2019-12-31-another-year.html</link><guid isPermaLink="false">2019-12-31 - Another Year.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Sun, 31 Dec 2023 18:52:41 GMT</pubDate></item><item><title><![CDATA[2020-09-17 - A Positive Note]]></title><description><![CDATA[2020-09-172020 has been a crazy/scary/disappointing/frustrating year for many different reasons.Thankfully, I've had at least one big great thing happen this year.I was officially a graphics engineer on a game that some folks called "<a data-tooltip-position="top" aria-label="https://www.eurogamer.net/articles/digitalfoundry-2020-tony-hawks-pro-skater-1-2-activisions-game-of-the-generation" rel="noopener nofollow" class="external-link is-unresolved" href="https://www.eurogamer.net/articles/digitalfoundry-2020-tony-hawks-pro-skater-1-2-activisions-game-of-the-generation" target="_self">one of the best games ever made</a>": Tony Hawk's Pro Skater 1+2.It's crazy to think of where I started, back with those simple XNA projects. It just goes to show you that you never know where you might end up!Here's to the rest of 2020 and the hope that there are many more happy moments! We need them.]]></description><link>https://glitchenzo.github.io/2020-09-17-a-positive-note.html</link><guid isPermaLink="false">2020-09-17 - A Positive Note.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Fri, 22 Dec 2023 03:27:02 GMT</pubDate></item><item><title><![CDATA[2009-02-05 - Per Pixel Normal Calculation]]></title><description><![CDATA[2009-02-05Sorry, still no actual code or pretty pictures! I just wanted to write up a quick note related to my second topic in my previous post. I did some Googling to see if any other people have implemented a similar system and indeed some people have. In fact I found an article by Microsoft that describes exactly what I was talking about.
<a data-tooltip-position="top" aria-label="http://msdn.microsoft.com/en-us/library/cc308054%28VS.85%29.aspx" rel="noopener nofollow" class="external-link is-unresolved" href="http://msdn.microsoft.com/en-us/library/cc308054%28VS.85%29.aspx" target="_self">http://msdn.microsoft.com/en-us/library/cc308054(VS.85).aspx</a> In the article, they are creating procedural materials dynamically, so they have to calculate normals dynamically as well. From the article:
"One solution is to run the shader multiple times and compute the difference in height at each sample point. If we calculated the height one pixel to the right of the currently rasterized pixel and one pixel above the currently rasterized pixel, we could compute tangent and bitangent vectors to the central pixel. Doing a cross product on these would give us the normal for that point." What I found funny is how they start talking about the ddX and ddY functions in HLSL but in the end they still use the render target + second pass method. "The solution that this sample uses by default is to render the perturbed heights of the objects in the scene into an off-screen render target. That render target is then read back in on another pass. For each pixel on the screen, its right and top neighbors are sampled. Tangent and bitangent vectors are created from the neighbors to the central pixel. A cross product between these will give the normal." I now feel very confident about this method of doing things and I will proceed to implement lighting in this manner. I will probably branch off of my existing planet codebase so I can easily compare the differences between the brute-force noise calculation vs the "deferred" style.]]></description><link>https://glitchenzo.github.io/2009-02-05-per-pixel-normal-calculation.html</link><guid isPermaLink="false">2009-02-05 - Per Pixel Normal Calculation.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Thu, 21 Dec 2023 22:30:50 GMT</pubDate></item><item><title><![CDATA[2009-02-03 - Hello 2009]]></title><description><![CDATA[2009-02-03I just realized that I never wrote an entry for January. It's the first month that I have not had an update since I started this dev blog. To be honest, I didn't have much to report. I haven't really written any code but I have been thinking about a lot. At first I was thinking about physics. I thought it would be nice to actually have collision detection with my terrain and possibly throw balls around or maybe even drive a car. However there was a big problem with this. How do I detect collision with a mesh that is deformed entirely on the GPU? Obviously I would have to have some way of sending the physics data to the GPU, do the collision detection there, and then somehow pass the resultant data back to the CPU. Getting the data to the GPU is the easy part, I think. If I only use bounding spheres for all of the objects, then I can simply pass one normal Color texture to the GPU containing the position of each sphere in the RGB and the radius of the sphere in the Alpha. It may even be possible to set a constant memory buffer (ie array) with the data, which would be even easier. Once I have this data, I can run through each object in the vertex shader to see if it collides with the current vertex. The problem I ran into then is I don't know how to get the data back to the CPU. I would obviously want to write the data to a render target. Unfortunately, the collision data is in the vertex shader. Pixel shaders cannot index into memory in XNA/DX9/SM3.0. [In DX10/SM4.0 they can index into constant memory, in DX11/SM5.0 both the vertex and pixel shaders can read and write to dynamic resources.] I have no idea how I would pass the data from the vertex shader to the pixel shader. That means I must somehow do the collision detection in the pixel shader. However, this means that I will be doing the checks for every object, for every pixel. That will be massive overkill. I couldn't come up with a good solution, so I pretty much gave up on physics for now. It should be a cinch in DirectX 11 and Shader Model 5.0! The next thing I was thinking about was mainly efficiencies. Currently I am calculating the normal in the pixel shader by doing 32 noise calculations per pixel. This is quite a strain on the GPU. I was reading an article about deferred rendering and I had a thought. If I only output the height of each pixel to a render target, then I could have another pass that reads the neighboring pixels in the render target into order to calculate the normal. This means it would one pass that does 8 noise calculations per pixel and then a second pass that does 4 texture lookups per pixel. I imagine that would be a much faster way of doing things. I have yet to actually implement anything though. So everything here is just speculation. Sorry for no pretty pictures. I will try to get something worth showing off sometime soon.]]></description><link>https://glitchenzo.github.io/2009-02-03-hello-2009.html</link><guid isPermaLink="false">2009-02-03 - Hello 2009.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Thu, 21 Dec 2023 22:29:31 GMT</pubDate></item><item><title><![CDATA[2008-08-04 - Nothing is easy]]></title><description><![CDATA[2008-08-04I thought that my camera was moving way too slowly after I increased the size to 6.5 million meters, so I increased its default speed. I also have a couple of keys that act as multipliers in order to get really high speeds. Unfortunately I realized that my terrain couldn't keep up with me because I was moving too fast. This is because the terrain would only move a maximum of 1 step each loop. So, if I traveled 3 steps' distance in one update loop, the terrain would fall 2 steps behind. I wrote a solution to this by calculating the number of steps the camera has moved and then rotate the terrain the appropriate number of steps. This worked great and the terrain always kept up with the camera. BUT! Yes, the big dreaded but. The terrain randomly disappears. It will be fine for quite a while and then flash on and off like crazy. Even worse, sometimes it completely disappears and doesn't return, no matter which way I turn or move. I have no idea what is causing this problem and I have tried debugging the code for awhile now. So either I find a fix to this bug, or I'll have to limit the speed to be slow enough that the terrain can keep up. I feel bad for not having any media for so long, so here is a screenshot to appease the horde. I desperately need to get better texturing on the terrain, but that will come after I get the terrain working to my satisfaction.
<a data-tooltip-position="top" aria-label="http://bp0.blogger.com/_hGl_uKJzpS0/SJfe25rwyEI/AAAAAAAADzI/pHLgZOPb1cE/s1600-h/screenshot_633534840388750000.png" rel="noopener nofollow" class="external-link is-unresolved" href="http://bp0.blogger.com/_hGl_uKJzpS0/SJfe25rwyEI/AAAAAAAADzI/pHLgZOPb1cE/s1600-h/screenshot_633534840388750000.png" target="_self"></a><img src="http://bp0.blogger.com/_hGl_uKJzpS0/SJfe25rwyEI/AAAAAAAADzI/pHLgZOPb1cE/s400/screenshot_633534840388750000.png" referrerpolicy="no-referrer" target="_self" class="is-unresolved">]]></description><link>https://glitchenzo.github.io/2008-08-04-nothing-is-easy.html</link><guid isPermaLink="false">2008-08-04 - Nothing is easy.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Thu, 21 Dec 2023 22:29:05 GMT</pubDate><enclosure url="http://bp0.blogger.com/_hGl_uKJzpS0/SJfe25rwyEI/AAAAAAAADzI/pHLgZOPb1cE/s400/screenshot_633534840388750000.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src="http://bp0.blogger.com/_hGl_uKJzpS0/SJfe25rwyEI/AAAAAAAADzI/pHLgZOPb1cE/s400/screenshot_633534840388750000.png"&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2008-08-07 - To-Do List]]></title><description><![CDATA[2008-08-07Here is a list of things that I want to get working before I create the next video: Fix disappearing terrain Make each level move at it's own step size (right now they all move at the smallest step size) Fix gaps between changing detail levels (you can see the gaps in the last screenshot I posted) As for the disappearing terrain, in my previous post you will see that I've narrowed the problem down to the angle calculation. I've read the documentation on acos() and it says that NaN is returned as a result if the input parameter is &lt; -1 or &gt; +1. I'm passing in the dot product of what should be two normal vectors, thus the input should never exceed 1. Apparently I'm not sending in true normal vectors, so I'm going to add more normalization calculations, just to make sure they are coming out normal. That should remove the NaN results, but hopefully it fixes the Pi results as well. (I'm crossing my fingers tightly.) I'll give it a try when I get home.]]></description><link>https://glitchenzo.github.io/2008-08-07-to-do-list.html</link><guid isPermaLink="false">2008-08-07 - To-Do List.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Thu, 21 Dec 2023 22:03:39 GMT</pubDate></item><item><title><![CDATA[2008-07-18 - First Blog Entry]]></title><description><![CDATA[2008-07-18Greetings! Here is my first blog post .... um ever! I will attempt to use this space to talk about some of the graphics projects that I am working on. Hopefully I actually stay devoted to it. I always seem to slack off on things similar to this. It's your duty as a reader to reprimand me if I fall behind on updates! Until next time...]]></description><link>https://glitchenzo.github.io/2008-07-18-first-blog-entry.html</link><guid isPermaLink="false">2008-07-18 - First Blog Entry.md</guid><dc:creator><![CDATA[Patrick McCarthy]]></dc:creator><pubDate>Thu, 21 Dec 2023 22:03:31 GMT</pubDate></item></channel></rss>